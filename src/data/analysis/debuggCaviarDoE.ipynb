{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark session created at 2025-06-26 13:30:28.104458\n",
      "Analysis started on 2025-06-26 at  2025-06-26 13:30:28.104458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/26 13:30:34 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files\n",
      "loaded files\n",
      "loaded newColoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gwasComplete\n",
      "loaded resolvedColloc\n",
      "run temporary direction of effect\n",
      "Moving to step 2\n",
      "defining non propagated,propagated and analysis_drugs functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining full_analysis_propagation\n"
     ]
    }
   ],
   "source": [
    "#### testing ecaviar for genevid analysis\n",
    "import time\n",
    "#from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "#from itertools import islice\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "#print('This time we want to have all Coloc and ecaviar >0.01')\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.06/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "ecaviar=spark.read.parquet(f\"{path_n}colocalisation_ecaviar\")\n",
    "\n",
    "all_coloc=ecaviar.unionByName(new, allowMissingColumns=True)#.filter((F.col('clpp')>=0.01) | (F.col('h4')>=0.8))\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    all_coloc.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            \"pValueExponent as qtlPValueExponent\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"right\", ## has to be right to have the whole genetic evidence subset (having doe or not)\n",
    "        )\n",
    "        #.join(  ### propagated using parent terms\n",
    "        #    diseases.selectExpr(\n",
    "        #        \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "        #    ),\n",
    "        #    on=\"diseaseId\",\n",
    "        #    how=\"left\",\n",
    "        #)\n",
    "        #.withColumn(\n",
    "        #    \"diseaseId\",\n",
    "        #    F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        #)\n",
    "        #.drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "resolvedColocFiltered = resolvedColoc.filter((F.col('clpp')>=0.01) | F.col('h4').isNotNull()) #| (F.col('h4')>=0.8))\n",
    "datasource_filter = [\n",
    "    #\"gwas_credible_set\", remove so avoid potential duplicates as it will be incorporated later (DoE is done separately)\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "window_spec = Window.partitionBy(\"targetId\", \"diseaseId\",'leftStudyId').orderBy( ### include gwas study\n",
    "    F.col(\"pValueExponent\").asc()\n",
    ")\n",
    "\n",
    "\n",
    "window_target_disease_only = Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "benchmark_processed = resolvedColocFiltered.withColumn(\n",
    "    \"hasboth\",\n",
    "    F.size(F.collect_set(\"colocalisationMethod\").over(window_target_disease_only)),\n",
    ")\n",
    "# Define window specs for the current iteration, including 'col_name' in partition\n",
    "# (This shuffle is still per iteration, but unavoidable if 'resolvedAgreeDrug' depends on 'col_name' values)\n",
    "current_col_window_spec_qtl = Window.partitionBy(\"targetId\", \"diseaseId\").orderBy(\n",
    "    F.col(\"qtlPValueExponent\").asc()\n",
    ")\n",
    "current_col_pvalue_order_window = Window.partitionBy(\"targetId\", \"diseaseId\").orderBy(\n",
    "    F.col(\"colocalisationMethod\").asc(), F.col(\"qtlPValueExponent\").asc()\n",
    ")\n",
    "\n",
    "# Calculate 'resolvedAgreeDrug' for the current 'col_name'\n",
    "# This involves a shuffle per iteration.\n",
    "temp_df_with_resolved = benchmark_processed.withColumn(\n",
    "    \"resolvedAgreeDrug\",\n",
    "    F.when(\n",
    "        F.col(\"hasboth\") > 1,\n",
    "        F.first(F.col(\"colocDoE\"), ignorenulls=True).over(\n",
    "            current_col_pvalue_order_window\n",
    "        ),\n",
    "    ).otherwise(\n",
    "        F.first(F.col(\"colocDoE\"), ignorenulls=True).over(current_col_window_spec_qtl)\n",
    "    ),\n",
    ")\n",
    "\n",
    "# qtlPValueExponent\n",
    "gwasCredibleAssoc_qtlPValue = (\n",
    "    temp_df_with_resolved.withColumn(\n",
    "        \"homogenized\", F.col('colocDoE')\n",
    "    )  ## added 30.01.2025\n",
    "    # .select(\"targetId\", \"diseaseId\",'leftStudyId', \"homogenized\")\n",
    "    .withColumn(\n",
    "        \"homogenized\",\n",
    "        F.when(F.col(\"homogenized\").isNull(), F.lit(\"noEvaluable\")).otherwise(\n",
    "            F.col(\"homogenized\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Moving to step 2\")\n",
    "\n",
    "columns_chembl = [\"LoF_protect\", \"GoF_protect\"]\n",
    "columns_dataset = [\"LoF_protect\", \"GoF_protect\", \"LoF_risk\", \"GoF_risk\", \"evidenceDif\"]\n",
    "columns = [\"GoF_risk\", \"LoF_protect\", \"LoF_risk\", \"GoF_protect\"]\n",
    "terms = [\"noEvaluable\", \"bivalent_risk\", \"null\", \"dispar\"]\n",
    "\n",
    "taDf = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"MONDO_0045024\", \"cell proliferation disorder\", \"Oncology\"),\n",
    "        (\"EFO_0005741\", \"infectious disease\", \"Other\"),\n",
    "        (\"OTAR_0000014\", \"pregnancy or perinatal disease\", \"Other\"),\n",
    "        (\"EFO_0005932\", \"animal disease\", \"Other\"),\n",
    "        (\"MONDO_0024458\", \"disease of visual system\", \"Other\"),\n",
    "        (\"EFO_0000319\", \"cardiovascular disease\", \"Other\"),\n",
    "        (\"EFO_0009605\", \"pancreas disease\", \"Other\"),\n",
    "        (\"EFO_0010282\", \"gastrointestinal disease\", \"Other\"),\n",
    "        (\"OTAR_0000017\", \"reproductive system or breast disease\", \"Other\"),\n",
    "        (\"EFO_0010285\", \"integumentary system disease\", \"Other\"),\n",
    "        (\"EFO_0001379\", \"endocrine system disease\", \"Other\"),\n",
    "        (\"OTAR_0000010\", \"respiratory or thoracic disease\", \"Other\"),\n",
    "        (\"EFO_0009690\", \"urinary system disease\", \"Other\"),\n",
    "        (\"OTAR_0000006\", \"musculoskeletal or connective tissue disease\", \"Other\"),\n",
    "        (\"MONDO_0021205\", \"disease of ear\", \"Other\"),\n",
    "        (\"EFO_0000540\", \"immune system disease\", \"Other\"),\n",
    "        (\"EFO_0005803\", \"hematologic disease\", \"Other\"),\n",
    "        (\"EFO_0000618\", \"nervous system disease\", \"Other\"),\n",
    "        (\"MONDO_0002025\", \"psychiatric disorder\", \"Other\"),\n",
    "        (\"MONDO_0024297\", \"nutritional or metabolic disease\", \"Other\"),\n",
    "        (\"OTAR_0000018\", \"genetic, familial or congenital disease\", \"Other\"),\n",
    "        (\"OTAR_0000009\", \"injury, poisoning or other complication\", \"Other\"),\n",
    "        (\"EFO_0000651\", \"phenotype\", \"Other\"),\n",
    "        (\"EFO_0001444\", \"measurement\", \"Other\"),\n",
    "        (\"GO_0008150\", \"biological process\", \"Other\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"taId\", StringType(), True),\n",
    "            StructField(\"taLabel\", StringType(), True),\n",
    "            StructField(\"taLabelSimple\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ").withColumn(\"taRank\", F.monotonically_increasing_id())\n",
    "\n",
    "### give us a classification of Oncology VS non oncology\n",
    "wByDisease = Window.partitionBy(\"diseaseId\")  #### checked 31.05.2023\n",
    "diseaseTA = (\n",
    "    diseases.withColumn(\"taId\", F.explode(\"therapeuticAreas\"))\n",
    "    .select(F.col(\"id\").alias(\"diseaseId\"), \"taId\", \"parents\")\n",
    "    .join(taDf, on=\"taId\", how=\"left\")\n",
    "    .withColumn(\"minRank\", F.min(\"taRank\").over(wByDisease))\n",
    "    .filter(F.col(\"taRank\") == F.col(\"minRank\"))\n",
    "    .drop(\"taRank\", \"minRank\")\n",
    ")\n",
    "\n",
    "#### give us propagation of diseases and list of therapeutic areas associated\n",
    "diseases2 = diseases.select(\"id\", \"parents\").withColumn(\n",
    "    \"diseaseIdPropagated\",\n",
    "    F.explode_outer(F.concat(F.array(F.col(\"id\")), F.col(\"parents\"))),\n",
    ")\n",
    "\n",
    "chembl_trials = (\n",
    "    assessment.filter((F.col(\"datasourceId\").isin([\"chembl\"])))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(F.max(F.col(\"clinicalPhase\")).alias(\"maxClinPhase\"))\n",
    ")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "assessment_all = assessment.unionByName(\n",
    "    gwasCredibleAssoc_qtlPValue.withColumn(\"datasourceId\", F.lit(\"gwas_credible_set\")),\n",
    "    allowMissingColumns=True,\n",
    ")\n",
    "\n",
    "print(\"defining non propagated,propagated and analysis_drugs functions\")\n",
    "\n",
    "def analysis_nonPropagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "def analysis_propagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .join(\n",
    "            diseases2.selectExpr(\"id as diseaseId\", \"diseaseIdPropagated\"),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumnRenamed(\"diseaseId\", \"oldDiseaseId\")\n",
    "        .withColumnRenamed(\"diseaseIdPropagated\", \"diseaseId\")\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "chembl_ds = [\"chembl\"]\n",
    "\n",
    "def analysis_drugs(assessment_all, chembl_ds):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter((F.col(\"datasourceId\").isin(chembl_ds))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "analysis_chembl = analysis_drugs(assessment_all, chembl_ds)\n",
    "\n",
    "#######\n",
    "## include here the analysis\n",
    "#######\n",
    "\n",
    "analysisDatasources = []\n",
    "\n",
    "print(\"defining full_analysis_propagation\")\n",
    "\n",
    "doe_columns=[\"LoF_protect\", \"GoF_risk\", \"LoF_risk\", \"GoF_protect\"]\n",
    "diagonal_lof=['LoF_protect','GoF_risk']\n",
    "diagonal_gof=['LoF_risk','GoF_protect']\n",
    "\n",
    "def full_analysis_propagation(\n",
    "    doe_columns,assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA,diagonal_lof,diagonal_gof\n",
    "):\n",
    "    conditions = [\n",
    "    F.when(F.col(c) == F.col(\"maxDoE\"), F.lit(c)).otherwise(F.lit(None)) for c in doe_columns\n",
    "    ]\n",
    "    \n",
    "    return (\n",
    "        analysis_propagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        #### Should remove the coherencyDiagonal.isNotNull()\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        ).withColumn(\n",
    "            \"arrayN\", F.array(*[F.col(c) for c in doe_columns])\n",
    "        ).withColumn(\n",
    "            \"maxDoE\", F.array_max(F.col(\"arrayN\"))\n",
    "        ).withColumn(\"maxDoE_names\", F.array(*conditions)\n",
    "        ).withColumn(\"maxDoE_names\", F.expr(\"filter(maxDoE_names, x -> x is not null)\")\n",
    "        ).withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxDoEArrayN\",\n",
    "            F.expr(\"aggregate(arrayN, 0, (acc, x) -> acc + IF(x = maxDoE, 1, 0))\")\n",
    "        ).withColumn(\n",
    "            \"NoneCellYes\",\n",
    "            F.when((F.col(\"LoF_protect_ch\").isNotNull() & (F.col('GoF_protect_ch').isNull())) & (F.array_contains(F.col(\"maxDoE_names\"), F.lit(\"LoF_protect\")))==True, F.lit('yes'))\n",
    "            .when((F.col(\"GoF_protect_ch\").isNotNull() & (F.col('LoF_protect_ch').isNull())) & (F.array_contains(F.col(\"maxDoE_names\"), F.lit(\"GoF_protect\")))==True, F.lit('yes')\n",
    "                ).otherwise(F.lit('no'))  # If the value is null, return null # Otherwise, check if name is in array\n",
    "        ).withColumn(\n",
    "            \"NdiagonalYes\",\n",
    "            F.when((F.col(\"LoF_protect_ch\").isNotNull() & (F.col('GoF_protect_ch').isNull())) & \n",
    "                (F.size(F.array_intersect(F.col(\"maxDoE_names\"), F.array([F.lit(x) for x in diagonal_lof]))) > 0),\n",
    "                F.lit(\"yes\")\n",
    "            ).when((F.col(\"GoF_protect_ch\").isNotNull() & (F.col('LoF_protect_ch').isNull())) & \n",
    "                (F.size(F.array_intersect(F.col(\"maxDoE_names\"), F.array([F.lit(x) for x in diagonal_gof]))) > 0),\n",
    "                F.lit(\"yes\")\n",
    "            ).otherwise(F.lit('no'))\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74187"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_trials.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining full analysis no propagation\n",
      "moving to Step 3\n",
      "starting dictionaries at 2025-06-26 13:32:12.551125\n",
      "gene_burden\n",
      "intogen\n",
      "cancer_gene_census\n",
      "eva\n",
      "eva_somatic\n",
      "gwas_credible_set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impc\n",
      "orphanet\n",
      "gene2phenotype\n",
      "somatic\n",
      "germline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#####\n",
    "## no propag\n",
    "#####\n",
    "print(\"defining full analysis no propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_noPropagation(\n",
    "    doe_columns,assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA,diagonal_lof,diagonal_gof\n",
    "):\n",
    "    conditions = [\n",
    "    F.when(F.col(c) == F.col(\"maxDoE\"), F.lit(c)).otherwise(F.lit(None)) for c in doe_columns\n",
    "    ]\n",
    "    return (\n",
    "        analysis_nonPropagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        ).withColumn(\n",
    "            \"arrayN\", F.array(*[F.col(c) for c in doe_columns])\n",
    "        ).withColumn(\n",
    "            \"maxDoE\", F.array_max(F.col(\"arrayN\"))\n",
    "        ).withColumn(\"maxDoE_names\", F.array(*conditions)\n",
    "        ).withColumn(\"maxDoE_names\", F.expr(\"filter(maxDoE_names, x -> x is not null)\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        ).withColumn(\n",
    "            \"maxDoEArrayN\",\n",
    "            F.expr(\"aggregate(arrayN, 0, (acc, x) -> acc + IF(x = maxDoE, 1, 0))\")\n",
    "        ).withColumn(\n",
    "            \"NoneCellYes\",\n",
    "            F.when(F.col(\"LoF_protect_ch\").isNotNull() & (F.array_contains(F.col(\"maxDoE_names\"), F.lit(\"LoF_protect\")))==True, F.lit('yes'))\n",
    "            .when(F.col(\"GoF_protect_ch\").isNotNull() & (F.array_contains(F.col(\"maxDoE_names\"), F.lit(\"GoF_protect\")))==True, F.lit('yes')\n",
    "                ).otherwise(F.lit('no'))  # If the value is null, return null # Otherwise, check if name is in array\n",
    "        ).withColumn(\n",
    "            \"NdiagonalYes\",\n",
    "            F.when(F.col(\"LoF_protect_ch\").isNotNull() & \n",
    "                (F.size(F.array_intersect(F.col(\"maxDoE_names\"), F.array([F.lit(x) for x in diagonal_lof]))) > 0),\n",
    "                F.lit(\"yes\")\n",
    "            ).when(F.col(\"GoF_protect_ch\").isNotNull() & \n",
    "                (F.size(F.array_intersect(F.col(\"maxDoE_names\"), F.array([F.lit(x) for x in diagonal_gof]))) > 0),\n",
    "                F.lit(\"yes\")\n",
    "            ).otherwise(F.lit('no'))\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "print(\"moving to Step 3\")\n",
    "\n",
    "from functions import relative_success, spreadSheetFormatter, convertTuple\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio, relative_risk\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "c = datetime.now()\n",
    "print(\"starting dictionaries at\", c)\n",
    "\n",
    "#### continue here on 10.07.2024\n",
    "\n",
    "## 1nd dictionary\n",
    "dfs_dict = {}  ### checked and changed on 01.06.2023\n",
    "dfs_dict_propag = {}\n",
    "\n",
    "\n",
    "wocgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "]\n",
    "wCgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"cancer_gene_census\",\n",
    "]\n",
    "\n",
    "datasource_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    #\"WOcgc\",\n",
    "    #\"wCgc\",\n",
    "    \"somatic\",\n",
    "    \"germline\",\n",
    "]\n",
    "\n",
    "germline_list = [\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "]\n",
    "\n",
    "somatic_list = [\"intogen\", \"cancer_gene_census\", \"eva_somatic\"]\n",
    "\n",
    "\n",
    "# assessment = prueba_assessment.filter(F.col(\"datasourceId\").isin(datasources_analysis))\n",
    "def dataset_builder(assessment_all, value, analysis_chembl, negativeTD, diseaseTA):\n",
    "    nonPropagated = full_analysis_noPropagation(\n",
    "        doe_columns,assessment_all, value, analysis_chembl, negativeTD, diseaseTA,diagonal_lof,diagonal_gof\n",
    "    )\n",
    "    propagated = full_analysis_propagation(\n",
    "        doe_columns,assessment_all, value, analysis_chembl, negativeTD, diseaseTA,diagonal_lof,diagonal_gof\n",
    "    )\n",
    "    return (\n",
    "        # Non propagation\n",
    "        ## All\n",
    "        nonPropagated,\n",
    "        ## Other\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        nonPropagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "        # Propagation\n",
    "        ## All\n",
    "        propagated,\n",
    "        ## Other\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        propagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "    )\n",
    "\n",
    "\n",
    "for value in datasource_list:\n",
    "    print(value)\n",
    "    if value == \"WOcgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wocgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"wCgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wCgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"germline\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            germline_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    elif value == \"somatic\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            somatic_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"]\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74187"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs_dict[f\"df_gwas_credible_set_All_original\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discrepancifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m analysis_chembl_indication \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdiscrepancifier\u001b[49m(\n\u001b[1;32m      3\u001b[0m         assessment\u001b[38;5;241m.\u001b[39mfilter((F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasourceId\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchembl\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxClinPhase\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m             F\u001b[38;5;241m.\u001b[39mmax(F\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclinicalPhase\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39mover(\n\u001b[1;32m      7\u001b[0m                 Window\u001b[38;5;241m.\u001b[39mpartitionBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargetId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiseaseId\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m             ),\n\u001b[1;32m      9\u001b[0m         )\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargetId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiseaseId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxClinPhase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;241m.\u001b[39mpivot(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhomogenized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;241m.\u001b[39magg(F\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargetId\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#.filter(F.col(\"coherencyDiagonal\") == \"coherent\")\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoherencyDiagonal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoherencyOneCell\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoEvaluable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoF_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoF_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrugGoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrugLoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# .persist()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     23\u001b[0m chemblAssoc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     24\u001b[0m     discrepancifier(\n\u001b[1;32m     25\u001b[0m         assessment\u001b[38;5;241m.\u001b[39mfilter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrugLoF_protect\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discrepancifier' is not defined"
     ]
    }
   ],
   "source": [
    "analysis_chembl_indication = (\n",
    "    discrepancifier(\n",
    "        assessment.filter((F.col(\"datasourceId\") == \"chembl\"))\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "    )\n",
    "    #.filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "chemblAssoc = (\n",
    "    discrepancifier(\n",
    "        assessment.filter(\n",
    "            (F.col(\"datasourceId\") == \"chembl\")\n",
    "            & (F.col(\"homogenized\") != \"noEvaluable\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(\"clinicalPhase\").over(Window.partitionBy(\"targetId\", \"diseaseId\")),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .count()\n",
    "    )\n",
    "    #.filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68692"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_chembl_indication.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+------+\n",
      "|maxClinPhase|coherent|dispar|\n",
      "+------------+--------+------+\n",
      "|         0.5|    1394|     2|\n",
      "|         1.0|   13919|    41|\n",
      "|         2.0|   30276|   327|\n",
      "|         3.0|   17865|   642|\n",
      "|         4.0|    5238|   375|\n",
      "+------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chemblAssoc.groupBy('maxClinPhase').pivot('coherencyDiagonal').count().sort(F.col('maxClinPhase').asc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chemblAssoc = (\n",
    "    discrepancifier(\n",
    "        assessment.filter(\n",
    "            (F.col(\"datasourceId\") == \"chembl\")\n",
    "            & (F.col(\"homogenized\") != \"noEvaluable\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(\"clinicalPhase\").over(Window.partitionBy(\"targetId\", \"diseaseId\")),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .count()\n",
    "    )\n",
    "    .filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark session created at 2025-06-28 09:10:26.510138\n",
      "Analysis started on 2025-06-28 at  2025-06-28 09:10:26.510138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 09:10:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files\n",
      "loaded newColoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gwasComplete\n",
      "loaded resolvedColloc\n",
      "run temporary direction of effect\n",
      "built drugApproved dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built chemblAssoc dataset\n",
      "load comparisons_df_iterative function\n",
      "created full_data and lists\n",
      "loaded rightTissue dataset\n",
      "built negativeTD dataset\n",
      "built bench2 dataset\n",
      "looping for variables_study\n",
      "built benchmark dataset\n",
      "Collecting combined distinct values from the cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final disdic: {'Sun_2018': 'projectId', 'van_de_Bunt_2015': 'projectId', 'Nedelec_2016': 'projectId', 'BrainSeq': 'projectId', 'GEUVADIS': 'projectId', 'Kim-Hellmuth_2017': 'projectId', 'GTEx': 'projectId', 'Schmiedel_2018': 'projectId', 'Lepik_2017': 'projectId', 'Bossini-Castillo_2019': 'projectId', 'Braineac2': 'projectId', 'TwinsUK': 'projectId', 'UKB_PPP_EUR': 'projectId', 'Alasoo_2018': 'projectId', 'FUSION': 'projectId', 'Cytoimmgen': 'projectId', 'CAP': 'projectId', 'Fairfax_2014': 'projectId', 'HipSci': 'projectId', 'Aygun_2021': 'projectId', 'Jerber_2021': 'projectId', 'CEDAR': 'projectId', 'Kasela_2017': 'projectId', 'BLUEPRINT': 'projectId', 'Steinberg_2020': 'projectId', 'Randolph_2021': 'projectId', 'Walker_2019': 'projectId', 'ROSMAP': 'projectId', 'Quach_2016': 'projectId', 'GENCORD': 'projectId', 'OneK1K': 'projectId', 'Nathan_2022': 'projectId', 'CommonMind': 'projectId', 'PISA': 'projectId', 'Naranbhai_2015': 'projectId', 'Fairfax_2012': 'projectId', 'PhLiPS': 'projectId', 'Peng_2018': 'projectId', 'Schwartzentruber_2018': 'projectId', 'iPSCORE': 'projectId', 'Gilchrist_2021': 'projectId', 'Perez_2022': 'projectId', 'Young_2019': 'projectId', 'CD4-positive, alpha-beta T cell': 'biosampleName', 'cerebellum': 'biosampleName', 'prostate gland': 'biosampleName', 'gastroesophageal sphincter': 'biosampleName', 'ascending aorta': 'biosampleName', 'transverse colon': 'biosampleName', 'induced pluripotent stem cell': 'biosampleName', 'adipose tissue': 'biosampleName', 'CD14-positive, CD16-negative classical monocyte': 'biosampleName', 'thyroid gland': 'biosampleName', 'macrophage': 'biosampleName', 'right lobe of liver': 'biosampleName', 'spleen': 'biosampleName', 'layer of synovial tissue': 'biosampleName', 'body of pancreas': 'biosampleName', 'floor plate': 'biosampleName', 'omental fat pad': 'biosampleName', 'tibial artery': 'biosampleName', 'naive regulatory T cell': 'biosampleName', 'skin of body': 'biosampleName', 'coronary artery': 'biosampleName', 'tibial nerve': 'biosampleName', 'sensory neuron': 'biosampleName', 'anterior lingual gland': 'biosampleName', 'lymphoblastoid cell line': 'biosampleName', 'sigmoid colon': 'biosampleName', 'breast epithelium': 'biosampleName', 'uterus': 'biosampleName', 'fibroblast': 'biosampleName', 'adrenal gland': 'biosampleName', 'blood': 'biosampleName', 'testis': 'biosampleName', 'skeletal muscle tissue': 'biosampleName', 'suprapubic skin': 'biosampleName', 'islet of Langerhans': 'biosampleName', 'substantia nigra': 'biosampleName', 'stomach': 'biosampleName', 'esophagus muscularis mucosa': 'biosampleName', 'memory regulatory T cell': 'biosampleName', 'vagina': 'biosampleName', 'dorsolateral prefrontal cortex': 'biosampleName', 'esophagus squamous epithelium': 'biosampleName', 'putamen': 'biosampleName', 'upper lobe of left lung': 'biosampleName', 'CD4-positive, alpha-beta memory T cell': 'biosampleName', 'natural killer cell': 'biosampleName', 'C1 segment of cervical spinal cord': 'biosampleName', 'frontal cortex': 'biosampleName', 'neutrophil': 'biosampleName', \"Peyer's patch\": 'biosampleName', 'blood plasma': 'biosampleName', 'nucleus accumbens': 'biosampleName', 'CD8-positive, alpha-beta T cell': 'biosampleName', 'pituitary gland': 'biosampleName', 'hepatocyte': 'biosampleName', 'platelet': 'biosampleName', 'serotonergic neuron': 'biosampleName', 'left ventricle myocardium': 'biosampleName', 'placenta': 'biosampleName', 'T-helper 17 cell': 'biosampleName', 'ovary': 'biosampleName', 'anterior cingulate cortex': 'biosampleName', 'cartilage tissue': 'biosampleName', 'hypothalamus': 'biosampleName', 'neocortex': 'biosampleName', 'right atrium auricular region': 'biosampleName', 'caudate nucleus': 'biosampleName', 'B cell': 'biosampleName', 'neuron': 'biosampleName', 'cortex of kidney': 'biosampleName', 'CD14-low, CD16-positive monocyte': 'biosampleName', 'T cell': 'biosampleName', 'CD16-negative, CD56-bright natural killer cell, human': 'biosampleName', 'T follicular helper cell': 'biosampleName', \"Ammon's horn\": 'biosampleName', 'effector memory CD8-positive, alpha-beta T cell': 'biosampleName', 'plasmacytoid dendritic cell': 'biosampleName', 'T-helper 1 cell': 'biosampleName', 'neural progenitor cell': 'biosampleName', 'ependymal cell': 'biosampleName', 'T-helper 2 cell': 'biosampleName', 'amygdala': 'biosampleName', 'rectum': 'biosampleName', 'double negative thymocyte': 'biosampleName', 'CD4-positive, alpha-beta cytotoxic T cell': 'biosampleName', 'dendritic cell': 'biosampleName', 'dopaminergic neuron': 'biosampleName', 'central memory CD4-positive, alpha-beta T cell': 'biosampleName', 'ileum': 'biosampleName', 'microglial cell': 'biosampleName', 'astrocyte': 'biosampleName', 'gamma-delta T cell': 'biosampleName', 'central memory CD8-positive, alpha-beta T cell': 'biosampleName', 'plasmablast': 'biosampleName', 'mucosal invariant T cell': 'biosampleName', 'effector memory CD4-positive, alpha-beta T cell': 'biosampleName', 'memory B cell': 'biosampleName', 'hematopoietic precursor cell': 'biosampleName', 'tuqtl': 'rightStudyType', 'sqtl': 'rightStudyType', 'eqtl': 'rightStudyType', 'sceqtl': 'rightStudyType', 'pqtl': 'rightStudyType', 'GoF_protect': 'colocDoE', 'LoF_protect': 'colocDoE', 'eCAVIAR': 'colocalisationMethod', 'COLOC': 'colocalisationMethod'}\n",
      "Pre-computing 'hasboth' column...\n",
      "Processing pivot for: projectId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: biosampleName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: rightStudyType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: colocDoE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: colocalisationMethod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting combined distinct values from the cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final disdic: {'Fairfax_2014': 'projectId', 'Walker_2019': 'projectId', 'GTEx': 'projectId', 'Schmiedel_2018': 'projectId', 'Jerber_2021': 'projectId', 'ROSMAP': 'projectId', 'TwinsUK': 'projectId', 'UKB_PPP_EUR': 'projectId', 'Alasoo_2018': 'projectId', 'Cytoimmgen': 'projectId', 'Quach_2016': 'projectId', 'GENCORD': 'projectId', 'GEUVADIS': 'projectId', 'OneK1K': 'projectId', 'Lepik_2017': 'projectId', 'Nathan_2022': 'projectId', 'BLUEPRINT': 'projectId', 'PhLiPS': 'projectId', 'HipSci': 'projectId', 'Nedelec_2016': 'projectId', 'Aygun_2021': 'projectId', 'Fairfax_2012': 'projectId', 'Peng_2018': 'projectId', 'CEDAR': 'projectId', 'FUSION': 'projectId', 'Young_2019': 'projectId', 'Schwartzentruber_2018': 'projectId', 'CommonMind': 'projectId', 'Kim-Hellmuth_2017': 'projectId', 'Kasela_2017': 'projectId', 'Sun_2018': 'projectId', 'van_de_Bunt_2015': 'projectId', 'BrainSeq': 'projectId', 'Bossini-Castillo_2019': 'projectId', 'Braineac2': 'projectId', 'CAP': 'projectId', 'Naranbhai_2015': 'projectId', 'Randolph_2021': 'projectId', 'iPSCORE': 'projectId', 'Steinberg_2020': 'projectId', 'PISA': 'projectId', 'Perez_2022': 'projectId', 'Gilchrist_2021': 'projectId', 'CD14-low, CD16-positive monocyte': 'biosampleName', 'skeletal muscle tissue': 'biosampleName', 'CD4-positive, alpha-beta T cell': 'biosampleName', 'cerebellum': 'biosampleName', 'tibial nerve': 'biosampleName', 'gastroesophageal sphincter': 'biosampleName', 'T-helper 17 cell': 'biosampleName', 'T cell': 'biosampleName', 'CD16-negative, CD56-bright natural killer cell, human': 'biosampleName', 'ascending aorta': 'biosampleName', 'islet of Langerhans': 'biosampleName', 'adipose tissue': 'biosampleName', 'blood plasma': 'biosampleName', 'CD14-positive, CD16-negative classical monocyte': 'biosampleName', 'natural killer cell': 'biosampleName', 'T follicular helper cell': 'biosampleName', 'ovary': 'biosampleName', 'fibroblast': 'biosampleName', 'right lobe of liver': 'biosampleName', 'vagina': 'biosampleName', 'dorsolateral prefrontal cortex': 'biosampleName', 'floor plate': 'biosampleName', 'esophagus squamous epithelium': 'biosampleName', 'neocortex': 'biosampleName', 'blood': 'biosampleName', 'testis': 'biosampleName', 'skin of body': 'biosampleName', 'coronary artery': 'biosampleName', 'prostate gland': 'biosampleName', 'neutrophil': 'biosampleName', \"Peyer's patch\": 'biosampleName', 'induced pluripotent stem cell': 'biosampleName', 'nucleus accumbens': 'biosampleName', 'lymphoblastoid cell line': 'biosampleName', 'stomach': 'biosampleName', 'breast epithelium': 'biosampleName', 'macrophage': 'biosampleName', 'spleen': 'biosampleName', 'CD8-positive, alpha-beta T cell': 'biosampleName', 'pituitary gland': 'biosampleName', 'hepatocyte': 'biosampleName', 'tibial artery': 'biosampleName', 'naive regulatory T cell': 'biosampleName', 'cartilage tissue': 'biosampleName', 'upper lobe of left lung': 'biosampleName', 'memory B cell': 'biosampleName', 'transverse colon': 'biosampleName', 'left ventricle myocardium': 'biosampleName', 'esophagus muscularis mucosa': 'biosampleName', 'cortex of kidney': 'biosampleName', 'adrenal gland': 'biosampleName', 'anterior cingulate cortex': 'biosampleName', 'putamen': 'biosampleName', 'amygdala': 'biosampleName', 'right atrium auricular region': 'biosampleName', 'T-helper 1 cell': 'biosampleName', 'uterus': 'biosampleName', 'sigmoid colon': 'biosampleName', 'thyroid gland': 'biosampleName', 'hypothalamus': 'biosampleName', 'layer of synovial tissue': 'biosampleName', 'body of pancreas': 'biosampleName', 'omental fat pad': 'biosampleName', 'sensory neuron': 'biosampleName', 'frontal cortex': 'biosampleName', 'platelet': 'biosampleName', 'serotonergic neuron': 'biosampleName', 'rectum': 'biosampleName', 'suprapubic skin': 'biosampleName', 'anterior lingual gland': 'biosampleName', 'substantia nigra': 'biosampleName', 'ileum': 'biosampleName', 'memory regulatory T cell': 'biosampleName', 'double negative thymocyte': 'biosampleName', \"Ammon's horn\": 'biosampleName', 'C1 segment of cervical spinal cord': 'biosampleName', 'placenta': 'biosampleName', 'B cell': 'biosampleName', 'T-helper 2 cell': 'biosampleName', 'neuron': 'biosampleName', 'caudate nucleus': 'biosampleName', 'CD4-positive, alpha-beta memory T cell': 'biosampleName', 'plasmacytoid dendritic cell': 'biosampleName', 'dopaminergic neuron': 'biosampleName', 'ependymal cell': 'biosampleName', 'neural progenitor cell': 'biosampleName', 'hematopoietic precursor cell': 'biosampleName', 'central memory CD8-positive, alpha-beta T cell': 'biosampleName', 'microglial cell': 'biosampleName', 'mucosal invariant T cell': 'biosampleName', 'dendritic cell': 'biosampleName', 'plasmablast': 'biosampleName', 'CD4-positive, alpha-beta cytotoxic T cell': 'biosampleName', 'astrocyte': 'biosampleName', 'central memory CD4-positive, alpha-beta T cell': 'biosampleName', 'effector memory CD8-positive, alpha-beta T cell': 'biosampleName', 'effector memory CD4-positive, alpha-beta T cell': 'biosampleName', 'gamma-delta T cell': 'biosampleName', 'tuqtl': 'rightStudyType', 'sqtl': 'rightStudyType', 'pqtl': 'rightStudyType', 'eqtl': 'rightStudyType', 'sceqtl': 'rightStudyType', 'GoF_protect': 'colocDoE', 'LoF_protect': 'colocDoE', 'eCAVIAR': 'colocalisationMethod', 'COLOC': 'colocalisationMethod'}\n",
      "Pre-computing 'hasboth' column...\n",
      "Processing pivot for: projectId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/28 09:19:58 WARN HeartbeatReceiver: Removing executor 8 with no recent heartbeats: 120014 ms exceeds timeout 120000 ms\n",
      "25/06/28 09:19:58 WARN HeartbeatReceiver: Removing executor 6 with no recent heartbeats: 122743 ms exceeds timeout 120000 ms\n",
      "25/06/28 09:19:58 WARN HeartbeatReceiver: Removing executor 9 with no recent heartbeats: 120149 ms exceeds timeout 120000 ms\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_268 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_252 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_338 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_321 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_306 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_320 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_18 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_336 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_138 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_77 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_80 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_67 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_135 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_42 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_374 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_189 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_2 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_152 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_252 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_294 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_375 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_77 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_18 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_171 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_209 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_69 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_240 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_380 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_69 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_193 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_85 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_374 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_343 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_74 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_58 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_209 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_374 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_398 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_336 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_133 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_266 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_65 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_380 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_200 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_85 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_189 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_338 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_249 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_112 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_81 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_67 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_322 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_321 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_321 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_171 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_294 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_322 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_266 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_189 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_10 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_249 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_58 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_286 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_34 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_76 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_193 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_257 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_16 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_234 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_133 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_152 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_50 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_136 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_124 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_34 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_343 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_306 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_58 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_229 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_375 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_348 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_96 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_10 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_257 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_42 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_398 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_50 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_104 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_249 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_234 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_144 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_113 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_193 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_34 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_42 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_379 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_320 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_130 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_164 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_359 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_371 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_26 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_40 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_398 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_164 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_294 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_105 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_371 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_85 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_75 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_48 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_380 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_96 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_348 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_24 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_138 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_187 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_152 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_2 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_56 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_144 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_81 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_133 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_268 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_209 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_288 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_164 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_187 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_10 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_50 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_359 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_229 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_252 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_229 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_200 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_375 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_322 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_65 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_0 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_286 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_71 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_77 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_69 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_371 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_257 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_73 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_135 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_200 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_286 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_144 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_306 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_187 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_336 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_71 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_379 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_171 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_124 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_65 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_338 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_2 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_288 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_320 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_379 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_67 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_153 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_268 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_343 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_26 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_153 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_81 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_102 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_138 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_240 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_135 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_124 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_240 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_359 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_8 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_348 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_120 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_153 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_288 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_26 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_266 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_166 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_234 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_32 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_71 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_18 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_96 !\n",
      "25/06/28 09:19:58 ERROR Inbox: Ignoring error\n",
      "java.lang.AssertionError: assertion failed: BlockManager re-registration shouldn't succeed when the executor is lost\n",
      "\tat scala.Predef$.assert(Predef.scala:223) ~[scala-library-2.12.18.jar:?]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:742) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:136) ~[spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41) [spark-core_2.12-3.5.3.jar:3.5.3]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829) [?:?]\n",
      "25/06/28 09:19:58 ERROR YarnScheduler: Lost executor 8 on jr-temp-m.c.open-targets-eu-dev.internal: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 47.0 in stage 364.0 (TID 18125) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 23.0 in stage 364.0 (TID 18101) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 7.0 in stage 364.0 (TID 18085) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 55.0 in stage 364.0 (TID 18133) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 31.0 in stage 364.0 (TID 18109) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 39.0 in stage 364.0 (TID 18117) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 15.0 in stage 364.0 (TID 18093) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 63.0 in stage 364.0 (TID 18141) (jr-temp-m.c.open-targets-eu-dev.internal executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120014 ms\n",
      "25/06/28 09:19:58 ERROR YarnScheduler: Lost executor 6 on jr-temp-m.c.open-targets-eu-dev.internal: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 12.0 in stage 364.0 (TID 18090) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 44.0 in stage 364.0 (TID 18122) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 20.0 in stage 364.0 (TID 18098) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 52.0 in stage 364.0 (TID 18130) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 28.0 in stage 364.0 (TID 18106) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 4.0 in stage 364.0 (TID 18082) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 60.0 in stage 364.0 (TID 18138) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 36.0 in stage 364.0 (TID 18114) (jr-temp-m.c.open-targets-eu-dev.internal executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 122743 ms\n",
      "25/06/28 09:19:58 ERROR YarnScheduler: Lost executor 9 on jr-temp-m.c.open-targets-eu-dev.internal: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 53.0 in stage 364.0 (TID 18131) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 29.0 in stage 364.0 (TID 18107) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 5.0 in stage 364.0 (TID 18083) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 61.0 in stage 364.0 (TID 18139) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 37.0 in stage 364.0 (TID 18115) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 13.0 in stage 364.0 (TID 18091) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 21.0 in stage 364.0 (TID 18099) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN TaskSetManager: Lost task 45.0 in stage 364.0 (TID 18123) (jr-temp-m.c.open-targets-eu-dev.internal executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 120149 ms\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_289 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_217 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_303 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_342 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_304 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_304 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_184 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_225 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_351 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_312 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_185 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_347 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_5 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_53 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_118 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_29 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_342 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_112 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_349 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_217 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_233 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_148 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_45 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_101 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_166 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_331 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_217 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_21 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_61 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_347 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_185 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_122 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_5 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_183 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_296 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_194 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_397 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_397 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_132 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_238 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_21 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_127 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_210 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_215 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_355 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_117 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_5 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_362 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_312 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_395 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_194 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_37 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_362 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_230 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_17 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_122 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_331 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_1 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_399 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_303 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_166 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_13 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_25 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_355 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_349 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_312 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_225 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_183 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_160 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_230 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_215 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_395 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_289 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_112 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_397 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_120 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_184 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_13 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_311 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_122 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_342 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_45 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_245 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_41 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_94 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_37 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_90 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_121 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_170 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_183 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_185 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_233 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_311 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_122 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_112 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_278 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_157 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_49 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_117 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_347 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_351 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_355 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_210 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_182 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_215 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_296 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_289 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_120 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_118 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_194 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_53 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_296 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_238 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_120 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_117 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_362 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_94 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_184 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_399 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_119 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_225 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_399 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_245 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_57 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_118 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_238 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_29 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_182 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_13 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_170 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_230 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_395 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_148 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_53 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_37 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_304 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_170 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_170 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_9 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_99 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_90 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_33 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_210 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_67 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_182 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_45 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_61 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_303 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_331 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_278 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_349 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_29 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_278 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_119 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_21 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_94 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_90 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_148 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_311 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_245 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_233 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_351 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_119 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_61 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_166 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_95 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_346 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_56 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_4 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_329 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_48 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_365 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_95 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_246 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_281 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_24 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_365 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_246 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_226 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_52 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_145 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_103 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_246 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_48 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_346 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_244 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_310 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_171 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_115 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_299 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_271 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_36 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_66 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_216 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_145 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_305 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_90 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_16 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_32 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_44 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_118 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_121 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_272 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_201 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_77 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_310 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_310 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_164 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_56 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_168 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_142 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_300 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_167 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_298 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_195 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_272 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_272 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_84 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_226 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_140 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_85 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_139 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_48 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_16 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_300 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_300 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_95 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_262 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_299 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_28 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_281 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_142 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_352 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_97 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_205 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_160 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_195 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_360 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_89 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_201 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_98 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_363 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_0 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_353 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_160 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_168 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_165 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_305 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_40 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_89 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_0 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_66 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_117 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_8 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_271 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_115 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_125 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_155 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_197 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_160 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_8 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_156 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_40 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_352 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_24 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_168 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_32 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_66 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_197 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_271 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_353 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_92 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_363 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_195 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_103 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_213 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_205 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_363 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_298 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_299 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_137 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_216 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_89 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_262 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_86 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_262 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_267 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_40 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_353 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_352 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_20 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_8 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_329 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_216 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_145 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_267 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_135 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_281 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_60 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_156 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_149 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_205 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_365 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_155 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_213 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_156 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_244 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_103 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_32 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_155 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_149 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_149 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_267 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_84 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_91 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_84 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_56 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_360 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_16 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_305 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_329 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_197 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_226 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_0 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_24 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_121 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_142 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_12 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_38_146 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_346 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_71_360 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_121 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_115 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_201 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_146_213 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_244 !\n",
      "25/06/28 09:19:58 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_152_298 !\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: biosampleName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: rightStudyType\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: colocDoE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pivot for: colocalisationMethod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    DecimalType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    ")\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.06/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "ecaviar=spark.read.parquet(f\"{path_n}colocalisation_ecaviar\")\n",
    "\n",
    "all_coloc=ecaviar.unionByName(new, allowMissingColumns=True)\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    all_coloc.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            \"pValueExponent as qtlPValueExponent\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .join(  ### propagated using parent terms\n",
    "            diseases.selectExpr(\n",
    "                \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "            ),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diseaseId\",\n",
    "            F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        )\n",
    "        .drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "\n",
    "datasource_filter = [\n",
    "#   \"ot_genetics_portal\",\n",
    "    \"gwas_credible_sets\",\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "\n",
    "print(\"built drugApproved dataset\")\n",
    "\n",
    "analysis_chembl_indication = (\n",
    "    discrepancifier(\n",
    "        assessment.filter((F.col(\"datasourceId\") == \"chembl\"))\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "    )\n",
    "    #.filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "chemblAssoc = (\n",
    "    discrepancifier(\n",
    "        assessment.filter(\n",
    "            (F.col(\"datasourceId\") == \"chembl\")\n",
    "            & (F.col(\"homogenized\") != \"noEvaluable\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(\"clinicalPhase\").over(Window.partitionBy(\"targetId\", \"diseaseId\")),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .count()\n",
    "    )\n",
    "    #.filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    ")\n",
    "\n",
    "print(\"built chemblAssoc dataset\")\n",
    "\n",
    "####2 Define agregation function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "def convertTuple(tup):\n",
    "    st = \",\".join(map(str, tup))\n",
    "    return st\n",
    "\n",
    "\n",
    "#####3 run in a function\n",
    "def aggregations_original(\n",
    "    df,\n",
    "    data,\n",
    "    listado,\n",
    "    comparisonColumn,\n",
    "    comparisonType,\n",
    "    predictionColumn,\n",
    "    predictionType,\n",
    "    today_date,\n",
    "):\n",
    "    wComparison = Window.partitionBy(comparisonColumn)\n",
    "    wPrediction = Window.partitionBy(predictionColumn)\n",
    "    wPredictionComparison = Window.partitionBy(comparisonColumn, predictionColumn)\n",
    "    results = []\n",
    "    # uniqIds = df.select(\"targetId\", \"diseaseId\").distinct().count()\n",
    "    out = (\n",
    "        df.withColumn(\"comparisonType\", F.lit(comparisonType))\n",
    "        .withColumn(\"dataset\", F.lit(data))\n",
    "        .withColumn(\"predictionType\", F.lit(predictionType))\n",
    "        # .withColumn(\"total\", F.lit(uniqIds))\n",
    "        .withColumn(\"a\", F.count(\"targetId\").over(wPredictionComparison))\n",
    "        .withColumn(\"comparisonColumn\", F.lit(comparisonColumn))\n",
    "        .withColumn(\"predictionColumnValue\", F.lit(predictionColumn))\n",
    "        .withColumn(\n",
    "            \"predictionTotal\",\n",
    "            F.count(\"targetId\").over(wPrediction),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"comparisonTotal\",\n",
    "            F.count(\"targetId\").over(wComparison),\n",
    "        )\n",
    "        .select(\n",
    "            F.col(predictionColumn).alias(\"prediction\"),\n",
    "            F.col(comparisonColumn).alias(\"comparison\"),\n",
    "            \"dataset\",\n",
    "            \"comparisonColumn\",\n",
    "            \"predictionColumnValue\",\n",
    "            \"comparisonType\",\n",
    "            \"predictionType\",\n",
    "            \"a\",\n",
    "            \"predictionTotal\",\n",
    "            \"comparisonTotal\",\n",
    "        )\n",
    "        .filter(F.col(\"prediction\").isNotNull())\n",
    "        .filter(F.col(\"comparison\").isNotNull())\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    out.write.mode(\"overwrite\").parquet(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + comparisonType\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    listado.append(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + comparisonType\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "    path = \"gs://ot-team/jroldan/\" + str(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + comparisonType\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    print(path)\n",
    "    \n",
    "    ### making analysis\n",
    "    array1 = np.delete(\n",
    "        out.join(full_data, on=[\"prediction\", \"comparison\"], how=\"outer\")\n",
    "        .groupBy(\"comparison\")\n",
    "        .pivot(\"prediction\")\n",
    "        .agg(F.first(\"a\"))\n",
    "        .sort(F.col(\"comparison\").desc())\n",
    "        .select(\"comparison\", \"yes\", \"no\")\n",
    "        .fillna(0)\n",
    "        .toPandas()\n",
    "        .to_numpy(),\n",
    "        [0],\n",
    "        1,\n",
    "    )\n",
    "    total = np.sum(array1)\n",
    "    res_npPhaseX = np.array(array1, dtype=int)\n",
    "    resX = convertTuple(fisher_exact(res_npPhaseX, alternative=\"two-sided\"))\n",
    "    resx_CI = convertTuple(\n",
    "        odds_ratio(res_npPhaseX).confidence_interval(confidence_level=0.95)\n",
    "    )\n",
    "\n",
    "    result_st.append(resX)\n",
    "    result_ci.append(resx_CI)\n",
    "    (rs_result, rs_ci) = relative_success(array1)\n",
    "    results.extend(\n",
    "        [\n",
    "            comparisonType,\n",
    "            comparisonColumn,\n",
    "            predictionColumn,\n",
    "            round(float(resX.split(\",\")[0]), 2),\n",
    "            float(resX.split(\",\")[1]),\n",
    "            round(float(resx_CI.split(\",\")[0]), 2),\n",
    "            round(float(resx_CI.split(\",\")[1]), 2),\n",
    "            str(total),\n",
    "            np.array(res_npPhaseX).tolist(),\n",
    "            round(float(rs_result), 2),\n",
    "            round(float(rs_ci[0]), 2),\n",
    "            round(float(rs_ci[1]), 2),\n",
    "            # studies,\n",
    "            # tissues,\n",
    "            path,\n",
    "        ]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "#### 3 Loop over different datasets (as they will have different rows and columns)\n",
    "\n",
    "\n",
    "def comparisons_df_iterative(elements):\n",
    "    # toAnalysis = [(key, value) for key, value in disdic.items() if value == projectId]\n",
    "    toAnalysis = [(col, \"predictor\") for col in elements]\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "            StructField(\"comparisonType\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    comparisons = spark.createDataFrame(toAnalysis, schema=schema)\n",
    "    ### include all the columns as predictor\n",
    "\n",
    "    predictions = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"Phase>=4\", \"clinical\"),\n",
    "            #('Phase>=3','clinical'),\n",
    "            #('Phase>=2','clinical'),\n",
    "            #('Phase>=1','clinical'),\n",
    "            #(\"PhaseT\", \"clinical\"),\n",
    "        ]\n",
    "    )\n",
    "    return comparisons.join(predictions, how=\"full\").collect()\n",
    "\n",
    "\n",
    "print(\"load comparisons_df_iterative function\")\n",
    "\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\"created full_data and lists\")\n",
    "\n",
    "#rightTissue = spark.read.csv(\n",
    "#    'gs://ot-team/jroldan/analysis/20250526_rightTissue.csv',\n",
    "#    header=True,\n",
    "#).drop(\"_c0\")\n",
    "\n",
    "print(\"loaded rightTissue dataset\")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "print(\"built negativeTD dataset\")\n",
    "\n",
    "print(\"built bench2 dataset\")\n",
    "\n",
    "###### cut from here\n",
    "print(\"looping for variables_study\")\n",
    "\n",
    "#### new part with chatgpt -- TEST\n",
    "\n",
    "## QUESTIONS TO ANSWER:\n",
    "# HAVE ECAVIAR >=0.8\n",
    "# HAVE COLOC \n",
    "# HAVE COLOC >= 0.8\n",
    "# HAVE COLOC + ECAVIAR >= 0.01\n",
    "# HAVE COLOC >= 0.8 + ECAVIAR >= 0.01\n",
    "# RIGHT JOING WITH CHEMBL \n",
    "\n",
    "resolvedColocFiltered = resolvedColoc.filter((F.col('clpp')>=0.01) | (F.col('h4')>=0.8))\n",
    "benchmark = (\n",
    "    (\n",
    "        resolvedColocFiltered.filter(F.col(\"betaGwas\") < 0).filter(\n",
    "        F.col(\"name\") != \"COVID-19\"\n",
    "    )\n",
    "        .join(  ### select just GWAS giving protection\n",
    "            analysis_chembl_indication, on=[\"targetId\", \"diseaseId\"], how=\"right\"  ### RIGHT SIDE\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AgreeDrug\",\n",
    "            F.when(\n",
    "                (F.col(\"drugGoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"GoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"drugLoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"LoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "    )  #### remove COVID-19 associations\n",
    ").join(biosample.select(\"biosampleId\", \"biosampleName\"), on=\"biosampleId\", how=\"left\")\n",
    "\n",
    "\n",
    "#### benchmark genetics\n",
    "benchmarkGenetics = (\n",
    "    (\n",
    "        resolvedColocFiltered.filter(F.col(\"betaGwas\") < 0).filter(\n",
    "        F.col(\"name\") != \"COVID-19\"\n",
    "    )\n",
    "        .join(  ### select just GWAS giving protection\n",
    "            analysis_chembl_indication, on=[\"targetId\", \"diseaseId\"], how=\"right\"  ### RIGHT SIDE\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasColoc\",\n",
    "            F.when(F.col(\"colocDoE\").isNotNull(), F.lit('yes')\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "    )  #### remove COVID-19 associations\n",
    ").join(biosample.select(\"biosampleId\", \"biosampleName\"), on=\"biosampleId\", how=\"left\")\n",
    "\n",
    "\n",
    "print(\"built benchmark dataset\")\n",
    "\n",
    "## write the benchmark \n",
    "#name='benchmark'\n",
    "#output_partitioned_path = f\"gs://ot-team/jroldan/analysis/parquetFiles/{name}\"\n",
    "#benchmark.write.mode(\"overwrite\").parquet(output_partitioned_path)\n",
    "#print(f'written {name}')\n",
    "#### Analysis\n",
    "\n",
    "#### 1 Build a dictionary with the distinct values as key and column names as value\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\",\"colocalisationMethod\"]\n",
    "\n",
    "# List to hold temporary DataFrames\n",
    "temp_dfs_for_union = []\n",
    "\n",
    "# Iterate over the column names to prepare DataFrames for union\n",
    "for col_name in variables_study:\n",
    "    # Select the current column, alias it to 'distinct_value' for consistent schema\n",
    "    # Filter out nulls, then get distinct values\n",
    "    # Add a literal column with the original 'col_name'\n",
    "    df_temp = (\n",
    "        benchmark.select(F.col(col_name).alias(\"distinct_value\"))\n",
    "        .filter(F.col(\"distinct_value\").isNotNull()) # Exclude None (null) values\n",
    "        .distinct()\n",
    "        .withColumn(\"column_name\", F.lit(col_name))\n",
    "    )\n",
    "    temp_dfs_for_union.append(df_temp)\n",
    "\n",
    "disdic = {}\n",
    "\n",
    "if temp_dfs_for_union:\n",
    "    # Union all the temporary DataFrames.\n",
    "    # unionByName is crucial to handle potential schema differences (e.g., if columns have same name but different types)\n",
    "    # and ensures columns are matched by name.\n",
    "    combined_distinct_values_df = temp_dfs_for_union[0]\n",
    "    for i in range(1, len(temp_dfs_for_union)):\n",
    "        combined_distinct_values_df = combined_distinct_values_df.unionByName(temp_dfs_for_union[i])\n",
    "\n",
    "    # Now, collect the combined distinct values.\n",
    "    # This is a single collect operation on the aggregated DataFrame.\n",
    "    print(\"Collecting combined distinct values from the cluster...\")\n",
    "    collected_rows = combined_distinct_values_df.collect()\n",
    "\n",
    "    # Populate the dictionary from the collected rows\n",
    "    for row in collected_rows:\n",
    "        disdic[row.distinct_value] = row.column_name\n",
    "else:\n",
    "    print(\"variables_study list is empty, disdic will be empty.\")\n",
    "\n",
    "\n",
    "print(\"\\nFinal disdic:\", disdic)\n",
    "\n",
    "# Assuming 'spark' session, 'benchmark' DataFrame, 'negativeTD' DataFrame, and 'disdic' dictionary are defined\n",
    "\n",
    "# --- Step 1: Pre-compute 'hasboth' ONCE ---\n",
    "# This is a shuffle, but only happens once.\n",
    "print(\"Pre-computing 'hasboth' column...\")\n",
    "window_target_disease_only = Window.partitionBy('targetId', 'diseaseId')\n",
    "benchmark_processed = benchmark.withColumn(\n",
    "    'hasboth',\n",
    "    F.size(F.collect_set('colocalisationMethod').over(window_target_disease_only))\n",
    ")\n",
    "\n",
    "# You might consider caching this intermediate result if 'benchmark' is very large\n",
    "# and you have enough memory, to avoid re-reading from source if possible.\n",
    "# benchmark_processed.cache() # or .persist(StorageLevel.MEMORY_AND_DISK)\n",
    "# benchmark_processed.count() # Force computation if you cache\n",
    "\n",
    "pivoted_dfs = {}\n",
    "\n",
    "# --- Step 2: Loop for each variable_study column ---\n",
    "for col_name in variables_study:\n",
    "    print(f\"Processing pivot for: {col_name}\")\n",
    "\n",
    "    # Define window specs for the current iteration, including 'col_name' in partition\n",
    "    # (This shuffle is still per iteration, but unavoidable if 'resolvedAgreeDrug' depends on 'col_name' values)\n",
    "    current_col_window_spec_qtl = Window.partitionBy(\"targetId\", \"diseaseId\", col_name).orderBy(F.col(\"qtlPValueExponent\").asc())\n",
    "    current_col_pvalue_order_window = Window.partitionBy(\"targetId\", \"diseaseId\", col_name).orderBy(F.col('colocalisationMethod').asc(), F.col(\"qtlPValueExponent\").asc())\n",
    "\n",
    "    # Calculate 'resolvedAgreeDrug' for the current 'col_name'\n",
    "    # This involves a shuffle per iteration.\n",
    "    temp_df_with_resolved = benchmark_processed.withColumn('resolvedAgreeDrug',\n",
    "        F.when(F.col('hasboth') > 1,\n",
    "            F.first(F.col('AgreeDrug'), ignorenulls=True).over(current_col_pvalue_order_window)\n",
    "        ).otherwise(F.first(F.col('AgreeDrug'), ignorenulls=True).over(current_col_window_spec_qtl))\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Perform the pivot and join ---\n",
    "    # This is an expensive operation (shuffle, potential wide dataframe)\n",
    "    pivoted_df = (\n",
    "        temp_df_with_resolved\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "            \"maxClinPhase\",\n",
    "        )\n",
    "        .pivot(col_name) # Pivoting on values of the 'col_name' column\n",
    "        .agg(F.collect_set(\"resolvedAgreeDrug\"))\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\") # Ensure negativeTD is broadcast if small\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Add derived columns (these are generally cheap) ---\n",
    "    for phase in [1, 2, 3, 4]:\n",
    "        pivoted_df = pivoted_df.withColumn(\n",
    "            f\"Phase>={phase}\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= phase, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "\n",
    "    pivoted_df = pivoted_df.withColumn(\n",
    "        \"PhaseT\",\n",
    "        F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "    )\n",
    "\n",
    "    # Add _only columns dynamically based on disdic values matching current column\n",
    "    matching_keys = [key for key, val in disdic.items() if val == col_name]\n",
    "\n",
    "    for key in matching_keys:\n",
    "        # F.col(key) assumes 'key' refers to a column that exists in pivoted_df after the pivot.\n",
    "        pivoted_df = pivoted_df.withColumn(\n",
    "            f\"{key}_only\",\n",
    "            F.when(F.array_contains(F.col(key), \"yes\"), F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "\n",
    "### making columns for the \n",
    "\n",
    "    # --- Step 5: Store result. Consider writing to GCS to break lineage if memory is an issue ---\n",
    "    # This is highly recommended if 'variables_study' is very large.\n",
    "    # Write to Parquet for efficient storage and schema preservation.\n",
    "    # output_path = f\"gs://your-bucket/temp_pivoted_results/{col_name}\"\n",
    "    # print(f\"Writing results for {col_name} to {output_path}\")\n",
    "    # pivoted_df.write.mode(\"overwrite\").parquet(output_path)\n",
    "    # pivoted_dfs[col_name] = spark.read.parquet(output_path) # Read back if needed later\n",
    "    # output_partitioned_path = f\"gs://ot-team/jroldan/analysis/parquetFiles/pivoted_df_{col_name}\"\n",
    "    # pivoted_df.write.mode(\"overwrite\").parquet(output_partitioned_path)\n",
    "    # print(f\"DataFrame successfully written and partitioned to {output_partitioned_path}\")\n",
    "    # If not writing to GCS, just store the DF in memory (be cautious for large number of DFs)\n",
    "\n",
    "    pivoted_dfs[col_name] = pivoted_df\n",
    "\n",
    "##### PROJECTID\n",
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']\n",
    "main=['GTEx_only', 'UKB_PPP_EUR_only']\n",
    "others=[item for item in project_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['projectId'] = pivoted_dfs['projectId'].withColumn(\"othersProjectId_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "##### BIOSAMPLE NAME\n",
    "biosample_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'biosampleName']\n",
    "main=['tibial nerve_only', 'upper lobe of left lung_only','blood plasma_only','lymphoblastoid cell line_only']\n",
    "others=[item for item in biosample_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['biosampleName'] = pivoted_dfs['biosampleName'].withColumn(\"othersBiosampleName_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "##### RIGHTSTUDYTYPE \n",
    "rightStudy_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'rightStudyType']\n",
    "main=['eqtl_only', 'pqtl_only']\n",
    "others=[item for item in rightStudy_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['rightStudyType'] = pivoted_dfs['rightStudyType'].withColumn(\"otherRightStudyType_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "###append to dictionary\n",
    "\n",
    "disdic.update({'othersProjectId': 'projectId', 'othersBiosampleName_only': 'biosampleName', 'otherRightStudyType':'rightStudyType'})\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting combined distinct values from the cluster...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final disdic: {'HipSci': 'projectId', 'GTEx': 'projectId', 'Schmiedel_2018': 'projectId', 'CEDAR': 'projectId', 'Nathan_2022': 'projectId', 'Quach_2016': 'projectId', 'CommonMind': 'projectId', 'GENCORD': 'projectId', 'Fairfax_2014': 'projectId', 'Aygun_2021': 'projectId', 'Kim-Hellmuth_2017': 'projectId', 'Jerber_2021': 'projectId', 'Kasela_2017': 'projectId', 'BLUEPRINT': 'projectId', 'Alasoo_2018': 'projectId', 'FUSION': 'projectId', 'Steinberg_2020': 'projectId', 'Cytoimmgen': 'projectId', 'Randolph_2021': 'projectId', 'Walker_2019': 'projectId', 'BrainSeq': 'projectId', 'OneK1K': 'projectId', 'Lepik_2017': 'projectId', 'ROSMAP': 'projectId', 'UKB_PPP_EUR': 'projectId', 'PhLiPS': 'projectId', 'Nedelec_2016': 'projectId', 'Fairfax_2012': 'projectId', 'TwinsUK': 'projectId', 'Sun_2018': 'projectId', 'GEUVADIS': 'projectId', 'Braineac2': 'projectId', 'Perez_2022': 'projectId', 'Bossini-Castillo_2019': 'projectId', 'Schwartzentruber_2018': 'projectId', 'iPSCORE': 'projectId', 'CAP': 'projectId', 'Naranbhai_2015': 'projectId', 'Peng_2018': 'projectId', 'van_de_Bunt_2015': 'projectId', 'Gilchrist_2021': 'projectId', 'Young_2019': 'projectId', 'PISA': 'projectId', 'skeletal muscle tissue': 'biosampleName', 'CD4-positive, alpha-beta T cell': 'biosampleName', 'cerebellum': 'biosampleName', 'suprapubic skin': 'biosampleName', 'tibial nerve': 'biosampleName', 'placenta': 'biosampleName', 'transverse colon': 'biosampleName', 'islet of Langerhans': 'biosampleName', 'induced pluripotent stem cell': 'biosampleName', 'adipose tissue': 'biosampleName', 'CD14-positive, CD16-negative classical monocyte': 'biosampleName', 'sigmoid colon': 'biosampleName', 'thyroid gland': 'biosampleName', 'macrophage': 'biosampleName', 'frontal cortex': 'biosampleName', 'fibroblast': 'biosampleName', 'spleen': 'biosampleName', 'esophagus muscularis mucosa': 'biosampleName', 'body of pancreas': 'biosampleName', 'pituitary gland': 'biosampleName', 'dorsolateral prefrontal cortex': 'biosampleName', 'omental fat pad': 'biosampleName', 'esophagus squamous epithelium': 'biosampleName', 'tibial artery': 'biosampleName', 'blood': 'biosampleName', 'effector memory CD4-positive, alpha-beta T cell': 'biosampleName', 'skin of body': 'biosampleName', 'upper lobe of left lung': 'biosampleName', 'gastroesophageal sphincter': 'biosampleName', 'right atrium auricular region': 'biosampleName', 'T follicular helper cell': 'biosampleName', 'layer of synovial tissue': 'biosampleName', 'CD8-positive, alpha-beta T cell': 'biosampleName', 'adrenal gland': 'biosampleName', 'naive regulatory T cell': 'biosampleName', 'putamen': 'biosampleName', 'testis': 'biosampleName', 'prostate gland': 'biosampleName', 'ascending aorta': 'biosampleName', 'substantia nigra': 'biosampleName', 'T-helper 1 cell': 'biosampleName', 'uterus': 'biosampleName', 'floor plate': 'biosampleName', 'cartilage tissue': 'biosampleName', 'T-helper 17 cell': 'biosampleName', 'neural progenitor cell': 'biosampleName', 'memory regulatory T cell': 'biosampleName', 'ependymal cell': 'biosampleName', 'CD14-low, CD16-positive monocyte': 'biosampleName', 'blood plasma': 'biosampleName', 'lymphoblastoid cell line': 'biosampleName', 'stomach': 'biosampleName', 'hypothalamus': 'biosampleName', 'right lobe of liver': 'biosampleName', 'coronary artery': 'biosampleName', 'sensory neuron': 'biosampleName', 'neutrophil': 'biosampleName', 'nucleus accumbens': 'biosampleName', 'platelet': 'biosampleName', 'serotonergic neuron': 'biosampleName', 'astrocyte': 'biosampleName', 'B cell': 'biosampleName', \"Ammon's horn\": 'biosampleName', 'anterior lingual gland': 'biosampleName', 'effector memory CD8-positive, alpha-beta T cell': 'biosampleName', 'natural killer cell': 'biosampleName', 'plasmacytoid dendritic cell': 'biosampleName', 'left ventricle myocardium': 'biosampleName', 'breast epithelium': 'biosampleName', 'ovary': 'biosampleName', 'double negative thymocyte': 'biosampleName', 'C1 segment of cervical spinal cord': 'biosampleName', 'T cell': 'biosampleName', 'CD4-positive, alpha-beta cytotoxic T cell': 'biosampleName', 'caudate nucleus': 'biosampleName', 'vagina': 'biosampleName', 'T-helper 2 cell': 'biosampleName', \"Peyer's patch\": 'biosampleName', 'amygdala': 'biosampleName', 'neuron': 'biosampleName', 'neocortex': 'biosampleName', 'anterior cingulate cortex': 'biosampleName', 'CD16-negative, CD56-bright natural killer cell, human': 'biosampleName', 'gamma-delta T cell': 'biosampleName', 'cortex of kidney': 'biosampleName', 'dopaminergic neuron': 'biosampleName', 'hepatocyte': 'biosampleName', 'CD4-positive, alpha-beta memory T cell': 'biosampleName', 'ileum': 'biosampleName', 'dendritic cell': 'biosampleName', 'central memory CD4-positive, alpha-beta T cell': 'biosampleName', 'rectum': 'biosampleName', 'plasmablast': 'biosampleName', 'microglial cell': 'biosampleName', 'memory B cell': 'biosampleName', 'hematopoietic precursor cell': 'biosampleName', 'central memory CD8-positive, alpha-beta T cell': 'biosampleName', 'mucosal invariant T cell': 'biosampleName', 'tuqtl': 'rightStudyType', 'sqtl': 'rightStudyType', 'eqtl': 'rightStudyType', 'sceqtl': 'rightStudyType', 'pqtl': 'rightStudyType', 'GoF_protect': 'colocDoE', 'LoF_protect': 'colocDoE', 'eCAVIAR': 'colocalisationMethod', 'COLOC': 'colocalisationMethod'}\n",
      "Pre-computing 'hasboth' column...\n",
      "Processing pivot for: projectId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 844:>                                                      (0 + 64) / 80]\r"
     ]
    }
   ],
   "source": [
    "########################################################################################################################################################\n",
    "################################################################### NOW BENCHMARK GENETICS #############################################################\n",
    "########################################################################################################################################################\n",
    "\n",
    "#### 1 Build a dictionary with the distinct values as key and column names as value\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\",\"colocalisationMethod\"]\n",
    "\n",
    "# List to hold temporary DataFrames\n",
    "temp_dfs_for_union = []\n",
    "\n",
    "# Iterate over the column names to prepare DataFrames for union\n",
    "for col_name in variables_study:\n",
    "    # Select the current column, alias it to 'distinct_value' for consistent schema\n",
    "    # Filter out nulls, then get distinct values\n",
    "    # Add a literal column with the original 'col_name'\n",
    "    df_temp = (\n",
    "        benchmarkGenetics.select(F.col(col_name).alias(\"distinct_value\"))\n",
    "        .filter(F.col(\"distinct_value\").isNotNull()) # Exclude None (null) values\n",
    "        .distinct()\n",
    "        .withColumn(\"column_name\", F.lit(col_name))\n",
    "    )\n",
    "    temp_dfs_for_union.append(df_temp)\n",
    "\n",
    "disdic = {}\n",
    "\n",
    "if temp_dfs_for_union:\n",
    "    # Union all the temporary DataFrames.\n",
    "    # unionByName is crucial to handle potential schema differences (e.g., if columns have same name but different types)\n",
    "    # and ensures columns are matched by name.\n",
    "    combined_distinct_values_df = temp_dfs_for_union[0]\n",
    "    for i in range(1, len(temp_dfs_for_union)):\n",
    "        combined_distinct_values_df = combined_distinct_values_df.unionByName(temp_dfs_for_union[i])\n",
    "\n",
    "    # Now, collect the combined distinct values.\n",
    "    # This is a single collect operation on the aggregated DataFrame.\n",
    "    print(\"Collecting combined distinct values from the cluster...\")\n",
    "    collected_rows = combined_distinct_values_df.collect()\n",
    "\n",
    "    # Populate the dictionary from the collected rows\n",
    "    for row in collected_rows:\n",
    "        disdic[row.distinct_value] = row.column_name\n",
    "else:\n",
    "    print(\"variables_study list is empty, disdic will be empty.\")\n",
    "\n",
    "\n",
    "print(\"\\nFinal disdic:\", disdic)\n",
    "\n",
    "# Assuming 'spark' session, 'benchmark' DataFrame, 'negativeTD' DataFrame, and 'disdic' dictionary are defined\n",
    "\n",
    "# --- Step 1: Pre-compute 'hasboth' ONCE ---\n",
    "# This is a shuffle, but only happens once.\n",
    "print(\"Pre-computing 'hasboth' column...\")\n",
    "window_target_disease_only = Window.partitionBy('targetId', 'diseaseId')\n",
    "benchmark_processed = benchmarkGenetics.withColumn(\n",
    "    'hasboth',\n",
    "    F.size(F.collect_set('colocalisationMethod').over(window_target_disease_only))\n",
    ")\n",
    "\n",
    "# You might consider caching this intermediate result if 'benchmark' is very large\n",
    "# and you have enough memory, to avoid re-reading from source if possible.\n",
    "# benchmark_processed.cache() # or .persist(StorageLevel.MEMORY_AND_DISK)\n",
    "# benchmark_processed.count() # Force computation if you cache\n",
    "\n",
    "pivoted_dfs = {}\n",
    "\n",
    "# --- Step 2: Loop for each variable_study column ---\n",
    "for col_name in variables_study:\n",
    "    print(f\"Processing pivot for: {col_name}\")\n",
    "\n",
    "    # Define window specs for the current iteration, including 'col_name' in partition\n",
    "    # (This shuffle is still per iteration, but unavoidable if 'resolvedAgreeDrug' depends on 'col_name' values)\n",
    "    current_col_window_spec_qtl = Window.partitionBy(\"targetId\", \"diseaseId\", col_name).orderBy(F.col(\"qtlPValueExponent\").asc())\n",
    "    current_col_pvalue_order_window = Window.partitionBy(\"targetId\", \"diseaseId\", col_name).orderBy(F.col('colocalisationMethod').asc(), F.col(\"qtlPValueExponent\").asc())\n",
    "\n",
    "    # Calculate 'resolvedAgreeDrug' for the current 'col_name'\n",
    "    # This involves a shuffle per iteration.\n",
    "    temp_df_with_resolved = benchmark_processed.withColumn('resolvedHasColoc',\n",
    "        F.when(F.col('hasboth') > 1,\n",
    "            F.first(F.col('hasColoc'), ignorenulls=True).over(current_col_pvalue_order_window)\n",
    "        ).otherwise(F.first(F.col('hasColoc'), ignorenulls=True).over(current_col_window_spec_qtl))\n",
    "    )\n",
    "\n",
    "    # --- Step 3: Perform the pivot and join ---\n",
    "    # This is an expensive operation (shuffle, potential wide dataframe)\n",
    "    pivoted_df = (\n",
    "        temp_df_with_resolved\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "            \"maxClinPhase\",\n",
    "        )\n",
    "        .pivot(col_name) # Pivoting on values of the 'col_name' column\n",
    "        .agg(F.collect_set(\"resolvedHasColoc\"))\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\") # Ensure negativeTD is broadcast if small\n",
    "    )\n",
    "\n",
    "    # --- Step 4: Add derived columns (these are generally cheap) ---\n",
    "    for phase in [1, 2, 3, 4]:\n",
    "        pivoted_df = pivoted_df.withColumn(\n",
    "            f\"Phase>={phase}\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= phase, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "\n",
    "    pivoted_df = pivoted_df.withColumn(\n",
    "        \"PhaseT\",\n",
    "        F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "    )\n",
    "\n",
    "    # Add _only columns dynamically based on disdic values matching current column\n",
    "    matching_keys = [key for key, val in disdic.items() if val == col_name]\n",
    "\n",
    "    for key in matching_keys:\n",
    "        # F.col(key) assumes 'key' refers to a column that exists in pivoted_df after the pivot.\n",
    "        pivoted_df = pivoted_df.withColumn(\n",
    "            f\"{key}_gen\",\n",
    "            F.when(F.array_contains(F.col(key), \"yes\"), F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "\n",
    "### making columns for the \n",
    "\n",
    "    # --- Step 5: Store result. Consider writing to GCS to break lineage if memory is an issue ---\n",
    "    # This is highly recommended if 'variables_study' is very large.\n",
    "    # Write to Parquet for efficient storage and schema preservation.\n",
    "    # output_path = f\"gs://your-bucket/temp_pivoted_results/{col_name}\"\n",
    "    # print(f\"Writing results for {col_name} to {output_path}\")\n",
    "    # pivoted_df.write.mode(\"overwrite\").parquet(output_path)\n",
    "    # pivoted_dfs[col_name] = spark.read.parquet(output_path) # Read back if needed later\n",
    "    # output_partitioned_path = f\"gs://ot-team/jroldan/analysis/parquetFiles/pivoted_df_{col_name}\"\n",
    "    # pivoted_df.write.mode(\"overwrite\").parquet(output_partitioned_path)\n",
    "    # print(f\"DataFrame successfully written and partitioned to {output_partitioned_path}\")\n",
    "    # If not writing to GCS, just store the DF in memory (be cautious for large number of DFs)\n",
    "\n",
    "    pivoted_dfs[f\"{col_name}_gen\"] = pivoted_df\n",
    "\n",
    "\n",
    "##### PROJECTID\n",
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']\n",
    "main=['GTEx_only', 'UKB_PPP_EUR_only']\n",
    "others=[item for item in project_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['projectId_gen'] = pivoted_dfs['projectId_gen'].withColumn(\"othersProjectId_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "##### BIOSAMPLE NAME\n",
    "biosample_keys=[f\"{k}_gen\" for k,v in disdic.items() if v == 'biosampleName']\n",
    "main=['tibial nerve_only', 'upper lobe of left lung_only','blood plasma_only','lymphoblastoid cell line_only']\n",
    "others=[item for item in biosample_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['biosampleName_gen'] = pivoted_dfs['biosampleName_gen'].withColumn(\"othersBiosampleName_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "##### RIGHTSTUDYTYPE \n",
    "rightStudy_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'rightStudyType']\n",
    "main=['eqtl_only', 'pqtl_only']\n",
    "others=[item for item in rightStudy_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['rightStudyType_gen'] = pivoted_dfs['rightStudyType_gen'].withColumn(\"othersRightStudyType_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "###append to dictionary\n",
    "\n",
    "disdic.update({'othersProjectId': 'projectId', 'othersBiosampleName': 'biosampleName', 'othersRightStudyType':'rightStudyType'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "disdic.update({'othersProjectId': 'projectId', 'othersBiosampleName_only': 'biosampleName', 'otherRightStudyType':'rightStudyType'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PROJECTID\n",
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']\n",
    "main=['GTEx_only', 'UKB_PPP_EUR_only']\n",
    "others=[item for item in project_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['projectId'] = pivoted_dfs['projectId'].withColumn(\"othersProjectId_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "##### BIOSAMPLE NAME\n",
    "biosample_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'biosampleName']\n",
    "main=['tibial nerve_only', 'upper lobe of left lung_only','blood plasma_only','lymphoblastoid cell line_only']\n",
    "others=[item for item in biosample_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['biosampleName'] = pivoted_dfs['biosampleName'].withColumn(\"othersBiosampleName_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "##### RIGHTSTUDYTYPE \n",
    "rightStudy_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'rightStudyType']\n",
    "main=['eqtl_only', 'pqtl_only']\n",
    "others=[item for item in rightStudy_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['rightStudyType'] = pivoted_dfs['rightStudyType'].withColumn(\"otherRightStudyType_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = benchmark.select('projectId').filter(F.col('projectId').isNotNull()).distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "len(pivoted_dfs['projectId'].drop(*unique_values).columns[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HipSci_only',\n",
       " 'van_de_Bunt_2015_only',\n",
       " 'GTEx_only',\n",
       " 'Lepik_2017_only',\n",
       " 'Bossini-Castillo_2019_only',\n",
       " 'ROSMAP_only',\n",
       " 'BLUEPRINT_only',\n",
       " 'TwinsUK_only',\n",
       " 'FUSION_only',\n",
       " 'Cytoimmgen_only',\n",
       " 'Gilchrist_2021_only',\n",
       " 'PhLiPS_only',\n",
       " 'BrainSeq_only',\n",
       " 'Schmiedel_2018_only',\n",
       " 'Jerber_2021_only',\n",
       " 'CEDAR_only',\n",
       " 'Alasoo_2018_only',\n",
       " 'Perez_2022_only',\n",
       " 'CommonMind_only',\n",
       " 'CAP_only',\n",
       " 'Nedelec_2016_only',\n",
       " 'Steinberg_2020_only',\n",
       " 'GEUVADIS_only',\n",
       " 'OneK1K_only',\n",
       " 'Nathan_2022_only',\n",
       " 'Quach_2016_only',\n",
       " 'Fairfax_2014_only',\n",
       " 'Fairfax_2012_only',\n",
       " 'Peng_2018_only',\n",
       " 'Aygun_2021_only',\n",
       " 'GENCORD_only',\n",
       " 'Walker_2019_only',\n",
       " 'Kasela_2017_only',\n",
       " 'iPSCORE_only',\n",
       " 'Young_2019_only',\n",
       " 'Schwartzentruber_2018_only',\n",
       " 'Kim-Hellmuth_2017_only',\n",
       " 'Naranbhai_2015_only',\n",
       " 'UKB_PPP_EUR_only',\n",
       " 'PISA_only',\n",
       " 'Randolph_2021_only',\n",
       " 'Sun_2018_only',\n",
       " 'Braineac2_only',\n",
       " 'others_only',\n",
       " 'othersProjectId_only']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_dfs['projectId'].drop(*unique_values).columns[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolvedColocFiltered = resolvedColoc.filter((F.col('clpp')>=0.01) | (F.col('h4')>=0.8))\n",
    "\n",
    "benchmark=(\n",
    "        resolvedColocFiltered.filter(F.col(\"betaGwas\") < 0).filter(\n",
    "        F.col(\"name\") != \"COVID-19\"\n",
    "    ).withColumn('hasGeneticData', F.lit('yes'))\n",
    "        .join(  ### select just GWAS giving protection\n",
    "            analysis_chembl_indication, on=[\"targetId\", \"diseaseId\"], how=\"right\"  ### RIGHT SIDE\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AgreeDrug\",\n",
    "            F.when(\n",
    "                (F.col(\"drugGoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"GoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"drugLoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"LoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .otherwise(F.lit(\"no\")),\n",
    "        ).withColumn('hasGeneticData', F.when(F.col('hasGeneticData')!='yes', F.lit('no')).otherwise(F.col('hasGeneticData')))\n",
    "    )  #### remove COVID-19 associations\n",
    "#).join(biosample.select(\"biosampleId\", \"biosampleName\"), on=\"biosampleId\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PROJECTID\n",
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']\n",
    "main=['GTEx_only', 'UKB_PPP_EUR_only']\n",
    "others=[item for item in project_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['projectId'] = pivoted_dfs['projectId'].withColumn(\"others_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "##### BIOSAMPLE NAME\n",
    "biosample_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'biosampleName']\n",
    "main=['tibial nerve_only', 'upper lobe of left lung_only','blood plasma_only','lymphoblastoid cell line_only']\n",
    "others=[item for item in biosample_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['biosampleName'] = pivoted_dfs['biosampleName'].withColumn(\"others_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n",
    "\n",
    "\n",
    "##### RIGHTSTUDYTYPE \n",
    "rightStudy_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'rightStudyType']\n",
    "main=['eqtl_only', 'pqtl_only']\n",
    "others=[item for item in rightStudy_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "# Add both columns\n",
    "pivoted_dfs['rightStudyType'] = pivoted_dfs['rightStudyType'].withColumn(\"others_only\", F.when(condition1, \"yes\").otherwise(\"no\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tibial nerve_only\n",
    "upper lobe of left lung_only\n",
    "blood plasma_only\n",
    "lymphoblastoid cell line_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'biosampleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rightStudyType_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'rightStudyType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fairfax_2014',\n",
       " 'van_de_Bunt_2015',\n",
       " 'HipSci',\n",
       " 'BrainSeq',\n",
       " 'OneK1K',\n",
       " 'GTEx',\n",
       " 'Schmiedel_2018',\n",
       " 'Lepik_2017',\n",
       " 'Peng_2018',\n",
       " 'Nathan_2022',\n",
       " 'TwinsUK',\n",
       " 'Alasoo_2018',\n",
       " 'Cytoimmgen',\n",
       " 'Quach_2016',\n",
       " 'CommonMind',\n",
       " 'Nedelec_2016',\n",
       " 'Kim-Hellmuth_2017',\n",
       " 'BLUEPRINT',\n",
       " 'UKB_PPP_EUR',\n",
       " 'FUSION',\n",
       " 'Naranbhai_2015',\n",
       " 'Bossini-Castillo_2019',\n",
       " 'ROSMAP',\n",
       " 'Randolph_2021',\n",
       " 'Aygun_2021',\n",
       " 'PISA',\n",
       " 'CEDAR',\n",
       " 'Steinberg_2020',\n",
       " 'Jerber_2021',\n",
       " 'Kasela_2017',\n",
       " 'iPSCORE',\n",
       " 'GENCORD',\n",
       " 'GEUVADIS',\n",
       " 'PhLiPS',\n",
       " 'CAP',\n",
       " 'Schwartzentruber_2018',\n",
       " 'Gilchrist_2021',\n",
       " 'Perez_2022',\n",
       " 'Fairfax_2012',\n",
       " 'Walker_2019',\n",
       " 'Braineac2',\n",
       " 'Sun_2018',\n",
       " 'Young_2019']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from functools import reduce\n",
    "\n",
    "project_keys=[f\"{k}_only\" for k,v in disdic.items() if v == 'projectId']\n",
    "main=['GTEx', 'UKB_PPP_EUR']\n",
    "others=[item for item in project_keys if item not in main]\n",
    "\n",
    "# First condition: any \"yes\" in list1\n",
    "condition1 = reduce(lambda acc, col: acc | (F.col(col) == \"yes\"), others[1:], F.col(others[0]) == \"yes\")\n",
    "\n",
    "# Second condition: any \"yes\" in list2\n",
    "\n",
    "# Add both columns\n",
    "pivoted_dfs['projectId'] = pivoted_dfs['projectId'].withColumn(\"others_only\", F.when(condition1, \"yes\").otherwise(\"no\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 503:=================================================>  (379 + 12) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|rightStudyType|count|\n",
      "+--------------+-----+\n",
      "|          NULL|73880|\n",
      "|          eqtl| 8812|\n",
      "|         tuqtl| 6341|\n",
      "|          sqtl| 1805|\n",
      "|        sceqtl|  279|\n",
      "|          pqtl|  601|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "benchmark.groupBy('rightStudyType').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.groupBy('targetId','diseaseId').pivot('rightStudyType')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 559:==================================================> (389 + 11) / 400]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+------------+-----+\n",
      "|rightStudyType|AgreeDrug|maxClinPhase|count|\n",
      "+--------------+---------+------------+-----+\n",
      "|          NULL|       no|         3.0|19342|\n",
      "|          NULL|       no|         1.0|14684|\n",
      "|          NULL|       no|         2.0|32282|\n",
      "|          NULL|       no|         4.0| 6155|\n",
      "|          NULL|       no|         0.5| 1417|\n",
      "|          eqtl|      yes|         3.0|  618|\n",
      "|          sqtl|       no|         4.0|  691|\n",
      "|          eqtl|       no|         3.0|  439|\n",
      "|          eqtl|      yes|         2.0|  682|\n",
      "|          eqtl|       no|         2.0| 1343|\n",
      "|         tuqtl|       no|         2.0|  724|\n",
      "|          sqtl|       no|         2.0|  433|\n",
      "|         tuqtl|      yes|         2.0| 1078|\n",
      "|          eqtl|      yes|         4.0| 2352|\n",
      "|          eqtl|       no|         4.0| 2065|\n",
      "|         tuqtl|      yes|         4.0| 2336|\n",
      "|         tuqtl|       no|         4.0|  615|\n",
      "|          eqtl|       no|         1.0|  810|\n",
      "|          pqtl|      yes|         3.0|   56|\n",
      "|          eqtl|      yes|         1.0|  480|\n",
      "+--------------+---------+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "benchmark.groupBy('rightStudyType','AgreeDrug', 'maxClinPhase').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".agg(F.collect_set(\"resolvedAgreeDrug\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 481:====================================================>  (83 + 4) / 87]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+------------+----+-----------+----------+---------+---------------------+--------+---------+---+-----+----------+----------+------+------------+------------+-------+--------+----+--------------+------+-----------+-----------+-----------------+----------+--------------+-----------+------------+------+----+---------+----------+------+----------+------+-------------+--------------+---------------------+--------------+--------+-------+-----------+-----------+----------+-------+----------------+----------+--------+--------+--------+--------+------+-----------------+---------------------+-----------+-------------+-----------+---------+-------------------+---------------+--------------+----------------+------------+----------------+---------------+---------------+---------------+-----------------+----------------------+--------------+----------------+-----------+-------------------+--------------------------+-----------+------------------+---------------+---------+----------+-------------------+----------------+----------------+------------+------------+-------------+-----------+--------+--------------------------+-------------------+---------------+-----------------+----------------+--------------+-------------+---------------+--------------+\n",
      "|       targetId|    diseaseId|maxClinPhase|null|Alasoo_2018|Aygun_2021|BLUEPRINT|Bossini-Castillo_2019|BrainSeq|Braineac2|CAP|CEDAR|CommonMind|Cytoimmgen|FUSION|Fairfax_2012|Fairfax_2014|GENCORD|GEUVADIS|GTEx|Gilchrist_2021|HipSci|Jerber_2021|Kasela_2017|Kim-Hellmuth_2017|Lepik_2017|Naranbhai_2015|Nathan_2022|Nedelec_2016|OneK1K|PISA|Peng_2018|Perez_2022|PhLiPS|Quach_2016|ROSMAP|Randolph_2021|Schmiedel_2018|Schwartzentruber_2018|Steinberg_2020|Sun_2018|TwinsUK|UKB_PPP_EUR|Walker_2019|Young_2019|iPSCORE|van_de_Bunt_2015|stopReason|Phase>=1|Phase>=2|Phase>=3|Phase>=4|PhaseT|Fairfax_2014_only|van_de_Bunt_2015_only|HipSci_only|BrainSeq_only|OneK1K_only|GTEx_only|Schmiedel_2018_only|Lepik_2017_only|Peng_2018_only|Nathan_2022_only|TwinsUK_only|Alasoo_2018_only|Cytoimmgen_only|Quach_2016_only|CommonMind_only|Nedelec_2016_only|Kim-Hellmuth_2017_only|BLUEPRINT_only|UKB_PPP_EUR_only|FUSION_only|Naranbhai_2015_only|Bossini-Castillo_2019_only|ROSMAP_only|Randolph_2021_only|Aygun_2021_only|PISA_only|CEDAR_only|Steinberg_2020_only|Jerber_2021_only|Kasela_2017_only|iPSCORE_only|GENCORD_only|GEUVADIS_only|PhLiPS_only|CAP_only|Schwartzentruber_2018_only|Gilchrist_2021_only|Perez_2022_only|Fairfax_2012_only|Walker_2019_only|Braineac2_only|Sun_2018_only|Young_2019_only|others_project|\n",
      "+---------------+-------------+------------+----+-----------+----------+---------+---------------------+--------+---------+---+-----+----------+----------+------+------------+------------+-------+--------+----+--------------+------+-----------+-----------+-----------------+----------+--------------+-----------+------------+------+----+---------+----------+------+----------+------+-------------+--------------+---------------------+--------------+--------+-------+-----------+-----------+----------+-------+----------------+----------+--------+--------+--------+--------+------+-----------------+---------------------+-----------+-------------+-----------+---------+-------------------+---------------+--------------+----------------+------------+----------------+---------------+---------------+---------------+-----------------+----------------------+--------------+----------------+-----------+-------------------+--------------------------+-----------+------------------+---------------+---------+----------+-------------------+----------------+----------------+------------+------------+-------------+-----------+--------+--------------------------+-------------------+---------------+-----------------+----------------+--------------+-------------+---------------+--------------+\n",
      "|ENSG00000007314|  EFO_0000555|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000007314|  EFO_1000249|         3.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000008018|  EFO_1000453|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000012504|MONDO_0019052|         4.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|     yes|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000012779|MONDO_0004235|         3.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|  Negative|     yes|     yes|     yes|      no|   yes|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000014138|  EFO_1001945|         3.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000023228|  EFO_1000657|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000062822|  EFO_0004991|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000065883|  EFO_0001378|         1.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|      no|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000067191|  EFO_0000319|         4.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|     yes|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000070886|  EFO_1000489|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|  Negative|     yes|     yes|      no|      no|   yes|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000077782|MONDO_0008315|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000080293|  EFO_0001073|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000081248|MONDO_0004992|         1.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|      no|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000082175|  EFO_1000796|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000082482|  EFO_1000637|         3.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000082556|  EFO_1000906|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000082556|MONDO_0004992|         2.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000087085|MONDO_0005301|         3.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|     yes|     yes|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "|ENSG00000087586|MONDO_0002516|         1.0|[no]|         []|        []|       []|                   []|      []|       []| []|   []|        []|        []|    []|          []|          []|     []|      []|  []|            []|    []|         []|         []|               []|        []|            []|         []|          []|    []|  []|       []|        []|    []|        []|    []|           []|            []|                   []|            []|      []|     []|         []|         []|        []|     []|              []|      NULL|     yes|      no|      no|      no|    no|               no|                   no|         no|           no|         no|       no|                 no|             no|            no|              no|          no|              no|             no|             no|             no|               no|                    no|            no|              no|         no|                 no|                        no|         no|                no|             no|       no|        no|                 no|              no|              no|          no|          no|           no|         no|      no|                        no|                 no|             no|               no|              no|            no|           no|             no|            no|\n",
      "+---------------+-------------+------------+----+-----------+----------+---------+---------------------+--------+---------+---+-----+----------+----------+------+------------+------------+-------+--------+----+--------------+------+-----------+-----------+-----------------+----------+--------------+-----------+------------+------+----+---------+----------+------+----------+------+-------------+--------------+---------------------+--------------+--------+-------+-----------+-----------+----------+-------+----------------+----------+--------+--------+--------+--------+------+-----------------+---------------------+-----------+-------------+-----------+---------+-------------------+---------------+--------------+----------------+------------+----------------+---------------+---------------+---------------+-----------------+----------------------+--------------+----------------+-----------+-------------------+--------------------------+-----------+------------------+---------------+---------+----------+-------------------+----------------+----------------+------------+------------+-------------+-----------+--------+--------------------------+-------------------+---------------+-----------------+----------------+--------------+-------------+---------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pivoted_dfs['projectId'].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
