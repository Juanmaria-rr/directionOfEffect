{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark session created at 2025-04-09 18:50:35.994060\n",
      "Analysis started on 2025-04-09 at  2025-04-09 18:50:35.994060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 18:50:40 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "#### 10.12.2024\n",
    "from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    DecimalType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"gs://open-targets-pre-data-releases/24.12-uo_test-3/output/etl/parquet/\"\n",
    "path_n='gs://open-targets-data-releases/25.03/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible = spark.read.parquet(f\"{path}credibleSet\")\n",
    "credible_n = spark.read.parquet(f\"{path_n}credible_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Common columns:\n",
      "['beta', 'chromosome', 'confidence', 'credibleSetIndex', 'credibleSetlog10BF', 'effectAlleleFrequencyFromSource', 'finemappingMethod', 'ldSet', 'locus', 'locusEnd', 'locusStart', 'pValueExponent', 'pValueMantissa', 'position', 'purityMeanR2', 'purityMinR2', 'qualityControls', 'region', 'sampleSize', 'standardError', 'studyId', 'studyLocusId', 'studyType', 'subStudyDescription', 'variantId', 'zScore']\n",
      "\n",
      "🟥 Columns only in credible:\n",
      "[]\n",
      "\n",
      "🟦 Columns only in credible_n:\n",
      "['isTransQtl']\n"
     ]
    }
   ],
   "source": [
    "# Get column names as sets\n",
    "cols_df1 = set(credible.columns)\n",
    "cols_df2 = set(credible_n.columns)\n",
    "\n",
    "# Compare\n",
    "common_cols = cols_df1 & cols_df2\n",
    "only_in_df1 = cols_df1 - cols_df2\n",
    "only_in_df2 = cols_df2 - cols_df1\n",
    "\n",
    "# Print results\n",
    "print(\"✅ Common columns:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n🟥 Columns only in credible:\")\n",
    "print(sorted(only_in_df1))\n",
    "\n",
    "print(\"\\n🟦 Columns only in credible_n:\")\n",
    "print(sorted(only_in_df2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Common columns:\n",
      "['betaRatioSignAverage', 'chromosome', 'colocalisationMethod', 'h0', 'h1', 'h2', 'h3', 'h4', 'leftStudyLocusId', 'numberColocalisingVariants', 'rightStudyLocusId', 'rightStudyType']\n",
      "\n",
      "🟥 Columns only in coloc:\n",
      "[]\n",
      "\n",
      "🟦 Columns only in coloc_n:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "coloc = spark.read.parquet(f\"{path}colocalisation/coloc\") ## new\n",
    "coloc_n = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "# Get column names as sets\n",
    "cols_df1 = set(coloc.columns)\n",
    "cols_df2 = set(coloc_n.columns)\n",
    "\n",
    "# Compare\n",
    "common_cols = cols_df1 & cols_df2\n",
    "only_in_df1 = cols_df1 - cols_df2\n",
    "only_in_df2 = cols_df2 - cols_df1\n",
    "\n",
    "# Print results\n",
    "print(\"✅ Common columns:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n🟥 Columns only in coloc:\")\n",
    "print(sorted(only_in_df1))\n",
    "\n",
    "print(\"\\n🟦 Columns only in coloc_n:\")\n",
    "print(sorted(only_in_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Common columns:\n",
      "['alleleFrequencies', 'alternateAllele', 'chromosome', 'dbXrefs', 'hgvsId', 'mostSevereConsequenceId', 'position', 'referenceAllele', 'rsIds', 'transcriptConsequences', 'variantDescription', 'variantId']\n",
      "\n",
      "🟥 Columns only in variantIndex:\n",
      "['inSilicoPredictors']\n",
      "\n",
      "🟦 Columns only in variantIndex_n:\n",
      "['variantEffect']\n"
     ]
    }
   ],
   "source": [
    "variantIndex = spark.read.parquet(f\"{path}variantIndex\")\n",
    "variantIndex_n = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "# Get column names as sets\n",
    "cols_df1 = set(variantIndex.columns)\n",
    "cols_df2 = set(variantIndex_n.columns)\n",
    "\n",
    "# Compare\n",
    "common_cols = cols_df1 & cols_df2\n",
    "only_in_df1 = cols_df1 - cols_df2\n",
    "only_in_df2 = cols_df2 - cols_df1\n",
    "\n",
    "# Print results\n",
    "print(\"✅ Common columns:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n🟥 Columns only in variantIndex:\")\n",
    "print(sorted(only_in_df1))\n",
    "\n",
    "print(\"\\n🟦 Columns only in variantIndex_n:\")\n",
    "print(sorted(only_in_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Common columns:\n",
      "['ancestors', 'biosampleId', 'biosampleName', 'children', 'descendants', 'description', 'parents', 'synonyms', 'xrefs']\n",
      "\n",
      "🟥 Columns only in biosample:\n",
      "[]\n",
      "\n",
      "🟦 Columns only in biosample_n:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "biosample = spark.read.parquet(f\"{path}biosample\")\n",
    "biosample_n = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "# Get column names as sets\n",
    "cols_df1 = set(biosample.columns)\n",
    "cols_df2 = set(biosample_n.columns)\n",
    "\n",
    "# Compare\n",
    "common_cols = cols_df1 & cols_df2\n",
    "only_in_df1 = cols_df1 - cols_df2\n",
    "only_in_df2 = cols_df2 - cols_df1\n",
    "\n",
    "# Print results\n",
    "print(\"✅ Common columns:\")\n",
    "print(sorted(common_cols))\n",
    "\n",
    "print(\"\\n🟥 Columns only in biosample:\")\n",
    "print(sorted(only_in_df1))\n",
    "\n",
    "print(\"\\n🟦 Columns only in biosample_n:\")\n",
    "print(sorted(only_in_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files\n",
      "loaded newColoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gwasComplete\n",
      "loaded resolvedColloc\n",
      "run temporary direction of effect\n",
      "built drugApproved dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "built chemblAssoc dataset\n"
     ]
    }
   ],
   "source": [
    "#### 10.12.2024\n",
    "import time\n",
    "from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    DecimalType,\n",
    "    StringType,\n",
    "    FloatType,\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.03/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    new.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .join(  ### propagated using parent terms\n",
    "            diseases.selectExpr(\n",
    "                \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "            ),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diseaseId\",\n",
    "            F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        )\n",
    "        .drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "\n",
    "path = \"gs://open-targets-pre-data-releases/24.12-uo_test-3/output/etl/parquet/\"\n",
    "\n",
    "datasource_filter = [\n",
    "    \"ot_genetics_portal\",\n",
    "    \"gwas_credible_sets\",\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "\n",
    "print(\"built drugApproved dataset\")\n",
    "\n",
    "analysis_chembl_indication = (\n",
    "    discrepancifier(\n",
    "        assessment.filter((F.col(\"datasourceId\") == \"chembl\"))\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "    )\n",
    "    .filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "chemblAssoc = (\n",
    "    discrepancifier(\n",
    "        assessment.filter(\n",
    "            (F.col(\"datasourceId\") == \"chembl\")\n",
    "            & (F.col(\"homogenized\") != \"noEvaluable\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(\"clinicalPhase\").over(Window.partitionBy(\"targetId\", \"diseaseId\")),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .count()\n",
    "    )\n",
    "    .filter(F.col(\"coherencyDiagonal\") == \"coherent\")\n",
    "    .drop(\n",
    "        \"coherencyDiagonal\", \"coherencyOneCell\", \"noEvaluable\", \"GoF_risk\", \"LoF_risk\"\n",
    "    )\n",
    "    .withColumnRenamed(\"GoF_protect\", \"drugGoF_protect\")\n",
    "    .withColumnRenamed(\"LoF_protect\", \"drugLoF_protect\")\n",
    ")\n",
    "\n",
    "print(\"built chemblAssoc dataset\")\n",
    "\n",
    "benchmark = (\n",
    "    (\n",
    "        resolvedColoc.filter(F.col(\"betaGwas\") < 0)\n",
    "        .join(  ### select just GWAS giving protection\n",
    "            analysis_chembl_indication, on=[\"targetId\", \"diseaseId\"], how=\"inner\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"AgreeDrug\",\n",
    "            F.when(\n",
    "                (F.col(\"drugGoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"GoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"drugLoF_protect\").isNotNull())\n",
    "                & (F.col(\"colocDoE\") == \"LoF_protect\"),\n",
    "                F.lit(\"yes\"),\n",
    "            )\n",
    "            .otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "    ).filter(\n",
    "        F.col(\"name\") != \"COVID-19\"\n",
    "    )  #### remove COVID-19 associations\n",
    ").join(biosample.select(\"biosampleId\", \"biosampleName\"), on=\"biosampleId\", how=\"left\")\n",
    "\n",
    "\n",
    "print(\"built benchmark dataset\")\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "#### 1 Build a dictionary with the distinct values as key and column names as value\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\"]\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "disdic = {}\n",
    "\n",
    "# Iterate over the list of column names\n",
    "for col_name in variables_study:\n",
    "    # Extract distinct values for the column\n",
    "    distinct_values = benchmark.select(col_name).distinct().collect()\n",
    "\n",
    "    # Populate the dictionary\n",
    "    for row in distinct_values:\n",
    "        distinct_value = row[col_name]\n",
    "        if distinct_value is not None:  # Exclude None (null) values\n",
    "            disdic[distinct_value] = col_name\n",
    "\n",
    "####2 Define agregation function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "def convertTuple(tup):\n",
    "    st = \",\".join(map(str, tup))\n",
    "    return st\n",
    "\n",
    "\n",
    "#####3 run in a function\n",
    "def aggregations_original(\n",
    "    df,\n",
    "    data,\n",
    "    listado,\n",
    "    comparisonColumn,\n",
    "    comparisonType,\n",
    "    predictionColumn,\n",
    "    predictionType,\n",
    "    today_date,\n",
    "):\n",
    "    wComparison = Window.partitionBy(comparisonColumn)\n",
    "    wPrediction = Window.partitionBy(predictionColumn)\n",
    "    wPredictionComparison = Window.partitionBy(comparisonColumn, predictionColumn)\n",
    "    results = []\n",
    "    # uniqIds = df.select(\"targetId\", \"diseaseId\").distinct().count()\n",
    "    out = (\n",
    "        df.withColumn(\"comparisonType\", F.lit(comparisonType))\n",
    "        .withColumn(\"dataset\", F.lit(data))\n",
    "        .withColumn(\"predictionType\", F.lit(predictionType))\n",
    "        # .withColumn(\"total\", F.lit(uniqIds))\n",
    "        .withColumn(\"a\", F.count(\"targetId\").over(wPredictionComparison))\n",
    "        .withColumn(\"comparisonColumn\", F.lit(comparisonColumn))\n",
    "        .withColumn(\"predictionColumnValue\", F.lit(predictionColumn))\n",
    "        .withColumn(\n",
    "            \"predictionTotal\",\n",
    "            F.count(\"targetId\").over(wPrediction),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"comparisonTotal\",\n",
    "            F.count(\"targetId\").over(wComparison),\n",
    "        )\n",
    "        .select(\n",
    "            F.col(predictionColumn).alias(\"prediction\"),\n",
    "            F.col(comparisonColumn).alias(\"comparison\"),\n",
    "            \"dataset\",\n",
    "            \"comparisonColumn\",\n",
    "            \"predictionColumnValue\",\n",
    "            \"comparisonType\",\n",
    "            \"predictionType\",\n",
    "            \"a\",\n",
    "            \"predictionTotal\",\n",
    "            \"comparisonTotal\",\n",
    "        )\n",
    "        .filter(F.col(\"prediction\").isNotNull())\n",
    "        .filter(F.col(\"comparison\").isNotNull())\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    out.write.mode(\"overwrite\").parquet(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + comparisonType\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    listado.append(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + comparisonType\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "    path = \"gs://ot-team/jroldan/\" + str(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + comparisonType\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    print(path)\n",
    "    \n",
    "    ### making analysis\n",
    "    array1 = np.delete(\n",
    "        out.join(full_data, on=[\"prediction\", \"comparison\"], how=\"outer\")\n",
    "        .groupBy(\"comparison\")\n",
    "        .pivot(\"prediction\")\n",
    "        .agg(F.first(\"a\"))\n",
    "        .sort(F.col(\"comparison\").desc())\n",
    "        .select(\"comparison\", \"yes\", \"no\")\n",
    "        .fillna(0)\n",
    "        .toPandas()\n",
    "        .to_numpy(),\n",
    "        [0],\n",
    "        1,\n",
    "    )\n",
    "    total = np.sum(array1)\n",
    "    res_npPhaseX = np.array(array1, dtype=int)\n",
    "    resX = convertTuple(fisher_exact(res_npPhaseX, alternative=\"two-sided\"))\n",
    "    resx_CI = convertTuple(\n",
    "        odds_ratio(res_npPhaseX).confidence_interval(confidence_level=0.95)\n",
    "    )\n",
    "\n",
    "    result_st.append(resX)\n",
    "    result_ci.append(resx_CI)\n",
    "    (rs_result, rs_ci) = relative_success(array1)\n",
    "    results.extend(\n",
    "        [\n",
    "            comparisonType,\n",
    "            comparisonColumn,\n",
    "            predictionColumn,\n",
    "            round(float(resX.split(\",\")[0]), 2),\n",
    "            float(resX.split(\",\")[1]),\n",
    "            round(float(resx_CI.split(\",\")[0]), 2),\n",
    "            round(float(resx_CI.split(\",\")[1]), 2),\n",
    "            str(total),\n",
    "            np.array(res_npPhaseX).tolist(),\n",
    "            round(float(rs_result), 2),\n",
    "            round(float(rs_ci[0]), 2),\n",
    "            round(float(rs_ci[1]), 2),\n",
    "            # studies,\n",
    "            # tissues,\n",
    "            path,\n",
    "        ]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "#### 3 Loop over different datasets (as they will have different rows and columns)\n",
    "\n",
    "\n",
    "def comparisons_df_iterative(elements):\n",
    "    # toAnalysis = [(key, value) for key, value in disdic.items() if value == projectId]\n",
    "    toAnalysis = [(col, \"predictor\") for col in elements]\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "            StructField(\"comparisonType\", StringType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    comparisons = spark.createDataFrame(toAnalysis, schema=schema)\n",
    "    ### include all the columns as predictor\n",
    "\n",
    "    predictions = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"Phase4\", \"clinical\"),\n",
    "            #('Phase>=3','clinical'),\n",
    "            #('Phase>=2','clinical'),\n",
    "            #('Phase>=1','clinical'),\n",
    "            #(\"PhaseT\", \"clinical\"),\n",
    "        ]\n",
    "    )\n",
    "    return comparisons.join(predictions, how=\"full\").collect()\n",
    "\n",
    "\n",
    "print(\"load comparisons_df_iterative function\")\n",
    "\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\"created full_data and lists\")\n",
    "\n",
    "rightTissue = spark.read.csv(\n",
    "    'gs://ot-team/jroldan/analysis/20250402_rightTissueListMarchRelease.csv',\n",
    "    header=True,\n",
    ").drop(\"_c0\")\n",
    "\n",
    "print(\"loaded rightTissue dataset\")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "print(\"built negativeTD dataset\")\n",
    "\n",
    "bench2 = benchmark.join(\n",
    "    rightTissue, on=[\"name\", \"bioSampleName\"], how=\"left\"\n",
    ").withColumn(\n",
    "    \"rightTissue\",\n",
    "    F.when(F.col(\"rightTissue1\") == \"yes\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    ")\n",
    "\n",
    "print(\"built bench2 dataset\")\n",
    "\n",
    "###### cut from here\n",
    "print(\"looping for variables_study\")\n",
    "# List of columns to analyze\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\"]\n",
    "\n",
    "# Dictionary to store results\n",
    "pivoted_dfs = {}\n",
    "\n",
    "# Loop over the columns\n",
    "for col in variables_study:\n",
    "    window_spec = Window.partitionBy(\"targetId\", \"diseaseId\", col).orderBy(\n",
    "        F.col(\"pValueExponent\").asc()\n",
    "    )\n",
    "    print(f\"Processing: {col}\")\n",
    "\n",
    "    pivoted_df = (\n",
    "        bench2.withColumn(\n",
    "            \"rightTissue\",\n",
    "            F.when(F.col(\"rightTissue1\") == \"yes\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"agree_lowestPval\",\n",
    "            F.first(\"AgreeDrug\", ignorenulls=True).over(\n",
    "                window_spec\n",
    "            ),  ### ignore nulls aded 29.01.2025\n",
    "            #### take directionality from lowest p value\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"isRightTissueSignalAgreed\",\n",
    "            F.collect_set(\n",
    "                F.when(F.col(\"rightTissue\") == \"yes\", F.col(\"agree_lowestPval\"))\n",
    "            ).over(window_spec),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"isSignalFromRightTissue\",\n",
    "            F.first(\n",
    "                F.when(\n",
    "                    F.col(\"AgreeDrug\") == F.col(\"agree_lowestPval\"),\n",
    "                    F.col(\"rightTissue\"),\n",
    "                ),\n",
    "                ignorenulls=True,\n",
    "            ).over(window_spec),\n",
    "        )\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "            \"maxClinPhase\",\n",
    "            \"rightTissue\",\n",
    "            \"isRightTissueSignalAgreed\",\n",
    "            \"isSignalFromRightTissue\",\n",
    "        )\n",
    "        .pivot(col)  # Pivot the column dynamically\n",
    "        .agg(F.collect_set(\"agree_lowestPval\"))\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(\n",
    "                F.lit(\"no\")\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .select(\n",
    "            [\"*\"]\n",
    "            + (\n",
    "                [  ### single columns\n",
    "                    F.when(F.array_contains(F.col(x), \"yes\"), F.lit(\"yes\"))\n",
    "                    .otherwise(F.lit(\"no\"))\n",
    "                    .alias(f\"{x}_only\")\n",
    "                    for x, value in [\n",
    "                        (key, val) for key, val in disdic.items() if val == col\n",
    "                    ]\n",
    "                ]\n",
    "            )\n",
    "            + (\n",
    "                [\n",
    "                    F.when(\n",
    "                        F.array_contains(F.col(\"isRightTissueSignalAgreed\"), \"yes\"),\n",
    "                        F.lit(\"yes\"),\n",
    "                    )\n",
    "                    .otherwise(F.lit(\"no\"))\n",
    "                    .alias(f\"{x}_isRightTissueSignalAgreed\")\n",
    "                    for x, value in [\n",
    "                        (key, val) for key, val in disdic.items() if val == col\n",
    "                    ]\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )  # Collect unique values\n",
    "\n",
    "    # Store the DataFrame in the dictionary\n",
    "    pivoted_dfs[col] = pivoted_df\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Duration for 1 iteration\n",
    "duration = end_time - start_time\n",
    "print(f\"⏱️ Time for one iteration: {duration:.2f} seconds\")\n",
    "\n",
    "result = []\n",
    "result_st = []\n",
    "result_ci = []\n",
    "array2 = []\n",
    "listado = []\n",
    "result_all = []\n",
    "today_date = str(date.today())\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\"]\n",
    "\n",
    "##### PROJECT ID ###### \n",
    "print('working with projectId')\n",
    "pivoted_dfs['projectId'].persist()\n",
    "unique_values = benchmark.select('projectId').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['projectId'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['projectId'].columns[-filter:])\n",
    "\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['projectId'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['projectId'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "\n",
    "pivoted_dfs['projectId'].unpersist()\n",
    "print('df unpersisted')\n",
    "\n",
    "##### BIOSAMPLE NAME ###### \n",
    "print('working with biosampleName')\n",
    "pivoted_dfs['biosampleName'].persist()\n",
    "unique_values = benchmark.select('biosampleName').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['biosampleName'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['biosampleName'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['biosampleName'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['biosampleName'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "\n",
    "pivoted_dfs['biosampleName'].unpersist()\n",
    "print('df unpersisted')\n",
    "\n",
    "##### RIGHTSTUDYTYPE  ###### \n",
    "print('working with rightStudyType')\n",
    "pivoted_dfs['rightStudyType'].persist()\n",
    "unique_values = benchmark.select('rightStudyType').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['rightStudyType'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['rightStudyType'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['rightStudyType'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['rightStudyType'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "    pivoted_dfs['rightStudyType'].unpersist()\n",
    "    print('df unpersisted')\n",
    "\n",
    "##### COLOC DOE ######\n",
    "print('working with colocDoE')\n",
    "pivoted_dfs['colocDoE'].persist()\n",
    "unique_values = benchmark.select('colocDoE').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['colocDoE'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['colocDoE'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['colocDoE'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['colocDoE'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "    pivoted_dfs['colocDoE'].unpersist()\n",
    "    print('df unpersisted')\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"group\", StringType(), True),\n",
    "        StructField(\"comparison\", StringType(), True),\n",
    "        StructField(\"phase\", StringType(), True),\n",
    "        StructField(\"oddsRatio\", DoubleType(), True),\n",
    "        StructField(\"pValue\", DoubleType(), True),\n",
    "        StructField(\"lowerInterval\", DoubleType(), True),\n",
    "        StructField(\"upperInterval\", DoubleType(), True),\n",
    "        StructField(\"total\", StringType(), True),\n",
    "        StructField(\"values\", ArrayType(ArrayType(IntegerType())), True),\n",
    "        StructField(\"relSuccess\", DoubleType(), True),\n",
    "        StructField(\"rsLower\", DoubleType(), True),\n",
    "        StructField(\"rsUpper\", DoubleType(), True),\n",
    "        StructField(\"path\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "import re\n",
    "\n",
    "# Define the list of patterns to search for\n",
    "patterns = [\n",
    "    \"_only\",\n",
    "    #\"_tissue\",\n",
    "    #\"_isSignalFromRightTissue\",\n",
    "    \"_isRightTissueSignalAgreed\",\n",
    "]\n",
    "# Create a regex pattern to match any of the substrings\n",
    "regex_pattern = \"(\" + \"|\".join(map(re.escape, patterns)) + \")\"\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "df = (\n",
    "    spreadSheetFormatter(spark.createDataFrame(result_all, schema=schema))\n",
    "    .withColumn(\n",
    "        \"prefix\",\n",
    "        F.regexp_replace(\n",
    "            F.col(\"comparison\"), regex_pattern + \".*\", \"\"\n",
    "        ),  # Extract part before the pattern\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"suffix\",\n",
    "        F.regexp_extract(\n",
    "            F.col(\"comparison\"), regex_pattern, 0\n",
    "        ),  # Extract the pattern itself\n",
    "    )\n",
    ")\n",
    "\n",
    "df.toPandas().to_csv(\n",
    "    f\"gs://ot-team/jroldan/analysis/{today_date}_credibleSetColocDoEanalysis_RightTissues.csv\"\n",
    ")\n",
    "\n",
    "print(\"dataframe written \\n Analysis finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱️ Time for one iteration: 0.00 seconds\n",
      "working with projectId\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 19:13:42 WARN CacheManager: Asked to cache already cached data.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  78 columns to analyse with phases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/HipSci_only_predictor_Phase4.parquet\n",
      "⏱️ Time for first iteration: 4.52 seconds\n",
      "⏳ Estimated total time for 78 iterations: 5.87 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/GTEx_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Schmiedel_2018_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/PISA_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Bossini-Castillo_2019_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/TwinsUK_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/GENCORD_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/CAP_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Nedelec_2016_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/UKB_PPP_EUR_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/BrainSeq_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/BLUEPRINT_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/FUSION_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Quach_2016_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/CommonMind_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Lepik_2017_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Cytoimmgen_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Aygun_2021_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Jerber_2021_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/ROSMAP_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Walker_2019_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Schwartzentruber_2018_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Alasoo_2018_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/PhLiPS_only_predictor_Phase4.parquet\n",
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/Gilchrist_2021_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ot-team/jroldan/2025-04-09_analysis/propagated/GEUVADIS_only_predictor_Phase4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/miniconda3/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# If needed, now process the rest\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 51\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43maggregations_original\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpivoted_dfs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprojectId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpropagated\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlistado\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoday_date\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     result_all\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     56\u001b[0m pivoted_dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprojectId\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munpersist()\n",
      "Cell \u001b[0;32mIn[14], line 144\u001b[0m, in \u001b[0;36maggregations_original\u001b[0;34m(df, data, listado, comparisonColumn, comparisonType, predictionColumn, predictionType, today_date)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(path)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m### making analysis\u001b[39;00m\n\u001b[1;32m    136\u001b[0m array1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(\n\u001b[1;32m    137\u001b[0m     \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mouter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpivot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomparison\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43myes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 144\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;241m.\u001b[39mto_numpy(),\n\u001b[1;32m    146\u001b[0m     [\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    149\u001b[0m total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(array1)\n\u001b[1;32m    150\u001b[0m res_npPhaseX \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(array1, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/pandas/conversion.py:202\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Below is toPandas without Arrow optimization.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rows) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    204\u001b[0m     pdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(\n\u001b[1;32m    205\u001b[0m         rows, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows)), columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/dataframe.py:1263\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns all the records as a list of :class:`Row`.\u001b[39;00m\n\u001b[1;32m   1244\u001b[0m \n\u001b[1;32m   1245\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[38;5;124;03m[Row(age=14, name='Tom'), Row(age=23, name='Alice'), Row(age=16, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SCCallSiteSync(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sc):\n\u001b[0;32m-> 1263\u001b[0m     sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollectToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.base/java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.base/java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:474)\n",
      "\tat java.base/java.net.ServerSocket.implAccept(ServerSocket.java:565)\n",
      "\tat java.base/java.net.ServerSocket.accept(ServerSocket.java:533)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n"
     ]
    }
   ],
   "source": [
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Duration for 1 iteration\n",
    "duration = end_time - start_time\n",
    "print(f\"⏱️ Time for one iteration: {duration:.2f} seconds\")\n",
    "\n",
    "result = []\n",
    "result_st = []\n",
    "result_ci = []\n",
    "array2 = []\n",
    "listado = []\n",
    "result_all = []\n",
    "today_date = str(date.today())\n",
    "variables_study = [\"projectId\", \"biosampleName\", \"rightStudyType\", \"colocDoE\"]\n",
    "\n",
    "##### PROJECT ID ###### \n",
    "print('working with projectId')\n",
    "pivoted_dfs['projectId'].persist()\n",
    "unique_values = benchmark.select('projectId').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['projectId'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['projectId'].columns[-filter:])\n",
    "\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['projectId'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['projectId'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "\n",
    "pivoted_dfs['projectId'].unpersist()\n",
    "print('df unpersisted')\n",
    "\n",
    "##### BIOSAMPLE NAME ###### \n",
    "print('working with biosampleName')\n",
    "pivoted_dfs['biosampleName'].persist()\n",
    "unique_values = benchmark.select('biosampleName').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['biosampleName'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['biosampleName'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['biosampleName'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['biosampleName'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "\n",
    "pivoted_dfs['biosampleName'].unpersist()\n",
    "print('df unpersisted')\n",
    "\n",
    "##### RIGHTSTUDYTYPE  ###### \n",
    "print('working with rightStudyType')\n",
    "pivoted_dfs['rightStudyType'].persist()\n",
    "unique_values = benchmark.select('rightStudyType').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['rightStudyType'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['rightStudyType'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['rightStudyType'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['rightStudyType'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "    pivoted_dfs['rightStudyType'].unpersist()\n",
    "    print('df unpersisted')\n",
    "\n",
    "##### COLOC DOE ######\n",
    "print('working with colocDoE')\n",
    "pivoted_dfs['colocDoE'].persist()\n",
    "unique_values = benchmark.select('colocDoE').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "filter = len(pivoted_dfs['colocDoE'].drop(*unique_values).columns[12:])\n",
    "print('There are ', filter, 'columns to analyse with phases')\n",
    "rows = comparisons_df_iterative(pivoted_dfs['colocDoE'].columns[-filter:])\n",
    "# Run the first row only to estimate timing\n",
    "first_row = rows[0]\n",
    "start_time = time.time()\n",
    "\n",
    "result = aggregations_original(\n",
    "    pivoted_dfs['colocDoE'], \"propagated\", listado, *first_row, today_date\n",
    ")\n",
    "result_all = [result]  # initialize with first result\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "estimated_total = duration * len(rows)\n",
    "\n",
    "print(f\"⏱️ Time for first iteration: {duration:.2f} seconds\")\n",
    "print(f\"⏳ Estimated total time for {len(rows)} iterations: {estimated_total/60:.2f} minutes\")\n",
    "\n",
    "# If needed, now process the rest\n",
    "for row in rows[1:]:\n",
    "    results = aggregations_original(\n",
    "        pivoted_dfs['colocDoE'], \"propagated\", listado, *row, today_date\n",
    "    )\n",
    "    result_all.append(results)\n",
    "    pivoted_dfs['colocDoE'].unpersist()\n",
    "    print('df unpersisted')\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"group\", StringType(), True),\n",
    "        StructField(\"comparison\", StringType(), True),\n",
    "        StructField(\"phase\", StringType(), True),\n",
    "        StructField(\"oddsRatio\", DoubleType(), True),\n",
    "        StructField(\"pValue\", DoubleType(), True),\n",
    "        StructField(\"lowerInterval\", DoubleType(), True),\n",
    "        StructField(\"upperInterval\", DoubleType(), True),\n",
    "        StructField(\"total\", StringType(), True),\n",
    "        StructField(\"values\", ArrayType(ArrayType(IntegerType())), True),\n",
    "        StructField(\"relSuccess\", DoubleType(), True),\n",
    "        StructField(\"rsLower\", DoubleType(), True),\n",
    "        StructField(\"rsUpper\", DoubleType(), True),\n",
    "        StructField(\"path\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "import re\n",
    "\n",
    "# Define the list of patterns to search for\n",
    "patterns = [\n",
    "    \"_only\",\n",
    "    #\"_tissue\",\n",
    "    #\"_isSignalFromRightTissue\",\n",
    "    \"_isRightTissueSignalAgreed\",\n",
    "]\n",
    "# Create a regex pattern to match any of the substrings\n",
    "regex_pattern = \"(\" + \"|\".join(map(re.escape, patterns)) + \")\"\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "df = (\n",
    "    spreadSheetFormatter(spark.createDataFrame(result_all, schema=schema))\n",
    "    .withColumn(\n",
    "        \"prefix\",\n",
    "        F.regexp_replace(\n",
    "            F.col(\"comparison\"), regex_pattern + \".*\", \"\"\n",
    "        ),  # Extract part before the pattern\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"suffix\",\n",
    "        F.regexp_extract(\n",
    "            F.col(\"comparison\"), regex_pattern, 0\n",
    "        ),  # Extract the pattern itself\n",
    "    )\n",
    ")\n",
    "\n",
    "df.toPandas().to_csv(\n",
    "    f\"gs://ot-team/jroldan/analysis/{today_date}_credibleSetColocDoEanalysis_RightTissues.csv\"\n",
    ")\n",
    "\n",
    "print(\"dataframe written \\n Analysis finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing functions\n",
      "imported functions\n",
      "dataframe written \n",
      " Analysis finished\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------+---------+-------------------+-------------+-------------+-----+--------------------+----------+-------+-------+--------------------+-----------+------------------+-------+-------+-------+-------+---------+-----------+----------------+------+--------------------+------+\n",
      "|    group|          comparison| phase|oddsRatio|             pValue|lowerInterval|upperInterval|total|              values|relSuccess|rsLower|rsUpper|                path|significant|       writeFigure|value_1|value_2|value_3|value_4|numerator|denominator|pValue_formatted|numDen|              prefix|suffix|\n",
      "+---------+--------------------+------+---------+-------------------+-------------+-------------+-----+--------------------+----------+-------+-------+--------------------+-----------+------------------+-------+-------+-------+-------+---------+-----------+----------------+------+--------------------+------+\n",
      "|predictor|         HipSci_only|Phase4|     0.73| 0.7431251135000856|         0.12|         3.49|  291|[[3, 6], [115, 167]]|      0.82|   0.32|   2.08|gs://ot-team/jrol...|         ns|  0.73 (0.12-3.49)|      3|      6|    115|    167|        9|        282|          0.7431| 9/282|              HipSci| _only|\n",
      "|predictor|           GTEx_only|Phase4|     0.69|0.19633675954707785|          0.4|         1.19|  291|[[31, 59], [87, 1...|       0.8|   0.57|    1.1|gs://ot-team/jrol...|         ns|   0.69 (0.4-1.19)|     31|     59|     87|    114|       90|        201|          0.1963|90/201|                GTEx| _only|\n",
      "|predictor| Schmiedel_2018_only|Phase4|     2.51|0.27663189103839825|         0.48|        16.41|  291|[[5, 3], [113, 170]]|      1.57|    0.9|   2.73|gs://ot-team/jrol...|         ns| 2.51 (0.48-16.41)|      5|      3|    113|    170|        8|        283|          0.2766| 8/283|      Schmiedel_2018| _only|\n",
      "|predictor|           PISA_only|Phase4|      NaN|                1.0|          0.0|     Infinity|  291|[[0, 0], [118, 173]]|       0.0|    0.0|    NaN|gs://ot-team/jrol...|         ns|NaN (0.0-Infinity)|      0|      0|    118|    173|        0|        291|          1.0000| 0/291|                PISA| _only|\n",
      "|predictor|Bossini-Castillo_...|Phase4|     0.73|                1.0|         0.01|         14.2|  291|[[1, 2], [117, 171]]|      0.82|   0.16|   4.09|gs://ot-team/jrol...|         ns|  0.73 (0.01-14.2)|      1|      2|    117|    171|        3|        288|          1.0000| 3/288|Bossini-Castillo_...| _only|\n",
      "|predictor|        TwinsUK_only|Phase4|     0.58| 0.2820577691852638|          0.2|         1.53|  291|[[7, 17], [111, 1...|       0.7|   0.37|   1.33|gs://ot-team/jrol...|         ns|   0.58 (0.2-1.53)|      7|     17|    111|    156|       24|        267|          0.2821|24/267|             TwinsUK| _only|\n",
      "|predictor|        GENCORD_only|Phase4|      3.0| 0.2270937560334598|         0.42|        33.55|  291|[[4, 2], [114, 171]]|      1.67|   0.93|   2.99|gs://ot-team/jrol...|         ns|  3.0 (0.42-33.55)|      4|      2|    114|    171|        6|        285|          0.2271| 6/285|             GENCORD| _only|\n",
      "|predictor|            CAP_only|Phase4|     1.47|                1.0|         0.02|       116.06|  291|[[1, 1], [117, 172]]|      1.24|   0.31|   4.97|gs://ot-team/jrol...|         ns|1.47 (0.02-116.06)|      1|      1|    117|    172|        2|        289|          1.0000| 2/289|                 CAP| _only|\n",
      "|predictor|   Nedelec_2016_only|Phase4|     2.97| 0.5680942534475993|         0.15|       175.95|  291|[[2, 1], [116, 172]]|      1.66|   0.73|   3.73|gs://ot-team/jrol...|         ns|2.97 (0.15-175.95)|      2|      1|    116|    172|        3|        288|          0.5681| 3/288|        Nedelec_2016| _only|\n",
      "|predictor|    UKB_PPP_EUR_only|Phase4|     1.76|0.14615489891198802|         0.82|         3.79|  291|[[19, 17], [99, 1...|      1.36|   0.96|   1.92|gs://ot-team/jrol...|         ns|  1.76 (0.82-3.79)|     19|     17|     99|    156|       36|        255|          0.1462|36/255|         UKB_PPP_EUR| _only|\n",
      "|predictor|       BrainSeq_only|Phase4|     0.54|0.32540735094375545|         0.15|         1.69|  291|[[5, 13], [113, 1...|      0.67|   0.31|   1.43|gs://ot-team/jrol...|         ns|  0.54 (0.15-1.69)|      5|     13|    113|    160|       18|        273|          0.3254|18/273|            BrainSeq| _only|\n",
      "|predictor|      BLUEPRINT_only|Phase4|     0.67|  0.420011878262168|         0.26|         1.63|  291|[[9, 19], [109, 1...|      0.78|   0.44|   1.35|gs://ot-team/jrol...|         ns|  0.67 (0.26-1.63)|      9|     19|    109|    154|       28|        263|          0.4200|28/263|           BLUEPRINT| _only|\n",
      "|predictor|         FUSION_only|Phase4|      0.7| 0.3827043564848223|         0.32|         1.49|  291|[[13, 26], [105, ...|       0.8|    0.5|   1.28|gs://ot-team/jrol...|         ns|   0.7 (0.32-1.49)|     13|     26|    105|    147|       39|        252|          0.3827|39/252|              FUSION| _only|\n",
      "|predictor|     Quach_2016_only|Phase4|     0.73| 0.7431251135000856|         0.12|         3.49|  291|[[3, 6], [115, 167]]|      0.82|   0.32|   2.08|gs://ot-team/jrol...|         ns|  0.73 (0.12-3.49)|      3|      6|    115|    167|        9|        282|          0.7431| 9/282|          Quach_2016| _only|\n",
      "|predictor|     CommonMind_only|Phase4|     0.98|                1.0|         0.08|         8.67|  291|[[2, 3], [116, 170]]|      0.99|   0.33|   2.91|gs://ot-team/jrol...|         ns|  0.98 (0.08-8.67)|      2|      3|    116|    170|        5|        286|          1.0000| 5/286|          CommonMind| _only|\n",
      "|predictor|     Lepik_2017_only|Phase4|     1.48| 0.7190508487749729|         0.27|         8.12|  291|[[4, 4], [114, 169]]|      1.24|   0.61|   2.52|gs://ot-team/jrol...|         ns|  1.48 (0.27-8.12)|      4|      4|    114|    169|        8|        283|          0.7191| 8/283|          Lepik_2017| _only|\n",
      "|predictor|     Cytoimmgen_only|Phase4|     3.78|0.12390848162713683|          0.6|        40.19|  291|[[5, 2], [113, 171]]|       1.8|    1.1|   2.93|gs://ot-team/jrol...|         ns|  3.78 (0.6-40.19)|      5|      2|    113|    171|        7|        284|          0.1239| 7/284|          Cytoimmgen| _only|\n",
      "|predictor|     Aygun_2021_only|Phase4|      NaN|                1.0|          0.0|     Infinity|  291|[[0, 0], [118, 173]]|       0.0|    0.0|    NaN|gs://ot-team/jrol...|         ns|NaN (0.0-Infinity)|      0|      0|    118|    173|        0|        291|          1.0000| 0/291|          Aygun_2021| _only|\n",
      "|predictor|    Jerber_2021_only|Phase4|     1.47|                1.0|         0.11|        20.57|  291|[[2, 2], [116, 171]]|      1.24|   0.46|   3.33|gs://ot-team/jrol...|         ns| 1.47 (0.11-20.57)|      2|      2|    116|    171|        4|        287|          1.0000| 4/287|         Jerber_2021| _only|\n",
      "|predictor|         ROSMAP_only|Phase4|     2.23| 0.3983542917871248|         0.25|        27.02|  291|[[3, 2], [115, 171]]|      1.49|   0.72|   3.09|gs://ot-team/jrol...|         ns| 2.23 (0.25-27.02)|      3|      2|    115|    171|        5|        286|          0.3984| 5/286|              ROSMAP| _only|\n",
      "+---------+--------------------+------+---------+-------------------+-------------+-------------+-----+--------------------+----------+-------+-------+--------------------+-----------+------------------+-------+-------+-------+-------+---------+-----------+----------------+------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### There are no transQtl when making the inner join with GWAS dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+---------------+-------------------+-------------------------+-------------------+------------------+-----------+--------------------+-------------------+------------------+-------+---------+----+--------------+\n",
      "|        studyLocusId|      datasourceId|       targetId|         datatypeId|diseaseFromSourceMappedId|      resourceScore|targetFromSourceId|  diseaseId|                  id|              score|          sourceId|studyId|variantId|beta|pValueExponent|\n",
      "+--------------------+------------------+---------------+-------------------+-------------------------+-------------------+------------------+-----------+--------------------+-------------------+------------------+-------+---------+----+--------------+\n",
      "|d4f28571f811989b8...|gwas_credible_sets|ENSG00000137656|genetic_association|              EFO_0008317|0.09631703101468457|   ENSG00000137656|EFO_0008317|000d16708fe49cb93...|0.09631703101468457|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|6a7fe17b1f421e6ca...|gwas_credible_sets|ENSG00000141431|genetic_association|              EFO_0004340| 0.7353553935116451|   ENSG00000141431|EFO_0004340|000ed03f6a84c95e8...| 0.7353553935116451|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|3626ebbca561173a0...|gwas_credible_sets|ENSG00000138085|genetic_association|              EFO_0010815| 0.7246087654502219|   ENSG00000138085|EFO_0010815|00151b8d19af930f5...| 0.7246087654502219|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|a63db3f01e38ebc5f...|gwas_credible_sets|ENSG00000249481|genetic_association|              EFO_0003923| 0.4344990910066717|   ENSG00000249481|EFO_0003923|0018f802e91e2ba00...| 0.4344990910066717|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|133bd867b4fc61f98...|gwas_credible_sets|ENSG00000164109|genetic_association|              EFO_0004346| 0.5824511365998359|   ENSG00000164109|EFO_0004346|00283a1715738f856...| 0.5824511365998359|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|2185fefb2d67d3b83...|gwas_credible_sets|ENSG00000174243|genetic_association|              EFO_0004348| 0.3871477037405501|   ENSG00000174243|EFO_0004348|0028805efc406356d...| 0.3871477037405501|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|38be872ec8a61bd23...|gwas_credible_sets|ENSG00000111540|genetic_association|              EFO_0003907|0.11796255658946271|   ENSG00000111540|EFO_0003907|00299fd01461188a1...|0.11796255658946271|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|89e14c2c95c123ecf...|gwas_credible_sets|ENSG00000172995|genetic_association|              EFO_0009589| 0.9508546879742953|   ENSG00000172995|EFO_0009589|0032a6bf045b52cc4...| 0.9508546879742953|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|b4b5fc6131f299cc6...|gwas_credible_sets|ENSG00000104866|genetic_association|              EFO_0004615|0.09037735867435333|   ENSG00000104866|EFO_0004615|0035d21c579babbe3...|0.09037735867435333|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|3edd157ed605c2686...|gwas_credible_sets|ENSG00000095951|genetic_association|              EFO_0005093| 0.8837346665579783|   ENSG00000095951|EFO_0005093|005c461194999d9f2...| 0.8837346665579783|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|6627149c0a2408c06...|gwas_credible_sets|ENSG00000174165|genetic_association|              EFO_0004574|0.14885321606750065|   ENSG00000174165|EFO_0004574|005f2b676dc612bec...|0.14885321606750065|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|e3ed881cdf866b86d...|gwas_credible_sets|ENSG00000183454|genetic_association|              EFO_0007052| 0.8246003100560496|   ENSG00000183454|EFO_0007052|00668aa6af3c85c68...| 0.8246003100560496|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|6f77bebda88988420...|gwas_credible_sets|ENSG00000135211|genetic_association|              EFO_0009795| 0.1451937503541286|   ENSG00000135211|EFO_0009795|00685041179b53cbe...| 0.1451937503541286|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|fa3f7d650a7e0959a...|gwas_credible_sets|ENSG00000151806|genetic_association|              EFO_0004458| 0.4336422397284331|   ENSG00000151806|EFO_0004458|0073a0382feb6f3b7...| 0.4336422397284331|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|c0827623efd09bd81...|gwas_credible_sets|ENSG00000198336|genetic_association|              EFO_0004611|0.21912923060540604|   ENSG00000198336|EFO_0004611|00775407c6f4917fd...|0.21912923060540604|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|dfb6295640601f594...|gwas_credible_sets|ENSG00000126266|genetic_association|              EFO_0004568| 0.4119740101327209|   ENSG00000126266|EFO_0004568|007a9bea306400717...| 0.4119740101327209|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|55682154e00b6122c...|gwas_credible_sets|ENSG00000126246|genetic_association|              EFO_0004346| 0.2003912610842887|   ENSG00000126246|EFO_0004346|007c40fbe478b5f94...| 0.2003912610842887|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|bd12a96e92a69886f...|gwas_credible_sets|ENSG00000189114|genetic_association|              EFO_0020946|0.25683128908807096|   ENSG00000189114|EFO_0020946|008a7200894c1baff...|0.25683128908807096|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|3e6b338ef983c5464...|gwas_credible_sets|ENSG00000115216|genetic_association|              EFO_0008317| 0.1355325914669477|   ENSG00000115216|EFO_0008317|00911e56a55625ffe...| 0.1355325914669477|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "|da22129dc12c21773...|gwas_credible_sets|ENSG00000120088|genetic_association|              EFO_0004641| 0.0777053843689139|   ENSG00000120088|EFO_0004641|0094267c111410b84...| 0.0777053843689139|gwas_credible_sets|   NULL|     NULL|NULL|          NULL|\n",
      "+--------------------+------------------+---------------+-------------------+-------------------------+-------------------+------------------+-----------+--------------------+-------------------+------------------+-------+---------+----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evidences.filter(F.col('datasourceId')=='gwas_credible_sets').select(*gwasComplete.columns).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['studyLocusId',\n",
       " 'datasourceId',\n",
       " 'targetId',\n",
       " 'datatypeId',\n",
       " 'diseaseFromSourceMappedId',\n",
       " 'resourceScore',\n",
       " 'targetFromSourceId',\n",
       " 'diseaseId',\n",
       " 'id',\n",
       " 'score',\n",
       " 'sourceId',\n",
       " 'studyId',\n",
       " 'variantId',\n",
       " 'betaGwas',\n",
       " 'pValueExponent']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gwasComplete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------+------------+----------------+----------+--------------+--------------------------+---+---+---+---+---+--------------------+--------------------+-----------+-------------+---------------------+--------------+----------------------+----------+---------+--------------+---------+-----------+------------+----------+-------------------------+-------------+------------------+---------+---+-----+--------+-------+---------+----+--------------+\n",
      "|rightStudyLocusId|targetId|rightStudyId|leftStudyLocusId|chromosome|rightStudyType|numberColocalisingVariants| h0| h1| h2| h3| h4|colocalisationMethod|betaRatioSignAverage|leftStudyId|leftVariantId|credibleLeftStudyType|rightVariantId|credibleRightStudyType|isTransQtl|projectId|indexStudyType|condition|biosampleId|datasourceId|datatypeId|diseaseFromSourceMappedId|resourceScore|targetFromSourceId|diseaseId| id|score|sourceId|studyId|variantId|beta|pValueExponent|\n",
      "+-----------------+--------+------------+----------------+----------+--------------+--------------------------+---+---+---+---+---+--------------------+--------------------+-----------+-------------+---------------------+--------------+----------------------+----------+---------+--------------+---------+-----------+------------+----------+-------------------------+-------------+------------------+---------+---+-----+--------+-------+---------+----+--------------+\n",
      "+-----------------+--------+------------+----------------+----------+--------------+--------------------------+---+---+---+---+---+--------------------+--------------------+-----------+-------------+---------------------+--------------+----------------------+----------+---------+--------------+---------+-----------+------------+----------+-------------------------+-------------+------------------+---------+---+-----+--------+-------+---------+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newColoc.filter((F.col('isTransQtl')==True)).withColumnRenamed(\"geneId\", \"targetId\"\n",
    "    ).join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"rightStudyLocusId\"),\n",
    "            on=[\"rightStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run temporary direction of effect\n",
      "built drugApproved dataset\n",
      "built chemblAssoc dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/09 18:11:25 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/09 18:11:25 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/09 18:11:25 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 308:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------+-----------------+---------------------+--------------------+----------------------+----------+---------------+-----------+--------------+---------+--------------+\n",
      "|        rightStudyId|   rightStudyLocusId|    leftStudyLocusId|chromosome|rightStudyType|numberColocalisingVariants|                  h0|                  h1|                  h2|                  h3|                h4|colocalisationMethod|betaRatioSignAverage| leftStudyId|    leftVariantId|credibleLeftStudyType|      rightVariantId|credibleRightStudyType|isTransQtl|         geneId|  projectId|indexStudyType|condition|   biosampleId|\n",
      "+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------+-----------------+---------------------+--------------------+----------------------+----------+---------------+-----------+--------------+---------+--------------+\n",
      "|UKB_PPP_EUR_APOA1...|b989372efe9871c5a...|002999a730e1825f2...|        16|          pqtl|                         1|5.058101716757925...|  3.9067582166745E-6|3.718601751655479...|0.001874038047812428|0.9981220551939696|               COLOC|                 1.0|GCST90301945|  16_56981179_G_C|                 gwas|     16_56976574_C_T|                  pqtl|      true|ENSG00000118137|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_FGFBP...|a98e9324e3efee006...|002999a730e1825f2...|        16|          pqtl|                         1|2.305741607232927...|1.780900320715439...|6.731836503140864...|0.004203715299975911|0.9957961066099917|               COLOC|                 1.0|GCST90301945|  16_56981179_G_C|                 gwas|     16_56976574_C_T|                  pqtl|      true|ENSG00000137441|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_C1orf...|5d9d401e4b82b83f7...|002999a730e1825f2...|        16|          pqtl|                         1|3.787925111073135...|2.925703827347701E-6|2.276651943212716...| 7.59194271742439E-4|0.9992378800244287|               COLOC|                 1.0|GCST90301945|  16_56981179_G_C|                 gwas|     16_56981179_G_C|                  pqtl|      true|ENSG00000143443|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_BPIFB...|9850d4901b166e7e7...|002999a730e1825f2...|        16|          pqtl|                         1|2.106913594141407...|1.627330262747478...|3.686331785225070...|0.001849247524193...|0.9979880194495262|               COLOC|                 1.0|GCST90301945|  16_56981179_G_C|                 gwas|     16_56976574_C_T|                  pqtl|      true|ENSG00000125999|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_NPY_P...|93c45c5b4a9163268...|005760db4fdece276...|         1|          pqtl|                       116|6.157825893988976...|1.030065727415781...|1.693901948038017...|   0.282634319202016| 0.717365680797892|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|1_62541132_TGATTT...|                  pqtl|      true|ENSG00000122585|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_HMOX1...|f213c8a093135a0a0...|005760db4fdece276...|         1|          pqtl|                       125|9.295401082633973...|1.554911464312659...|1.704361782882818...|  0.2843857658383145| 0.715614078670528|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|     1_62553032_CT_C|                  pqtl|      true|ENSG00000100292|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_AGRP_...|94890897f9d9d9068...|005760db4fdece276...|         1|          pqtl|                       114|4.373925857061308...|7.316593871246953E-8|1.822417654389699...|  0.3041536247842849|0.6958463020497637|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|      1_62620330_T_A|                  pqtl|      true|ENSG00000159723|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_APOC1...|3c819b1c36dafb734...|005760db4fdece276...|         1|          pqtl|                       133|7.881301364836852...|1.318364397291321E-9|1.249714214839610...| 0.20825732820813014|0.7917426704735098|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|      1_62468331_G_A|                  pqtl|      true|ENSG00000130208|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_NRP1_...|66f2829a772b7461a...|005760db4fdece276...|         1|          pqtl|                       124|3.413876858043036...|5.710647896883034...|1.165943363736449...|  0.1942303225682361|0.8057696774317703|               COLOC|                -1.0|GCST90269542|1_62514728_CACA_C|                 gwas|      1_62670284_G_A|                  pqtl|      true|ENSG00000099250|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_LDLR_...|5f1d87bd6649f2061...|005760db4fdece276...|         1|          pqtl|                       129|6.325546812004234...|1.058121663454323...|1.149890917172839...| 0.19154242152037193|0.8084575784796185|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|1_62541132_TGATTT...|                  pqtl|      true|ENSG00000130164|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_MFGE8...|521bb8d5130dfda40...|005760db4fdece276...|         1|          pqtl|                       108|1.141276125154601...|1.909098182180179...|1.912464300704423...| 0.31923148053987044|0.6807685194582332|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|     1_62462070_CA_C|                  pqtl|      true|ENSG00000140545|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_PLA2G...|832858d05d0280014...|005760db4fdece276...|         1|          pqtl|                       132|6.705076116688435...|1.121608377115188...|1.790585431725314...| 0.29882347990634195|0.7011765199814831|               COLOC|                -1.0|GCST90269542|1_62514728_CACA_C|                 gwas|      1_62689678_G_A|                  pqtl|      true|ENSG00000069764|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_LCAT_...|b96567724f54c6982...|005760db4fdece276...|         1|          pqtl|                       107|3.180244908253186...|5.319834209632201...|1.820950715109124...| 0.30390799314248274|0.6960920068043083|               COLOC|                 1.0|GCST90269542|1_62514728_CACA_C|                 gwas|     1_62462070_CA_C|                  pqtl|      true|ENSG00000213398|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_PCSK9...|707be6015708e3217...|006298962b6378749...|        11|          pqtl|                         1|                 0.0|8.553286626795285...|                 0.0|0.007698528214172932|0.9923014718001425|               COLOC|                 1.0|GCST90025039|  11_61811991_A_G|                 gwas|     11_61826344_C_T|                  pqtl|      true|ENSG00000169174|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_AGRN_...|95ed6b3292dcf41e6...|01189b6175d0a478b...|         4|          pqtl|                         2|4.967836055267946...|2.000410076033168...|3.742890858047457E-8| 5.07666255732438E-4|0.9994922943148976|               COLOC|                -1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000188157|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_HS6ST...|9f7e0a5824c47e3c0...|01189b6175d0a478b...|         4|          pqtl|                         1|1.004800140822511...|4.046052051112814...|3.502789986196873E-8|4.108874971668500...|0.9995890774749355|               COLOC|                -1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000136720|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_TEK_Q...|fe22554ea3dfdd943...|01189b6175d0a478b...|         4|          pqtl|                         2|1.493498377485576...|6.013904584659616...|4.486273991503042E-8|8.073057125596076E-4| 0.999192649424699|               COLOC|                -1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000120156|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_HEPH_...|43394091f48970c9e...|01189b6175d0a478b...|         4|          pqtl|                         1|8.244074726902525...|3.319660706954785...|3.502789986196848E-8|4.108874971668500...|0.9995890774749355|               COLOC|                -1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000089472|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_HS3ST...|b34ceda075ac02aa6...|01189b6175d0a478b...|         4|          pqtl|                         2|6.753015883916373...|2.719252581508486...|3.805084857352573E-8|5.327351253195778E-4|0.9994672267966416|               COLOC|                 1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000125430|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "|UKB_PPP_EUR_CD300...|bc9cc5602ffc565c8...|01189b6175d0a478b...|         4|          pqtl|                         1|3.256531646023717...|1.311315157173667...|3.502789986196873E-8|4.108874971668500...|0.9995890774749355|               COLOC|                -1.0|GCST90133000|  4_102267552_C_T|                 gwas|     4_102267552_C_T|                  pqtl|      true|ENSG00000167850|UKB_PPP_EUR|          pqtl|     NULL|UBERON_0001969|\n",
      "+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+------------+-----------------+---------------------+--------------------+----------------------+----------+---------------+-----------+--------------+---------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newColoc.filter(F.col('isTransQtl')==True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 282:=======================================>              (50 + 18) / 68]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-------+\n",
      "|isTransQtl|rightStudyType|  count|\n",
      "+----------+--------------+-------+\n",
      "|     false|          pqtl| 101634|\n",
      "|     false|          eqtl|9391014|\n",
      "|     false|          sqtl|1707860|\n",
      "|     false|        sceqtl| 579478|\n",
      "|     false|         tuqtl|3353210|\n",
      "+----------+--------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "resolvedColoc.groupBy('isTransQtl','rightStudyType').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 262:=============================================>        (57 + 11) / 68]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+\n",
      "|isTransQtl|rightStudyType|   count|\n",
      "+----------+--------------+--------+\n",
      "|      NULL|          gwas|15500254|\n",
      "|     false|          pqtl|   42228|\n",
      "|      true|          pqtl| 1527897|\n",
      "|     false|          eqtl| 5136676|\n",
      "|     false|          sqtl|  761937|\n",
      "|     false|        sceqtl|  581576|\n",
      "|     false|         tuqtl| 1425456|\n",
      "+----------+--------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "newColoc.groupBy('isTransQtl','rightStudyType').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5215"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- biosampleId: string (nullable = true)\n",
      " |-- targetId: string (nullable = true)\n",
      " |-- diseaseId: string (nullable = true)\n",
      " |-- leftStudyLocusId: string (nullable = true)\n",
      " |-- rightStudyId: string (nullable = true)\n",
      " |-- rightStudyLocusId: string (nullable = true)\n",
      " |-- chromosome: string (nullable = true)\n",
      " |-- rightStudyType: string (nullable = true)\n",
      " |-- numberColocalisingVariants: long (nullable = true)\n",
      " |-- h0: double (nullable = true)\n",
      " |-- h1: double (nullable = true)\n",
      " |-- h2: double (nullable = true)\n",
      " |-- h3: double (nullable = true)\n",
      " |-- h4: double (nullable = true)\n",
      " |-- colocalisationMethod: string (nullable = true)\n",
      " |-- betaRatioSignAverage: double (nullable = true)\n",
      " |-- leftStudyId: string (nullable = true)\n",
      " |-- leftVariantId: string (nullable = true)\n",
      " |-- credibleLeftStudyType: string (nullable = true)\n",
      " |-- rightVariantId: string (nullable = true)\n",
      " |-- credibleRightStudyType: string (nullable = true)\n",
      " |-- isTransQtl: boolean (nullable = true)\n",
      " |-- projectId: string (nullable = true)\n",
      " |-- indexStudyType: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- datasourceId: string (nullable = true)\n",
      " |-- datatypeId: string (nullable = true)\n",
      " |-- diseaseFromSourceMappedId: string (nullable = true)\n",
      " |-- resourceScore: double (nullable = true)\n",
      " |-- targetFromSourceId: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      " |-- sourceId: string (nullable = true)\n",
      " |-- studyId: string (nullable = true)\n",
      " |-- variantId: string (nullable = true)\n",
      " |-- betaGwas: double (nullable = true)\n",
      " |-- pValueExponent: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- therapeuticAreas: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- colocDoE: string (nullable = true)\n",
      " |-- maxClinPhase: double (nullable = true)\n",
      " |-- approvedDrug: integer (nullable = true)\n",
      " |-- drugGoF_protect: long (nullable = true)\n",
      " |-- drugLoF_protect: long (nullable = true)\n",
      " |-- approved: string (nullable = false)\n",
      " |-- newPhases: double (nullable = true)\n",
      " |-- AgreeDrug: string (nullable = false)\n",
      " |-- biosampleName: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.select('targetId','diseaseId').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 194:>                                                      (1 + 64) / 68]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|isTransQtl|count|\n",
      "+----------+-----+\n",
      "|     false| 5215|\n",
      "+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "benchmark.groupBy('isTransQtl').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-------------+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+----------------+----------------------+----------+---------+--------------+---------+------------------+-------------------+-------------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+---------------+--------------------+--------------+--------------------+--------------------+-----------+------------+------------+---------------+---------------+--------+---------+---------+--------------------+\n",
      "|   biosampleId|       targetId|    diseaseId|    leftStudyLocusId|        rightStudyId|   rightStudyLocusId|chromosome|rightStudyType|numberColocalisingVariants|                  h0|                  h1|                  h2|                  h3|                h4|colocalisationMethod|betaRatioSignAverage|         leftStudyId|  leftVariantId|credibleLeftStudyType|  rightVariantId|credibleRightStudyType|isTransQtl|projectId|indexStudyType|condition|      datasourceId|         datatypeId|diseaseFromSourceMappedId|     resourceScore|targetFromSourceId|                  id|             score|          sourceId|             studyId|      variantId|            betaGwas|pValueExponent|                name|    therapeuticAreas|   colocDoE|maxClinPhase|approvedDrug|drugGoF_protect|drugLoF_protect|approved|newPhases|AgreeDrug|       biosampleName|\n",
      "+--------------+---------------+-------------+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+----------------+----------------------+----------+---------+--------------+---------+------------------+-------------------+-------------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+---------------+--------------------+--------------+--------------------+--------------------+-----------+------------+------------+---------------+---------------+--------+---------+---------+--------------------+\n",
      "|UBERON_0002037|ENSG00000105397|  EFO_0000676|34a2ab91d9b68cefe...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|7.485894609522133...|3.604729371054766...|2.231710454159268...|7.472413366875091E-5|0.9999252758440171|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         4.0|           1|           NULL|             48|     yes|      4.0|      yes|          cerebellum|\n",
      "|UBERON_0002037|ENSG00000105397|MONDO_0002406|34a2ab91d9b68cefe...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|7.485894609522133...|3.604729371054766...|2.231710454159268...|7.472413366875091E-5|0.9999252758440171|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         2.0|        NULL|           NULL|              1|      no|      2.0|      yes|          cerebellum|\n",
      "|UBERON_0002037|ENSG00000105397|  EFO_0000540|34a2ab91d9b68cefe...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|7.485894609522133...|3.604729371054766...|2.231710454159268...|7.472413366875091E-5|0.9999252758440171|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         4.0|           1|           NULL|              8|     yes|      4.0|      yes|          cerebellum|\n",
      "|UBERON_0002037|ENSG00000105397|  EFO_1000636|34a2ab91d9b68cefe...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|7.485894609522133...|3.604729371054766...|2.231710454159268...|7.472413366875091E-5|0.9999252758440171|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         1.0|        NULL|           NULL|              1|      no|      1.0|      yes|          cerebellum|\n",
      "|    CL_0000057|ENSG00000105397|  EFO_0000676|34a2ab91d9b68cefe...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         1|1.009145701166168...|4.859402033312298E-6|2.327702985808751...|1.209991486365986...|0.9998741414259537|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         4.0|           1|           NULL|             48|     yes|      4.0|      yes|          fibroblast|\n",
      "|    CL_0000057|ENSG00000105397|MONDO_0002406|34a2ab91d9b68cefe...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         1|1.009145701166168...|4.859402033312298E-6|2.327702985808751...|1.209991486365986...|0.9998741414259537|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         2.0|        NULL|           NULL|              1|      no|      2.0|      yes|          fibroblast|\n",
      "|    CL_0000057|ENSG00000105397|  EFO_0000540|34a2ab91d9b68cefe...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         1|1.009145701166168...|4.859402033312298E-6|2.327702985808751...|1.209991486365986...|0.9998741414259537|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         4.0|           1|           NULL|              8|     yes|      4.0|      yes|          fibroblast|\n",
      "|    CL_0000057|ENSG00000105397|  EFO_1000636|34a2ab91d9b68cefe...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         1|1.009145701166168...|4.859402033312298E-6|2.327702985808751...|1.209991486365986...|0.9998741414259537|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0000676|0.9750594257272259|   ENSG00000105397|b1201561492889a1d...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|   -0.30632754439486|           -14|           psoriasis|[OTAR_0000018, EF...|LoF_protect|         1.0|        NULL|           NULL|              1|      no|      1.0|      yes|          fibroblast|\n",
      "|UBERON_0002367|ENSG00000164116|  EFO_0001645|2607e0cb3f5be41c3...|gtex_leafcutter_p...|4e57f3b74cdda17cc...|         4|          sqtl|                         7|1.422936571674347...|1.233248468791097...|1.061157928643730...|  0.0910609471340762|0.9088157279127862|               COLOC|                 1.0|          GCST005195|4_155721732_A_G|                 gwas| 4_155742255_C_A|                  sqtl|     false|     GTEx|          sqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0001645|0.9073917573459095|   ENSG00000164116|6bf8e18171e1c051f...|0.9073917573459095|gwas_credible_sets|          GCST005195|4_155721732_A_G|-0.01040544016469...|           -14|coronary artery d...|       [EFO_0000319]|GoF_protect|         2.0|        NULL|              4|           NULL|      no|      2.0|      yes|      prostate gland|\n",
      "|UBERON_0000473|ENSG00000145777|MONDO_0004979|069bf488df7436384...|gtex_txrev_testis...|7bf89db29ef6ed974...|         5|         tuqtl|                         4|3.98389523388595E-31|1.056297550370158...|2.637491669376403...|0.005999094610243...| 0.994000905389756|               COLOC|                 1.0|FINNGEN_R12_J10_A...|5_111071044_C_T|                 gwas| 5_111069977_A_G|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|            MONDO_0004979|0.9044386377963552|   ENSG00000145777|d640e1f994e63e2f8...|0.9044386377963552|gwas_credible_sets|FINNGEN_R12_J10_A...|5_111071044_C_T| -0.0112788771889455|           -18|              asthma|      [OTAR_0000010]|LoF_protect|         4.0|           1|           NULL|             16|     yes|      4.0|      yes|              testis|\n",
      "|UBERON_0001159|ENSG00000145777|MONDO_0004979|069bf488df7436384...|gtex_ge_colon_sig...|d6e6c9450dee58e88...|         5|          eqtl|                         5|4.008418617291633...|1.062799726832500...|2.302436581060556...|0.005109833923585362|0.9948901659701339|               COLOC|                 1.0|FINNGEN_R12_J10_A...|5_111071044_C_T|                 gwas| 5_111071044_C_T|                  eqtl|     false|     GTEx|          eqtl|    naive|gwas_credible_sets|genetic_association|            MONDO_0004979|0.9044386377963552|   ENSG00000145777|d640e1f994e63e2f8...|0.9044386377963552|gwas_credible_sets|FINNGEN_R12_J10_A...|5_111071044_C_T| -0.0112788771889455|           -18|              asthma|      [OTAR_0000010]|LoF_protect|         4.0|           1|           NULL|             16|     yes|      4.0|      yes|       sigmoid colon|\n",
      "|UBERON_0002367|ENSG00000164116|  EFO_0001645|0a5307d21304310a7...|gtex_leafcutter_p...|4e57f3b74cdda17cc...|         4|          sqtl|                        10|3.966296108524207E-8|2.798559446262161E-5|2.957871250497178E-5|0.019890246745232543|0.9800521492848381|               COLOC|                 1.0|        GCST90013868|4_155721732_A_G|                 gwas| 4_155742255_C_A|                  sqtl|     false|     GTEx|          sqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0001645|0.9056237982377962|   ENSG00000164116|bf77e015beff284a5...|0.9056237982377962|gwas_credible_sets|        GCST90013868|4_155721732_A_G|-0.00927907718753...|            -9|coronary artery d...|       [EFO_0000319]|GoF_protect|         2.0|        NULL|              4|           NULL|      no|      2.0|      yes|      prostate gland|\n",
      "|   EFO_0004905|ENSG00000128052|  EFO_0001065|ca82f189aafc0edf1...|phlips_ge_ipsc_en...|c18925e69731711ce...|         4|          eqtl|                        27|6.751172301567163...|2.866514438137678...|1.051095350545576...| 0.04367266246872595|0.9563273364801731|               COLOC|                -1.0|        GCST90269970| 4_55136522_A_T|                 gwas|4_55132212_TAA_T|                  eqtl|     false|   PhLiPS|          eqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0001065|0.8696127368090059|   ENSG00000128052|586c7adacb7467925...|0.8696127368090059|gwas_credible_sets|        GCST90269970| 4_55136522_A_T|-0.01035891730213...|           -14|       endometriosis|      [OTAR_0000017]|GoF_protect|         1.0|        NULL|           NULL|              2|      no|      1.0|       no|induced pluripote...|\n",
      "|UBERON_0002367|ENSG00000164116|  EFO_0001645|59a34168cd2bde1d3...|gtex_leafcutter_p...|4e57f3b74cdda17cc...|         4|          sqtl|                         8|2.330347245631471...|1.545314581156197...|1.737861106269483E-5| 0.11435667170529021|0.8854713949220576|               COLOC|                 1.0|          GCST003116|4_155718736_G_T|                 gwas| 4_155742255_C_A|                  sqtl|     false|     GTEx|          sqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0001645|0.8339758487385046|   ENSG00000164116|f19dd1a941a01b517...|0.8339758487385046|gwas_credible_sets|          GCST003116|4_155718736_G_T|-0.01350509176073839|            -9|coronary artery d...|       [EFO_0000319]|GoF_protect|         2.0|        NULL|              4|           NULL|      no|      2.0|      yes|      prostate gland|\n",
      "|UBERON_0002037|ENSG00000105397|MONDO_0019338|a7d5988aa93fe93d4...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         2|4.773820781481797...|4.345336841999591...|1.423181369767612...|2.957508301276314...|0.9996900173561781|               COLOC|                 1.0|FINNGEN_R12_D3_SA...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|            MONDO_0019338|0.9196165198803148|   ENSG00000105397|e4cba9bca903f355d...|0.9196165198803148|gwas_credible_sets|FINNGEN_R12_D3_SA...|19_10352442_G_C|  -0.274799285393874|            -8|         sarcoidosis|      [OTAR_0000006]|LoF_protect|         1.0|        NULL|           NULL|              1|      no|      1.0|      yes|          cerebellum|\n",
      "|    CL_0000057|ENSG00000105397|MONDO_0019338|a7d5988aa93fe93d4...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         2|6.333659900794069E-8|5.765169446322004...|1.460927340494469...|3.301494394843087...|0.9996494127810662|               COLOC|                 1.0|FINNGEN_R12_D3_SA...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|            MONDO_0019338|0.9196165198803148|   ENSG00000105397|e4cba9bca903f355d...|0.9196165198803148|gwas_credible_sets|FINNGEN_R12_D3_SA...|19_10352442_G_C|  -0.274799285393874|            -8|         sarcoidosis|      [OTAR_0000006]|LoF_protect|         1.0|        NULL|           NULL|              1|      no|      1.0|      yes|          fibroblast|\n",
      "|    CL_0000057|ENSG00000105397|  EFO_0003767|8d14f4a8e4ec380f5...|gtex_txrev_fibrob...|e61c38b067d7b81db...|        19|         tuqtl|                         1|3.048030006965031E-9|1.245387348743785E-4|7.030614797903852E-7|0.027754101539710207|0.9721206536159064|               COLOC|                 1.0|          GCST004131|19_10286554_C_T|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0003767|0.6934678719771792|   ENSG00000105397|97ed539cbad1a04da...|0.6934678719771792|gwas_credible_sets|          GCST004131|19_10286554_C_T|-0.02606357519759...|           -11|inflammatory bowe...|[EFO_0010282, OTA...|LoF_protect|         2.0|        NULL|           NULL|              4|      no|      2.0|      yes|          fibroblast|\n",
      "|    CL_0000775|ENSG00000115232|  EFO_0003767|c53f513524ad16f36...|blueprint_ge_neut...|04d32dee70a4d0539...|         2|          eqtl|                         1|                 0.0|1.205132048812873...|                 0.0|3.044626650860797E-4|0.9996955373347589|               COLOC|                 1.0|        GCST90292538|2_181463487_G_A|                 gwas| 2_181463487_G_A|                  eqtl|     false|BLUEPRINT|          eqtl|    naive|gwas_credible_sets|genetic_association|              EFO_0003767|0.9565496569269856|   ENSG00000115232|4e94cf56206be48b6...|0.9565496569269856|gwas_credible_sets|        GCST90292538|2_181463487_G_A|-0.10486039909356243|           -17|inflammatory bowe...|[EFO_0010282, OTA...|LoF_protect|         1.0|        NULL|           NULL|              1|      no|      1.0|      yes|          neutrophil|\n",
      "|UBERON_0002037|ENSG00000105397|  EFO_1001494|b8a67437f19eb1607...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|4.333755842801539...|3.604729370702611...|1.291988295941479...|7.472413367065913E-5|0.9999252757371311|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_1001494|0.9750594257272259|   ENSG00000105397|24e376be2e9a16c20...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|  -0.382753682380315|           -13|  psoriasis vulgaris|[EFO_0000540, OTA...|LoF_protect|         3.0|        NULL|           NULL|              6|      no|      3.0|      yes|          cerebellum|\n",
      "|UBERON_0002037|ENSG00000105397|  EFO_0000676|b8a67437f19eb1607...|gtex_txrev_brain_...|ca3ba10d095473d0f...|        19|         tuqtl|                         1|4.333755842801539...|3.604729370702611...|1.291988295941479...|7.472413367065913E-5|0.9999252757371311|               COLOC|                 1.0|FINNGEN_R12_L12_P...|19_10352442_G_C|                 gwas| 19_10352442_G_C|                 tuqtl|     false|     GTEx|         tuqtl|    naive|gwas_credible_sets|genetic_association|              EFO_1001494|0.9750594257272259|   ENSG00000105397|24e376be2e9a16c20...|0.9750594257272259|gwas_credible_sets|FINNGEN_R12_L12_P...|19_10352442_G_C|  -0.382753682380315|           -13|  psoriasis vulgaris|[EFO_0000540, OTA...|LoF_protect|         4.0|           1|           NULL|             48|     yes|      4.0|      yes|          cerebellum|\n",
      "+--------------+---------------+-------------+--------------------+--------------------+--------------------+----------+--------------+--------------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+--------------------+--------------------+---------------+---------------------+----------------+----------------------+----------+---------+--------------+---------+------------------+-------------------+-------------------------+------------------+------------------+--------------------+------------------+------------------+--------------------+---------------+--------------------+--------------+--------------------+--------------------+-----------+------------+------------+---------------+---------------+--------+---------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's try the try gen evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 10.12.2024\n",
    "import time\n",
    "#from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType\n",
    ")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files\n",
      "loaded newColoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gwasComplete\n",
      "loaded resolvedColloc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:42 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:43 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run temporary direction of effect\n",
      "Moving to step 2\n",
      "defining non propagated,propagated and analysis_drugs functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:44 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:44 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:44 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining full_analysis_propagation\n",
      "defining full analysis no propagation\n",
      "moving to Step 3\n",
      "starting dictionaries at 2025-04-22 09:40:44.314299\n",
      "gene_burden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:44 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:44 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:45 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:45 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intogen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:46 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:46 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:47 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:47 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_gene_census\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:48 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:48 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:49 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:49 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:50 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:50 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:51 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:51 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eva_somatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:40:52 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:52 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:52 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:53 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:53 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:40:53 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gwas_credible_set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:41:12 WARN CacheManager: Asked to cache already cached data.        \n",
      "25/04/22 09:41:30 WARN CacheManager: Asked to cache already cached data.        ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:41:31 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:31 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:31 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:31 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:32 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:32 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:32 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:32 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orphanet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:41:33 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:33 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:34 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:34 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene2phenotype\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:41:35 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:35 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:36 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:41:36 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOcgc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wCgc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somatic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 09:42:49 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:42:49 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:42:50 WARN CacheManager: Asked to cache already cached data.\n",
      "25/04/22 09:42:50 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "germline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ]\r"
     ]
    }
   ],
   "source": [
    "#### 10.12.2024\n",
    "import time\n",
    "#from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "from itertools import islice\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.03/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    new.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .join(  ### propagated using parent terms\n",
    "            diseases.selectExpr(\n",
    "                \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "            ),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diseaseId\",\n",
    "            F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        )\n",
    "        .drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "\n",
    "datasource_filter = [\n",
    "    \"gwas_credible_set\",\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "window_spec = Window.partitionBy(\"targetId\", \"diseaseId\",'leftStudyId').orderBy( ### include gwas study\n",
    "    F.col(\"pValueExponent\").asc()\n",
    ")\n",
    "gwasCredibleAssoc = (\n",
    "    resolvedColoc.withColumn(\n",
    "        \"homogenized\", F.first(\"colocDoE\", ignorenulls=True).over(window_spec)\n",
    "    )  ## added 30.01.2025\n",
    "    .select(\"targetId\", \"diseaseId\",'leftStudyId', \"homogenized\")\n",
    "    .withColumn(\n",
    "        \"homogenized\",\n",
    "        F.when(F.col(\"homogenized\").isNull(), F.lit(\"noEvaluable\")).otherwise(\n",
    "            F.col(\"homogenized\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Moving to step 2\")\n",
    "\n",
    "columns_chembl = [\"LoF_protect\", \"GoF_protect\"]\n",
    "columns_dataset = [\"LoF_protect\", \"GoF_protect\", \"LoF_risk\", \"GoF_risk\", \"evidenceDif\"]\n",
    "columns = [\"GoF_risk\", \"LoF_protect\", \"LoF_risk\", \"GoF_protect\"]\n",
    "terms = [\"noEvaluable\", \"bivalent_risk\", \"null\", \"dispar\"]\n",
    "\n",
    "taDf = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"MONDO_0045024\", \"cell proliferation disorder\", \"Oncology\"),\n",
    "        (\"EFO_0005741\", \"infectious disease\", \"Other\"),\n",
    "        (\"OTAR_0000014\", \"pregnancy or perinatal disease\", \"Other\"),\n",
    "        (\"EFO_0005932\", \"animal disease\", \"Other\"),\n",
    "        (\"MONDO_0024458\", \"disease of visual system\", \"Other\"),\n",
    "        (\"EFO_0000319\", \"cardiovascular disease\", \"Other\"),\n",
    "        (\"EFO_0009605\", \"pancreas disease\", \"Other\"),\n",
    "        (\"EFO_0010282\", \"gastrointestinal disease\", \"Other\"),\n",
    "        (\"OTAR_0000017\", \"reproductive system or breast disease\", \"Other\"),\n",
    "        (\"EFO_0010285\", \"integumentary system disease\", \"Other\"),\n",
    "        (\"EFO_0001379\", \"endocrine system disease\", \"Other\"),\n",
    "        (\"OTAR_0000010\", \"respiratory or thoracic disease\", \"Other\"),\n",
    "        (\"EFO_0009690\", \"urinary system disease\", \"Other\"),\n",
    "        (\"OTAR_0000006\", \"musculoskeletal or connective tissue disease\", \"Other\"),\n",
    "        (\"MONDO_0021205\", \"disease of ear\", \"Other\"),\n",
    "        (\"EFO_0000540\", \"immune system disease\", \"Other\"),\n",
    "        (\"EFO_0005803\", \"hematologic disease\", \"Other\"),\n",
    "        (\"EFO_0000618\", \"nervous system disease\", \"Other\"),\n",
    "        (\"MONDO_0002025\", \"psychiatric disorder\", \"Other\"),\n",
    "        (\"MONDO_0024297\", \"nutritional or metabolic disease\", \"Other\"),\n",
    "        (\"OTAR_0000018\", \"genetic, familial or congenital disease\", \"Other\"),\n",
    "        (\"OTAR_0000009\", \"injury, poisoning or other complication\", \"Other\"),\n",
    "        (\"EFO_0000651\", \"phenotype\", \"Other\"),\n",
    "        (\"EFO_0001444\", \"measurement\", \"Other\"),\n",
    "        (\"GO_0008150\", \"biological process\", \"Other\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"taId\", StringType(), True),\n",
    "            StructField(\"taLabel\", StringType(), True),\n",
    "            StructField(\"taLabelSimple\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ").withColumn(\"taRank\", F.monotonically_increasing_id())\n",
    "\n",
    "### give us a classification of Oncology VS non oncology\n",
    "wByDisease = Window.partitionBy(\"diseaseId\")  #### checked 31.05.2023\n",
    "diseaseTA = (\n",
    "    diseases.withColumn(\"taId\", F.explode(\"therapeuticAreas\"))\n",
    "    .select(F.col(\"id\").alias(\"diseaseId\"), \"taId\", \"parents\")\n",
    "    .join(taDf, on=\"taId\", how=\"left\")\n",
    "    .withColumn(\"minRank\", F.min(\"taRank\").over(wByDisease))\n",
    "    .filter(F.col(\"taRank\") == F.col(\"minRank\"))\n",
    "    .drop(\"taRank\", \"minRank\")\n",
    ")\n",
    "\n",
    "#### give us propagation of diseases and list of therapeutic areas associated\n",
    "diseases2 = diseases.select(\"id\", \"parents\").withColumn(\n",
    "    \"diseaseIdPropagated\",\n",
    "    F.explode_outer(F.concat(F.array(F.col(\"id\")), F.col(\"parents\"))),\n",
    ")\n",
    "\n",
    "chembl_trials = (\n",
    "    assessment.filter((F.col(\"datasourceId\").isin([\"chembl\"])))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(F.max(F.col(\"clinicalPhase\")).alias(\"maxClinPhase\"))\n",
    ")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "assessment_all = assessment.unionByName(\n",
    "    gwasCredibleAssoc.withColumn(\"datasourceId\", F.lit(\"gwas_credible_set\")),\n",
    "    allowMissingColumns=True,\n",
    ")\n",
    "\n",
    "print(\"defining non propagated,propagated and analysis_drugs functions\")\n",
    "\n",
    "def analysis_nonPropagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "def analysis_propagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .join(\n",
    "            diseases2.selectExpr(\"id as diseaseId\", \"diseaseIdPropagated\"),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumnRenamed(\"diseaseId\", \"oldDiseaseId\")\n",
    "        .withColumnRenamed(\"diseaseIdPropagated\", \"diseaseId\")\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "chembl_ds = [\"chembl\"]\n",
    "\n",
    "def analysis_drugs(assessment_all, chembl_ds):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter((F.col(\"datasourceId\").isin(chembl_ds))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "analysis_chembl = analysis_drugs(assessment_all, chembl_ds)\n",
    "\n",
    "#######\n",
    "## include here the analysis\n",
    "#######\n",
    "\n",
    "analysisDatasources = []\n",
    "\n",
    "print(\"defining full_analysis_propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_propagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_propagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        #### Should remove the coherencyDiagonal.isNotNull()\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "#####\n",
    "## no propag\n",
    "#####\n",
    "print(\"defining full analysis no propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_noPropagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_nonPropagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "print(\"moving to Step 3\")\n",
    "\n",
    "from functions import relative_success, spreadSheetFormatter, convertTuple\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio, relative_risk\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "c = datetime.now()\n",
    "print(\"starting dictionaries at\", c)\n",
    "\n",
    "#### continue here on 10.07.2024\n",
    "\n",
    "## 1nd dictionary\n",
    "dfs_dict = {}  ### checked and changed on 01.06.2023\n",
    "dfs_dict_propag = {}\n",
    "\n",
    "\n",
    "wocgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "]\n",
    "wCgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"cancer_gene_census\",\n",
    "]\n",
    "\n",
    "datasource_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"WOcgc\",\n",
    "    \"wCgc\",\n",
    "    \"somatic\",\n",
    "    \"germline\",\n",
    "]\n",
    "\n",
    "germline_list = [\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "]\n",
    "\n",
    "somatic_list = [\"intogen\", \"cancer_gene_census\", \"eva_somatic\"]\n",
    "\n",
    "\n",
    "# assessment = prueba_assessment.filter(F.col(\"datasourceId\").isin(datasources_analysis))\n",
    "def dataset_builder(assessment_all, value, analysis_chembl, negativeTD, diseaseTA):\n",
    "    nonPropagated = full_analysis_noPropagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    propagated = full_analysis_propagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    return (\n",
    "        # Non propagation\n",
    "        ## All\n",
    "        nonPropagated,\n",
    "        ## Other\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        nonPropagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "        # Propagation\n",
    "        ## All\n",
    "        propagated,\n",
    "        ## Other\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        propagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "    )\n",
    "\n",
    "\n",
    "for value in datasource_list:\n",
    "    print(value)\n",
    "    if value == \"WOcgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wocgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"wCgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wCgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"germline\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            germline_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    elif value == \"somatic\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            somatic_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"]\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "\n",
    "\n",
    "def comparisons_df() -> list:\n",
    "    \"\"\"Return list of all comparisons to be used in the analysis\"\"\"\n",
    "    comparisons = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"hasGeneticEvidence\", \"byDatatype\"),\n",
    "            (\"diagonalYes\", \"byDatatype\"),\n",
    "            (\"oneCellYes\", \"byDatatype\"),\n",
    "        ],\n",
    "        schema=StructType(\n",
    "            [\n",
    "                StructField(\"comparison\", StringType(), True),\n",
    "                StructField(\"comparisonType\", StringType(), True),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    predictions = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"Phase4\", \"clinical\"),\n",
    "            (\"Phase>=3\", \"clinical\"),\n",
    "            (\"Phase>=2\", \"clinical\"),\n",
    "            (\"Phase>=1\", \"clinical\"),\n",
    "            (\"PhaseT\", \"clinical\"),\n",
    "        ]\n",
    "    )\n",
    "    return comparisons.join(predictions, how=\"full\").collect()\n",
    "\n",
    "\n",
    "result = []\n",
    "result_st = []\n",
    "result_ci = []\n",
    "array2 = []\n",
    "results = []\n",
    "\n",
    "\n",
    "def aggregations_original(\n",
    "    df,\n",
    "    data,\n",
    "    listado,\n",
    "    comparisonColumn,\n",
    "    comparisonType,\n",
    "    predictionColumn,\n",
    "    predictionType,\n",
    "    today_date,\n",
    "):\n",
    "\n",
    "    wComparison = Window.partitionBy(comparisonColumn)\n",
    "    wPrediction = Window.partitionBy(predictionColumn)\n",
    "    wPredictionComparison = Window.partitionBy(comparisonColumn, predictionColumn)\n",
    "\n",
    "    uniqIds = df.select(\"targetId\", \"diseaseId\").distinct().count()\n",
    "\n",
    "    out = (\n",
    "        df.withColumn(\"comparisonType\", F.lit(comparisonType))\n",
    "        .withColumn(\"predictionType\", F.lit(predictionType))\n",
    "        .withColumn(\"total\", F.lit(uniqIds))\n",
    "        .withColumn(\"a\", F.count(\"targetId\").over(wPredictionComparison))\n",
    "        .withColumn(\n",
    "            \"predictionTotal\",\n",
    "            F.count(\"targetId\").over(wPrediction),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"comparisonTotal\",\n",
    "            F.count(\"targetId\").over(wComparison),\n",
    "        )\n",
    "        .select(\n",
    "            F.col(predictionColumn).alias(\"prediction\"),\n",
    "            F.col(comparisonColumn).alias(\"comparison\"),\n",
    "            \"comparisonType\",\n",
    "            \"predictionType\",\n",
    "            \"a\",\n",
    "            \"predictionTotal\",\n",
    "            \"comparisonTotal\",\n",
    "            \"total\",\n",
    "        )\n",
    "        .filter(F.col(\"prediction\").isNotNull())\n",
    "        .filter(F.col(\"comparison\").isNotNull())\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    out.write.mode(\"overwrite\").parquet(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    filePath = \"gs://ot-team/jroldan/\" + str(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    listado.append(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    c = datetime.now()\n",
    "    c.strftime(\"%H:%M:%S\")\n",
    "    print(c)\n",
    "\n",
    "    array1 = np.delete(\n",
    "        out.join(full_data, on=[\"prediction\", \"comparison\"], how=\"outer\")\n",
    "        .groupBy(\"comparison\")\n",
    "        .pivot(\"prediction\")\n",
    "        .agg(F.first(\"a\"))\n",
    "        .sort(F.col(\"comparison\").desc())\n",
    "        .select(\"comparison\", \"yes\", \"no\")\n",
    "        .fillna(0)\n",
    "        .toPandas()\n",
    "        .to_numpy(),\n",
    "        [0],\n",
    "        1,\n",
    "    )\n",
    "    total = np.sum(array1)\n",
    "    res_npPhaseX = np.array(array1, dtype=int)\n",
    "    resX = convertTuple(fisher_exact(res_npPhaseX, alternative=\"two-sided\"))\n",
    "    resx_CI = convertTuple(\n",
    "        odds_ratio(res_npPhaseX).confidence_interval(confidence_level=0.95)\n",
    "    )\n",
    "\n",
    "    result_st.append(resX)\n",
    "    result_ci.append(resx_CI)\n",
    "    (rs_result, rs_ci) = relative_success(array1)\n",
    "\n",
    "    results.append(\n",
    "        [\n",
    "            data,\n",
    "            comparisonColumn,\n",
    "            predictionColumn,\n",
    "            round(float(resX.split(\",\")[0]), 2),\n",
    "            float(resX.split(\",\")[1]),\n",
    "            round(float(resx_CI.split(\",\")[0]), 2),\n",
    "            round(float(resx_CI.split(\",\")[1]), 2),\n",
    "            str(total),\n",
    "            np.array(res_npPhaseX).tolist(),\n",
    "            round(float(rs_result), 2),\n",
    "            round(float(rs_ci[0]), 2),\n",
    "            round(float(rs_ci[1]), 2),\n",
    "            filePath,\n",
    "        ]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "c = datetime.now()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start doing aggregations and writing\n",
      "starting with non-propagated aggregations at 2025-04-22 09:15:01.007325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22_analysis/df_gene_burden_All_original/hasGeneticEvidence_Phase4.parquet\n",
      "2025-04-22 09:38:40.029839\n",
      "df_gene_burden_All_original df unpersisted\n",
      "non propagated files wroten succesfully at 2025-04-22 09:15:01.007325\n",
      "starting with propagated aggregations at 2025-04-22 09:15:01.007325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-22_analysis/df_gene_burden_All_propag/hasGeneticEvidence_Phase4.parquet\n",
      "2025-04-22 09:38:47.248868\n",
      "df_gene_burden_All_propag df unpersisted\n",
      "propagated files wroten succesfully at 2025-04-22 09:15:01.007325\n",
      "creating pandas dataframe with resulting rows\n",
      "created pandas dataframe\n",
      "converting to spark dataframe\n",
      "preparing dataframe\n",
      "read pattern variables\n",
      "importing functions\n",
      "imported functions\n",
      "processed spreadsheet\n",
      "writting the dataframe\n",
      "dataframe written \n",
      " Analysis finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "#from itertools import islice\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.03/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    new.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .join(  ### propagated using parent terms\n",
    "            diseases.selectExpr(\n",
    "                \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "            ),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diseaseId\",\n",
    "            F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        )\n",
    "        .drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "\n",
    "datasource_filter = [\n",
    "    \"gwas_credible_set\",\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "window_spec = Window.partitionBy(\"targetId\", \"diseaseId\",'leftStudyId').orderBy( ### include gwas study\n",
    "    F.col(\"pValueExponent\").asc()\n",
    ")\n",
    "gwasCredibleAssoc = (\n",
    "    resolvedColoc.withColumn(\n",
    "        \"homogenized\", F.first(\"colocDoE\", ignorenulls=True).over(window_spec)\n",
    "    )  ## added 30.01.2025\n",
    "    .select(\"targetId\", \"diseaseId\",'leftStudyId', \"homogenized\")\n",
    "    .withColumn(\n",
    "        \"homogenized\",\n",
    "        F.when(F.col(\"homogenized\").isNull(), F.lit(\"noEvaluable\")).otherwise(\n",
    "            F.col(\"homogenized\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Moving to step 2\")\n",
    "\n",
    "columns_chembl = [\"LoF_protect\", \"GoF_protect\"]\n",
    "columns_dataset = [\"LoF_protect\", \"GoF_protect\", \"LoF_risk\", \"GoF_risk\", \"evidenceDif\"]\n",
    "columns = [\"GoF_risk\", \"LoF_protect\", \"LoF_risk\", \"GoF_protect\"]\n",
    "terms = [\"noEvaluable\", \"bivalent_risk\", \"null\", \"dispar\"]\n",
    "\n",
    "taDf = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"MONDO_0045024\", \"cell proliferation disorder\", \"Oncology\"),\n",
    "        (\"EFO_0005741\", \"infectious disease\", \"Other\"),\n",
    "        (\"OTAR_0000014\", \"pregnancy or perinatal disease\", \"Other\"),\n",
    "        (\"EFO_0005932\", \"animal disease\", \"Other\"),\n",
    "        (\"MONDO_0024458\", \"disease of visual system\", \"Other\"),\n",
    "        (\"EFO_0000319\", \"cardiovascular disease\", \"Other\"),\n",
    "        (\"EFO_0009605\", \"pancreas disease\", \"Other\"),\n",
    "        (\"EFO_0010282\", \"gastrointestinal disease\", \"Other\"),\n",
    "        (\"OTAR_0000017\", \"reproductive system or breast disease\", \"Other\"),\n",
    "        (\"EFO_0010285\", \"integumentary system disease\", \"Other\"),\n",
    "        (\"EFO_0001379\", \"endocrine system disease\", \"Other\"),\n",
    "        (\"OTAR_0000010\", \"respiratory or thoracic disease\", \"Other\"),\n",
    "        (\"EFO_0009690\", \"urinary system disease\", \"Other\"),\n",
    "        (\"OTAR_0000006\", \"musculoskeletal or connective tissue disease\", \"Other\"),\n",
    "        (\"MONDO_0021205\", \"disease of ear\", \"Other\"),\n",
    "        (\"EFO_0000540\", \"immune system disease\", \"Other\"),\n",
    "        (\"EFO_0005803\", \"hematologic disease\", \"Other\"),\n",
    "        (\"EFO_0000618\", \"nervous system disease\", \"Other\"),\n",
    "        (\"MONDO_0002025\", \"psychiatric disorder\", \"Other\"),\n",
    "        (\"MONDO_0024297\", \"nutritional or metabolic disease\", \"Other\"),\n",
    "        (\"OTAR_0000018\", \"genetic, familial or congenital disease\", \"Other\"),\n",
    "        (\"OTAR_0000009\", \"injury, poisoning or other complication\", \"Other\"),\n",
    "        (\"EFO_0000651\", \"phenotype\", \"Other\"),\n",
    "        (\"EFO_0001444\", \"measurement\", \"Other\"),\n",
    "        (\"GO_0008150\", \"biological process\", \"Other\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"taId\", StringType(), True),\n",
    "            StructField(\"taLabel\", StringType(), True),\n",
    "            StructField(\"taLabelSimple\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ").withColumn(\"taRank\", F.monotonically_increasing_id())\n",
    "\n",
    "### give us a classification of Oncology VS non oncology\n",
    "wByDisease = Window.partitionBy(\"diseaseId\")  #### checked 31.05.2023\n",
    "diseaseTA = (\n",
    "    diseases.withColumn(\"taId\", F.explode(\"therapeuticAreas\"))\n",
    "    .select(F.col(\"id\").alias(\"diseaseId\"), \"taId\", \"parents\")\n",
    "    .join(taDf, on=\"taId\", how=\"left\")\n",
    "    .withColumn(\"minRank\", F.min(\"taRank\").over(wByDisease))\n",
    "    .filter(F.col(\"taRank\") == F.col(\"minRank\"))\n",
    "    .drop(\"taRank\", \"minRank\")\n",
    ")\n",
    "\n",
    "#### give us propagation of diseases and list of therapeutic areas associated\n",
    "diseases2 = diseases.select(\"id\", \"parents\").withColumn(\n",
    "    \"diseaseIdPropagated\",\n",
    "    F.explode_outer(F.concat(F.array(F.col(\"id\")), F.col(\"parents\"))),\n",
    ")\n",
    "\n",
    "chembl_trials = (\n",
    "    assessment.filter((F.col(\"datasourceId\").isin([\"chembl\"])))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(F.max(F.col(\"clinicalPhase\")).alias(\"maxClinPhase\"))\n",
    ")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "assessment_all = assessment.unionByName(\n",
    "    gwasCredibleAssoc.withColumn(\"datasourceId\", F.lit(\"gwas_credible_set\")),\n",
    "    allowMissingColumns=True,\n",
    ")\n",
    "\n",
    "print(\"defining non propagated,propagated and analysis_drugs functions\")\n",
    "\n",
    "def analysis_nonPropagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "def analysis_propagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .join(\n",
    "            diseases2.selectExpr(\"id as diseaseId\", \"diseaseIdPropagated\"),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumnRenamed(\"diseaseId\", \"oldDiseaseId\")\n",
    "        .withColumnRenamed(\"diseaseIdPropagated\", \"diseaseId\")\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "chembl_ds = [\"chembl\"]\n",
    "\n",
    "def analysis_drugs(assessment_all, chembl_ds):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter((F.col(\"datasourceId\").isin(chembl_ds))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "analysis_chembl = analysis_drugs(assessment_all, chembl_ds)\n",
    "\n",
    "#######\n",
    "## include here the analysis\n",
    "#######\n",
    "\n",
    "analysisDatasources = []\n",
    "\n",
    "print(\"defining full_analysis_propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_propagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_propagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        #### Should remove the coherencyDiagonal.isNotNull()\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "#####\n",
    "## no propag\n",
    "#####\n",
    "print(\"defining full analysis no propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_noPropagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_nonPropagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "print(\"moving to Step 3\")\n",
    "\n",
    "from functions import relative_success, spreadSheetFormatter, convertTuple\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio, relative_risk\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "c = datetime.now()\n",
    "print(\"starting dictionaries at\", c)\n",
    "\n",
    "#### continue here on 10.07.2024\n",
    "\n",
    "## 1nd dictionary\n",
    "dfs_dict = {}  ### checked and changed on 01.06.2023\n",
    "dfs_dict_propag = {}\n",
    "\n",
    "\n",
    "wocgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "]\n",
    "wCgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"cancer_gene_census\",\n",
    "]\n",
    "\n",
    "datasource_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"WOcgc\",\n",
    "    \"wCgc\",\n",
    "    \"somatic\",\n",
    "    \"germline\",\n",
    "]\n",
    "\n",
    "germline_list = [\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "]\n",
    "\n",
    "somatic_list = [\"intogen\", \"cancer_gene_census\", \"eva_somatic\"]\n",
    "\n",
    "\n",
    "# assessment = prueba_assessment.filter(F.col(\"datasourceId\").isin(datasources_analysis))\n",
    "def dataset_builder(assessment_all, value, analysis_chembl, negativeTD, diseaseTA):\n",
    "    nonPropagated = full_analysis_noPropagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    propagated = full_analysis_propagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    return (\n",
    "        # Non propagation\n",
    "        ## All\n",
    "        nonPropagated,\n",
    "        ## Other\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        nonPropagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "        # Propagation\n",
    "        ## All\n",
    "        propagated,\n",
    "        ## Other\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        propagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "    )\n",
    "\n",
    "\n",
    "for value in datasource_list:\n",
    "    print(value)\n",
    "    if value == \"WOcgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wocgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"wCgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wCgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"germline\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            germline_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    elif value == \"somatic\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            somatic_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"]\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "\n",
    "\n",
    "def comparisons_df() -> list:\n",
    "    \"\"\"Return list of all comparisons to be used in the analysis\"\"\"\n",
    "    comparisons = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"hasGeneticEvidence\", \"byDatatype\"),\n",
    "            (\"diagonalYes\", \"byDatatype\"),\n",
    "            (\"oneCellYes\", \"byDatatype\"),\n",
    "        ],\n",
    "        schema=StructType(\n",
    "            [\n",
    "                StructField(\"comparison\", StringType(), True),\n",
    "                StructField(\"comparisonType\", StringType(), True),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    predictions = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"Phase4\", \"clinical\"),\n",
    "            (\"Phase>=3\", \"clinical\"),\n",
    "            (\"Phase>=2\", \"clinical\"),\n",
    "            (\"Phase>=1\", \"clinical\"),\n",
    "            (\"PhaseT\", \"clinical\"),\n",
    "        ]\n",
    "    )\n",
    "    return comparisons.join(predictions, how=\"full\").collect()\n",
    "\n",
    "\n",
    "result = []\n",
    "result_st = []\n",
    "result_ci = []\n",
    "array2 = []\n",
    "results = []\n",
    "\n",
    "\n",
    "def aggregations_original(\n",
    "    df,\n",
    "    data,\n",
    "    listado,\n",
    "    comparisonColumn,\n",
    "    comparisonType,\n",
    "    predictionColumn,\n",
    "    predictionType,\n",
    "    today_date,\n",
    "):\n",
    "\n",
    "    wComparison = Window.partitionBy(comparisonColumn)\n",
    "    wPrediction = Window.partitionBy(predictionColumn)\n",
    "    wPredictionComparison = Window.partitionBy(comparisonColumn, predictionColumn)\n",
    "\n",
    "    uniqIds = df.select(\"targetId\", \"diseaseId\").distinct().count()\n",
    "\n",
    "    out = (\n",
    "        df.withColumn(\"comparisonType\", F.lit(comparisonType))\n",
    "        .withColumn(\"predictionType\", F.lit(predictionType))\n",
    "        .withColumn(\"total\", F.lit(uniqIds))\n",
    "        .withColumn(\"a\", F.count(\"targetId\").over(wPredictionComparison))\n",
    "        .withColumn(\n",
    "            \"predictionTotal\",\n",
    "            F.count(\"targetId\").over(wPrediction),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"comparisonTotal\",\n",
    "            F.count(\"targetId\").over(wComparison),\n",
    "        )\n",
    "        .select(\n",
    "            F.col(predictionColumn).alias(\"prediction\"),\n",
    "            F.col(comparisonColumn).alias(\"comparison\"),\n",
    "            \"comparisonType\",\n",
    "            \"predictionType\",\n",
    "            \"a\",\n",
    "            \"predictionTotal\",\n",
    "            \"comparisonTotal\",\n",
    "            \"total\",\n",
    "        )\n",
    "        .filter(F.col(\"prediction\").isNotNull())\n",
    "        .filter(F.col(\"comparison\").isNotNull())\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "    out.write.mode(\"overwrite\").parquet(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    filePath = \"gs://ot-team/jroldan/\" + str(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    listado.append(\n",
    "        \"gs://ot-team/jroldan/\"\n",
    "        + str(\n",
    "            today_date\n",
    "            + \"_\"\n",
    "            + \"analysis/\"\n",
    "            + data\n",
    "            # + \"_propagated\"\n",
    "            + \"/\"\n",
    "            + comparisonColumn\n",
    "            + \"_\"\n",
    "            + predictionColumn\n",
    "            + \".parquet\"\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        today_date\n",
    "        + \"_\"\n",
    "        + \"analysis/\"\n",
    "        + data\n",
    "        # + \"_propagated\"\n",
    "        + \"/\"\n",
    "        + comparisonColumn\n",
    "        + \"_\"\n",
    "        + predictionColumn\n",
    "        + \".parquet\"\n",
    "    )\n",
    "    c = datetime.now()\n",
    "    c.strftime(\"%H:%M:%S\")\n",
    "    print(c)\n",
    "\n",
    "    array1 = np.delete(\n",
    "        out.join(full_data, on=[\"prediction\", \"comparison\"], how=\"outer\")\n",
    "        .groupBy(\"comparison\")\n",
    "        .pivot(\"prediction\")\n",
    "        .agg(F.first(\"a\"))\n",
    "        .sort(F.col(\"comparison\").desc())\n",
    "        .select(\"comparison\", \"yes\", \"no\")\n",
    "        .fillna(0)\n",
    "        .toPandas()\n",
    "        .to_numpy(),\n",
    "        [0],\n",
    "        1,\n",
    "    )\n",
    "    total = np.sum(array1)\n",
    "    res_npPhaseX = np.array(array1, dtype=int)\n",
    "    resX = convertTuple(fisher_exact(res_npPhaseX, alternative=\"two-sided\"))\n",
    "    resx_CI = convertTuple(\n",
    "        odds_ratio(res_npPhaseX).confidence_interval(confidence_level=0.95)\n",
    "    )\n",
    "\n",
    "    result_st.append(resX)\n",
    "    result_ci.append(resx_CI)\n",
    "    (rs_result, rs_ci) = relative_success(array1)\n",
    "\n",
    "    results.append(\n",
    "        [\n",
    "            data,\n",
    "            comparisonColumn,\n",
    "            predictionColumn,\n",
    "            round(float(resX.split(\",\")[0]), 2),\n",
    "            float(resX.split(\",\")[1]),\n",
    "            round(float(resx_CI.split(\",\")[0]), 2),\n",
    "            round(float(resx_CI.split(\",\")[1]), 2),\n",
    "            str(total),\n",
    "            np.array(res_npPhaseX).tolist(),\n",
    "            round(float(rs_result), 2),\n",
    "            round(float(rs_ci[0]), 2),\n",
    "            round(float(rs_ci[1]), 2),\n",
    "            filePath,\n",
    "        ]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "c = datetime.now()\n",
    "print(\"start doing aggregations and writing\")\n",
    "today_date = str(date.today())\n",
    "aggSetups_original = comparisons_df()\n",
    "listado = []\n",
    "results = []\n",
    "\n",
    "\n",
    "print(\"starting with non-propagated aggregations at\", c)\n",
    "for key, df in dfs_dict.items():\n",
    "    df = df.persist()\n",
    "    for row in aggSetups_original:\n",
    "        aggregations_original(df, key, listado, *row, today_date)\n",
    "    df.unpersist()\n",
    "    print(key + \" df unpersisted\")\n",
    "\n",
    "print(\"non propagated files wroten succesfully at\", c)\n",
    "\n",
    "\n",
    "print(\"starting with propagated aggregations at\", c)\n",
    "for key, df in dfs_dict_propag.items():\n",
    "    df = df.persist()\n",
    "    for row in aggSetups_original:\n",
    "        aggregations_original(df, key, listado, *row, today_date)\n",
    "    df.unpersist()\n",
    "    print(key + \" df unpersisted\")\n",
    "\n",
    "print(\"propagated files wroten succesfully at\", c)\n",
    "\n",
    "print(\"creating pandas dataframe with resulting rows\")\n",
    "df_results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\n",
    "        \"group\",\n",
    "        \"comparison\",\n",
    "        \"phase\",\n",
    "        \"OR\",\n",
    "        \"pValue\",\n",
    "        \"LowCI\",\n",
    "        \"HighCI\",\n",
    "        \"total\",\n",
    "        \"array\",\n",
    "        \"rs\",\n",
    "        \"lowRs\",\n",
    "        \"HighRs\",\n",
    "        \"path\",\n",
    "    ],\n",
    ")\n",
    "print(\"created pandas dataframe\")\n",
    "print(\"converting to spark dataframe\")\n",
    "print(\"preparing dataframe\")\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"group\", StringType(), True),\n",
    "        StructField(\"comparison\", StringType(), True),\n",
    "        StructField(\"phase\", StringType(), True),\n",
    "        StructField(\"oddsRatio\", DoubleType(), True),\n",
    "        StructField(\"pValue\", DoubleType(), True),\n",
    "        StructField(\"lowerInterval\", DoubleType(), True),\n",
    "        StructField(\"upperInterval\", DoubleType(), True),\n",
    "        StructField(\"total\", StringType(), True),\n",
    "        StructField(\"values\", ArrayType(ArrayType(IntegerType())), True),\n",
    "        StructField(\"relSuccess\", DoubleType(), True),\n",
    "        StructField(\"rsLower\", DoubleType(), True),\n",
    "        StructField(\"rsUpper\", DoubleType(), True),\n",
    "        StructField(\"path\", StringType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"read pattern variables\")\n",
    "df = spreadSheetFormatter(spark.createDataFrame(df_results, schema=schema))\n",
    "print(\"processed spreadsheet\")\n",
    "print(\"writting the dataframe\")\n",
    "\n",
    "# Convert list of lists to DataFrame\n",
    "# Regular expressions\n",
    "'''\n",
    "value_pattern = r\"df_([^_]+)_\"  # Extracts {value}\n",
    "middle_pattern = r\"df_[^_]+_([^_]+)_\"  # Extracts middle part (All, Other, etc.)\n",
    "suffix_pattern = r\"(original|propag)$\"  # Extracts suffix (original or propag)\n",
    "'''\n",
    "\n",
    "df.withColumn(\n",
    "    \"datasource\",\n",
    "    F.regexp_extract(F.col(\"group\"), r\"df_(.*?)_(All|Other|OtherNull|Oncology)_(propag|original)\", 1)\n",
    ").withColumn(\n",
    "    \"therArea\",\n",
    "    F.regexp_extract(F.col(\"group\"), r\"_(All|Other|OtherNull|Oncology)_\", 1)\n",
    ").withColumn(\n",
    "    \"type\",\n",
    "    F.regexp_extract(F.col(\"group\"), r\"_(propag|original)$\", 1)\n",
    ").toPandas().to_csv(\n",
    "    f\"gs://ot-team/jroldan/analysis/{today_date}_genEvidAnalysis_new.csv\"\n",
    ")\n",
    "\n",
    "print(\"dataframe written \\n Analysis finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>comparison</th>\n",
       "      <th>phase</th>\n",
       "      <th>OR</th>\n",
       "      <th>pValue</th>\n",
       "      <th>LowCI</th>\n",
       "      <th>HighCI</th>\n",
       "      <th>total</th>\n",
       "      <th>array</th>\n",
       "      <th>rs</th>\n",
       "      <th>lowRs</th>\n",
       "      <th>HighRs</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_gene_burden_All_original</td>\n",
       "      <td>hasGeneticEvidence</td>\n",
       "      <td>Phase4</td>\n",
       "      <td>6.18</td>\n",
       "      <td>4.102323e-09</td>\n",
       "      <td>3.44</td>\n",
       "      <td>10.85</td>\n",
       "      <td>74197</td>\n",
       "      <td>[[21, 37], [6233, 67906]]</td>\n",
       "      <td>4.31</td>\n",
       "      <td>3.06</td>\n",
       "      <td>6.07</td>\n",
       "      <td>gs://ot-team/jroldan/2025-04-22_analysis/df_ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_gene_burden_All_propag</td>\n",
       "      <td>hasGeneticEvidence</td>\n",
       "      <td>Phase4</td>\n",
       "      <td>5.56</td>\n",
       "      <td>3.576052e-10</td>\n",
       "      <td>3.32</td>\n",
       "      <td>9.09</td>\n",
       "      <td>74197</td>\n",
       "      <td>[[26, 51], [6228, 67892]]</td>\n",
       "      <td>4.02</td>\n",
       "      <td>2.94</td>\n",
       "      <td>5.50</td>\n",
       "      <td>gs://ot-team/jroldan/2025-04-22_analysis/df_ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         group          comparison   phase    OR  \\\n",
       "0  df_gene_burden_All_original  hasGeneticEvidence  Phase4  6.18   \n",
       "1    df_gene_burden_All_propag  hasGeneticEvidence  Phase4  5.56   \n",
       "\n",
       "         pValue  LowCI  HighCI  total                      array    rs  lowRs  \\\n",
       "0  4.102323e-09   3.44   10.85  74197  [[21, 37], [6233, 67906]]  4.31   3.06   \n",
       "1  3.576052e-10   3.32    9.09  74197  [[26, 51], [6228, 67892]]  4.02   2.94   \n",
       "\n",
       "   HighRs                                               path  \n",
       "0    6.07  gs://ot-team/jroldan/2025-04-22_analysis/df_ge...  \n",
       "1    5.50  gs://ot-team/jroldan/2025-04-22_analysis/df_ge...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's chech what happens with the coloc funtionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spark session created at 2025-04-22 15:53:48.571064\n",
      "Analysis started on 2025-04-22 at  2025-04-22 15:53:48.571064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/22 15:53:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files\n",
      "loaded newColoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded gwasComplete\n",
      "loaded resolvedColloc\n",
      "run temporary direction of effect\n",
      "Moving to step 2\n",
      "defining non propagated,propagated and analysis_drugs functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defining full_analysis_propagation\n",
      "defining full analysis no propagation\n",
      "moving to Step 3\n",
      "starting dictionaries at 2025-04-22 15:55:00.695089\n",
      "gene_burden\n",
      "intogen\n",
      "cancer_gene_census\n",
      "eva\n",
      "eva_somatic\n",
      "gwas_credible_set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "impc\n",
      "orphanet\n",
      "gene2phenotype\n",
      "WOcgc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wCgc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "somatic\n",
      "germline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#from array import ArrayType\n",
    "from functions import (\n",
    "    relative_success,\n",
    "    spreadSheetFormatter,\n",
    "    discrepancifier,\n",
    "    temporary_directionOfEffect,\n",
    ")\n",
    "# from stoppedTrials import terminated_td\n",
    "from DoEAssessment import directionOfEffect\n",
    "# from membraneTargets import target_membrane\n",
    "from pyspark.sql import SparkSession, Window\n",
    "import pyspark.sql.functions as F\n",
    "#from itertools import islice\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    ArrayType\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\n",
    "    \"spark.sql.shuffle.partitions\", \"400\"\n",
    ")  # Default is 200, increase if needed\n",
    "\n",
    "\n",
    "path_n='gs://open-targets-data-releases/25.03/output/'\n",
    "\n",
    "target = spark.read.parquet(f\"{path_n}target/\")\n",
    "\n",
    "diseases = spark.read.parquet(f\"{path_n}disease/\")\n",
    "\n",
    "evidences = spark.read.parquet(f\"{path_n}evidence\")\n",
    "\n",
    "credible = spark.read.parquet(f\"{path_n}credible_set\")\n",
    "\n",
    "new = spark.read.parquet(f\"{path_n}colocalisation_coloc\") \n",
    "\n",
    "index=spark.read.parquet(f\"{path_n}study/\")\n",
    "\n",
    "variantIndex = spark.read.parquet(f\"{path_n}variant\")\n",
    "\n",
    "biosample = spark.read.parquet(f\"{path_n}biosample\")\n",
    "\n",
    "print(\"loaded files\")\n",
    "\n",
    "newColoc = (\n",
    "    new.join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on left side\n",
    "            \"studyLocusId as leftStudyLocusId\",\n",
    "            \"StudyId as leftStudyId\",\n",
    "            \"variantId as leftVariantId\",\n",
    "            \"studyType as credibleLeftStudyType\",\n",
    "        ),\n",
    "        on=\"leftStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        credible.selectExpr(  #### studyLocusId from credible set to uncover the codified variants on right side\n",
    "            \"studyLocusId as rightStudyLocusId\",\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"variantId as rightVariantId\",\n",
    "            \"studyType as credibleRightStudyType\",\n",
    "            'isTransQtl'\n",
    "        ),\n",
    "        on=\"rightStudyLocusId\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .join(\n",
    "        index.selectExpr(  ### bring modulated target on right side (QTL study)\n",
    "            \"studyId as rightStudyId\",\n",
    "            \"geneId\",\n",
    "            \"projectId\",\n",
    "            \"studyType as indexStudyType\",\n",
    "            \"condition\",\n",
    "            \"biosampleId\",\n",
    "        ),\n",
    "        on=\"rightStudyId\",\n",
    "        how=\"left\",\n",
    ")\n",
    "    # .persist()\n",
    ")\n",
    "\n",
    "print(\"loaded newColoc\")\n",
    "\n",
    "# remove columns without content (only null values on them)\n",
    "df = evidences.filter((F.col(\"datasourceId\") == \"gwas_credible_sets\"))\n",
    "\n",
    "# Use an aggregation to determine non-null columns\n",
    "non_null_counts = df.select(\n",
    "    *[F.sum(F.col(col).isNotNull().cast(\"int\")).alias(col) for col in df.columns]\n",
    ")\n",
    "\n",
    "# Collect the counts for each column\n",
    "non_null_columns = [\n",
    "    row[0] for row in non_null_counts.collect()[0].asDict().items() if row[1] > 0\n",
    "]\n",
    "\n",
    "# Select only the non-null columns\n",
    "filtered_df = df.select(*non_null_columns)  # .persist()\n",
    "\n",
    "## bring studyId, variantId, beta from Gwas and pValue\n",
    "gwasComplete = filtered_df.join(\n",
    "    credible.selectExpr(\n",
    "        \"studyLocusId\", \"studyId\", \"variantId\", \"beta as betaGwas\", \"pValueExponent\"\n",
    "    ),\n",
    "    on=\"studyLocusId\",\n",
    "    how=\"left\",\n",
    ")  # .persist()\n",
    "\n",
    "print(\"loaded gwasComplete\")\n",
    "\n",
    "resolvedColoc = (\n",
    "    (\n",
    "        newColoc.withColumnRenamed(\"geneId\", \"targetId\")\n",
    "        .join(\n",
    "            gwasComplete.withColumnRenamed(\"studyLocusId\", \"leftStudyLocusId\"),\n",
    "            on=[\"leftStudyLocusId\", \"targetId\"],\n",
    "            how=\"inner\",\n",
    "        )\n",
    "        .join(  ### propagated using parent terms\n",
    "            diseases.selectExpr(\n",
    "                \"id as diseaseId\", \"name\", \"parents\", \"therapeuticAreas\"\n",
    "            ),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diseaseId\",\n",
    "            F.explode_outer(F.concat(F.array(F.col(\"diseaseId\")), F.col(\"parents\"))),\n",
    "        )\n",
    "        .drop(\"parents\", \"oldDiseaseId\")\n",
    "    ).withColumn(\n",
    "        \"colocDoE\",\n",
    "        F.when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"eqtl\", \"pqtl\", \"tuqtl\", \"sceqtl\", \"sctuqtl\"]\n",
    "            ),\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            ),\n",
    "        ).when(\n",
    "            F.col(\"rightStudyType\").isin(\n",
    "                [\"sqtl\", \"scsqtl\"]\n",
    "            ),  ### opposite directionality than sqtl\n",
    "            F.when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"LoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") > 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"GoF_risk\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") > 0),\n",
    "                F.lit(\"GoF_protect\"),\n",
    "            )\n",
    "            .when(\n",
    "                (F.col(\"betaGwas\") < 0) & (F.col(\"betaRatioSignAverage\") < 0),\n",
    "                F.lit(\"LoF_protect\"),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    # .persist()\n",
    ")\n",
    "print(\"loaded resolvedColloc\")\n",
    "\n",
    "datasource_filter = [\n",
    "    \"gwas_credible_set\",\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gene2phenotype\",\n",
    "    \"orphanet\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"intogen\",\n",
    "    \"impc\",\n",
    "    \"chembl\",\n",
    "]\n",
    "\n",
    "assessment, evidences, actionType, oncolabel = temporary_directionOfEffect(\n",
    "    path_n, datasource_filter\n",
    ")\n",
    "\n",
    "print(\"run temporary direction of effect\")\n",
    "\n",
    "window_spec = Window.partitionBy(\"targetId\", \"diseaseId\",'leftStudyId').orderBy( ### include gwas study\n",
    "    F.col(\"pValueExponent\").asc()\n",
    ")\n",
    "gwasCredibleAssoc = (\n",
    "    resolvedColoc.withColumn(\n",
    "        \"homogenized\", F.first(\"colocDoE\", ignorenulls=True).over(window_spec)\n",
    "    )  ## added 30.01.2025\n",
    "    .select(\"targetId\", \"diseaseId\",'leftStudyId', \"homogenized\")\n",
    "    .withColumn(\n",
    "        \"homogenized\",\n",
    "        F.when(F.col(\"homogenized\").isNull(), F.lit(\"noEvaluable\")).otherwise(\n",
    "            F.col(\"homogenized\")\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"Moving to step 2\")\n",
    "\n",
    "columns_chembl = [\"LoF_protect\", \"GoF_protect\"]\n",
    "columns_dataset = [\"LoF_protect\", \"GoF_protect\", \"LoF_risk\", \"GoF_risk\", \"evidenceDif\"]\n",
    "columns = [\"GoF_risk\", \"LoF_protect\", \"LoF_risk\", \"GoF_protect\"]\n",
    "terms = [\"noEvaluable\", \"bivalent_risk\", \"null\", \"dispar\"]\n",
    "\n",
    "taDf = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"MONDO_0045024\", \"cell proliferation disorder\", \"Oncology\"),\n",
    "        (\"EFO_0005741\", \"infectious disease\", \"Other\"),\n",
    "        (\"OTAR_0000014\", \"pregnancy or perinatal disease\", \"Other\"),\n",
    "        (\"EFO_0005932\", \"animal disease\", \"Other\"),\n",
    "        (\"MONDO_0024458\", \"disease of visual system\", \"Other\"),\n",
    "        (\"EFO_0000319\", \"cardiovascular disease\", \"Other\"),\n",
    "        (\"EFO_0009605\", \"pancreas disease\", \"Other\"),\n",
    "        (\"EFO_0010282\", \"gastrointestinal disease\", \"Other\"),\n",
    "        (\"OTAR_0000017\", \"reproductive system or breast disease\", \"Other\"),\n",
    "        (\"EFO_0010285\", \"integumentary system disease\", \"Other\"),\n",
    "        (\"EFO_0001379\", \"endocrine system disease\", \"Other\"),\n",
    "        (\"OTAR_0000010\", \"respiratory or thoracic disease\", \"Other\"),\n",
    "        (\"EFO_0009690\", \"urinary system disease\", \"Other\"),\n",
    "        (\"OTAR_0000006\", \"musculoskeletal or connective tissue disease\", \"Other\"),\n",
    "        (\"MONDO_0021205\", \"disease of ear\", \"Other\"),\n",
    "        (\"EFO_0000540\", \"immune system disease\", \"Other\"),\n",
    "        (\"EFO_0005803\", \"hematologic disease\", \"Other\"),\n",
    "        (\"EFO_0000618\", \"nervous system disease\", \"Other\"),\n",
    "        (\"MONDO_0002025\", \"psychiatric disorder\", \"Other\"),\n",
    "        (\"MONDO_0024297\", \"nutritional or metabolic disease\", \"Other\"),\n",
    "        (\"OTAR_0000018\", \"genetic, familial or congenital disease\", \"Other\"),\n",
    "        (\"OTAR_0000009\", \"injury, poisoning or other complication\", \"Other\"),\n",
    "        (\"EFO_0000651\", \"phenotype\", \"Other\"),\n",
    "        (\"EFO_0001444\", \"measurement\", \"Other\"),\n",
    "        (\"GO_0008150\", \"biological process\", \"Other\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"taId\", StringType(), True),\n",
    "            StructField(\"taLabel\", StringType(), True),\n",
    "            StructField(\"taLabelSimple\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ").withColumn(\"taRank\", F.monotonically_increasing_id())\n",
    "\n",
    "### give us a classification of Oncology VS non oncology\n",
    "wByDisease = Window.partitionBy(\"diseaseId\")  #### checked 31.05.2023\n",
    "diseaseTA = (\n",
    "    diseases.withColumn(\"taId\", F.explode(\"therapeuticAreas\"))\n",
    "    .select(F.col(\"id\").alias(\"diseaseId\"), \"taId\", \"parents\")\n",
    "    .join(taDf, on=\"taId\", how=\"left\")\n",
    "    .withColumn(\"minRank\", F.min(\"taRank\").over(wByDisease))\n",
    "    .filter(F.col(\"taRank\") == F.col(\"minRank\"))\n",
    "    .drop(\"taRank\", \"minRank\")\n",
    ")\n",
    "\n",
    "#### give us propagation of diseases and list of therapeutic areas associated\n",
    "diseases2 = diseases.select(\"id\", \"parents\").withColumn(\n",
    "    \"diseaseIdPropagated\",\n",
    "    F.explode_outer(F.concat(F.array(F.col(\"id\")), F.col(\"parents\"))),\n",
    ")\n",
    "\n",
    "chembl_trials = (\n",
    "    assessment.filter((F.col(\"datasourceId\").isin([\"chembl\"])))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .agg(F.max(F.col(\"clinicalPhase\")).alias(\"maxClinPhase\"))\n",
    ")\n",
    "\n",
    "negativeTD = (\n",
    "    evidences.filter(F.col(\"datasourceId\") == \"chembl\")\n",
    "    .select(\"targetId\", \"diseaseId\", \"studyStopReason\", \"studyStopReasonCategories\")\n",
    "    .filter(F.array_contains(F.col(\"studyStopReasonCategories\"), \"Negative\"))\n",
    "    .groupBy(\"targetId\", \"diseaseId\")\n",
    "    .count()\n",
    "    .withColumn(\"stopReason\", F.lit(\"Negative\"))\n",
    "    .drop(\"count\")\n",
    ")\n",
    "\n",
    "assessment_all = assessment.unionByName(\n",
    "    gwasCredibleAssoc.withColumn(\"datasourceId\", F.lit(\"gwas_credible_set\")),\n",
    "    allowMissingColumns=True,\n",
    ")\n",
    "\n",
    "print(\"defining non propagated,propagated and analysis_drugs functions\")\n",
    "\n",
    "def analysis_nonPropagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "def analysis_propagated(assessment_all, analysisDatasources):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter(F.col(\"datasourceId\").isin(analysisDatasources))\n",
    "        .withColumn(\n",
    "            \"datasources\",\n",
    "            F.collect_set(F.col(\"datasourceId\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .join(\n",
    "            diseases2.selectExpr(\"id as diseaseId\", \"diseaseIdPropagated\"),\n",
    "            on=\"diseaseId\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumnRenamed(\"diseaseId\", \"oldDiseaseId\")\n",
    "        .withColumnRenamed(\"diseaseIdPropagated\", \"diseaseId\")\n",
    "        .groupBy(\n",
    "            \"targetId\",\n",
    "            \"diseaseId\",\n",
    "        )\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "chembl_ds = [\"chembl\"]\n",
    "\n",
    "def analysis_drugs(assessment_all, chembl_ds):\n",
    "    return discrepancifier(\n",
    "        assessment_all.filter((F.col(\"datasourceId\").isin(chembl_ds))\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"maxClinPhase\",\n",
    "            F.max(F.col(\"clinicalPhase\")).over(\n",
    "                Window.partitionBy(\"targetId\", \"diseaseId\")\n",
    "            ),\n",
    "        )\n",
    "        .groupBy(\"targetId\", \"diseaseId\", \"maxClinPhase\")\n",
    "        .pivot(\"homogenized\")\n",
    "        .agg(F.count(\"targetId\"))\n",
    "        .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "analysis_chembl = analysis_drugs(assessment_all, chembl_ds)\n",
    "\n",
    "#######\n",
    "## include here the analysis\n",
    "#######\n",
    "\n",
    "analysisDatasources = []\n",
    "\n",
    "print(\"defining full_analysis_propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_propagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_propagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        #### Should remove the coherencyDiagonal.isNotNull()\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "\n",
    "#####\n",
    "## no propag\n",
    "#####\n",
    "print(\"defining full analysis no propagation\")\n",
    "\n",
    "\n",
    "def full_analysis_noPropagation(\n",
    "    assessment_all, analysisDatasources, analysis_chembl, negativeTD, diseaseTA\n",
    "):\n",
    "    return (\n",
    "        analysis_nonPropagated(assessment_all, analysisDatasources)\n",
    "        .join(\n",
    "            analysis_chembl.selectExpr(\n",
    "                \"targetId\",\n",
    "                \"diseaseId\",\n",
    "                \"maxClinPhase\",\n",
    "                \"coherencyDiagonal as coherencyDiagonal_ch\",\n",
    "                \"coherencyOneCell as coherencyOneCell_ch\",\n",
    "                \"LoF_protect as LoF_protect_ch\",\n",
    "                \"GoF_protect as GoF_protect_ch\",\n",
    "            ),\n",
    "            on=[\"targetId\", \"diseaseId\"],\n",
    "            how=\"right\",\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"geneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"coherencyDiagonal\").isNotNull(), F.lit(\"hasGeneticEvidence\")\n",
    "            ).otherwise(F.lit(\"noGeneticEvidence\")),\n",
    "        )\n",
    "        # .filter(F.col(\"coherencyDiagonal_ch\").isNotNull())\n",
    "        .withColumn(\n",
    "            \"diagonalAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyDiagonal_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyDiagonal\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        F.col(\"GoF_risk\").isNotNull() | F.col(\"LoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    F.col(\"GoF_protect_ch\").isNotNull()\n",
    "                    & (\n",
    "                        F.col(\"LoF_risk\").isNotNull() | F.col(\"GoF_protect\").isNotNull()\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellAgreeWithDrugs\",\n",
    "            F.when(\n",
    "                (F.col(\"coherencyOneCell_ch\") == \"coherent\")\n",
    "                & (F.col(\"coherencyOneCell\") == \"coherent\"),\n",
    "                F.when(\n",
    "                    (F.col(\"LoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"LoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"GoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .when(\n",
    "                    (F.col(\"GoF_protect_ch\").isNotNull())\n",
    "                    & (\n",
    "                        (F.col(\"GoF_protect\").isNotNull())\n",
    "                        & (F.col(\"LoF_risk\").isNull())\n",
    "                        & (F.col(\"LoF_protect\").isNull())\n",
    "                        & (F.col(\"GoF_risk\").isNull())\n",
    "                    ),\n",
    "                    F.lit(\"coherent\"),\n",
    "                )\n",
    "                .otherwise(F.lit(\"dispar\")),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase4\",\n",
    "            F.when(F.col(\"maxClinPhase\") == 4, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=3\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 3, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=2\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 2, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"Phase>=1\",\n",
    "            F.when(F.col(\"maxClinPhase\") >= 1, F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(negativeTD, on=[\"targetId\", \"diseaseId\"], how=\"left\")\n",
    "        .withColumn(\n",
    "            \"PhaseT\",\n",
    "            F.when(F.col(\"stopReason\") == \"Negative\", F.lit(\"yes\")).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .join(\n",
    "            diseaseTA.select(\"diseaseId\", \"taLabelSimple\"), on=\"diseaseId\", how=\"left\"\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"hasGeneticEvidence\",\n",
    "            F.when(\n",
    "                F.col(\"geneticEvidence\") == \"hasGeneticEvidence\", F.lit(\"yes\")\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"diagonalYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"diagonalAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"diagonalAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"oneCellYes\",\n",
    "            F.when(\n",
    "                F.col(\"hasGeneticEvidence\") == \"yes\",\n",
    "                F.when(F.col(\"oneCellAgreeWithDrugs\") == \"coherent\", F.lit(\"yes\"))\n",
    "                .when(F.col(\"oneCellAgreeWithDrugs\") == \"dispar\", F.lit(\"no\"))\n",
    "                .otherwise(F.lit(\"no\")),\n",
    "            ).otherwise(F.lit(\"no\")),\n",
    "        )\n",
    "        # .persist()\n",
    "    )\n",
    "\n",
    "print(\"moving to Step 3\")\n",
    "\n",
    "from functions import relative_success, spreadSheetFormatter, convertTuple\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats.contingency import odds_ratio, relative_risk\n",
    "\n",
    "full_data = spark.createDataFrame(\n",
    "    data=[\n",
    "        (\"yes\", \"yes\"),\n",
    "        (\"yes\", \"no\"),\n",
    "        (\"no\", \"yes\"),\n",
    "        (\"no\", \"no\"),\n",
    "    ],\n",
    "    schema=StructType(\n",
    "        [\n",
    "            StructField(\"prediction\", StringType(), True),\n",
    "            StructField(\"comparison\", StringType(), True),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "c = datetime.now()\n",
    "print(\"starting dictionaries at\", c)\n",
    "\n",
    "#### continue here on 10.07.2024\n",
    "\n",
    "## 1nd dictionary\n",
    "dfs_dict = {}  ### checked and changed on 01.06.2023\n",
    "dfs_dict_propag = {}\n",
    "\n",
    "\n",
    "wocgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "]\n",
    "wCgc_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"cancer_gene_census\",\n",
    "]\n",
    "\n",
    "datasource_list = [\n",
    "    \"gene_burden\",\n",
    "    \"intogen\",\n",
    "    \"cancer_gene_census\",\n",
    "    \"eva\",\n",
    "    \"eva_somatic\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "    \"WOcgc\",\n",
    "    \"wCgc\",\n",
    "    \"somatic\",\n",
    "    \"germline\",\n",
    "]\n",
    "\n",
    "germline_list = [\n",
    "    \"gene_burden\",\n",
    "    \"eva\",\n",
    "    \"gwas_credible_set\",\n",
    "    \"impc\",\n",
    "    \"orphanet\",\n",
    "    \"gene2phenotype\",\n",
    "]\n",
    "\n",
    "somatic_list = [\"intogen\", \"cancer_gene_census\", \"eva_somatic\"]\n",
    "\n",
    "\n",
    "# assessment = prueba_assessment.filter(F.col(\"datasourceId\").isin(datasources_analysis))\n",
    "def dataset_builder(assessment_all, value, analysis_chembl, negativeTD, diseaseTA):\n",
    "    nonPropagated = full_analysis_noPropagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    propagated = full_analysis_propagation(\n",
    "        assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "    )\n",
    "    return (\n",
    "        # Non propagation\n",
    "        ## All\n",
    "        nonPropagated,\n",
    "        ## Other\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        nonPropagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        nonPropagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "        # Propagation\n",
    "        ## All\n",
    "        propagated,\n",
    "        ## Other\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Other\"),\n",
    "        ## Other&Null\n",
    "        propagated.filter(\n",
    "            (F.col(\"taLabelSimple\").isNull()) | (F.col(\"taLabelSimple\") == \"Other\")\n",
    "        ),\n",
    "        ## Oncology\n",
    "        propagated.filter(F.col(\"taLabelSimple\") == \"Oncology\"),\n",
    "    )\n",
    "\n",
    "\n",
    "for value in datasource_list:\n",
    "    print(value)\n",
    "    if value == \"WOcgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wocgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"wCgc\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, wCgc_list, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "    elif value == \"germline\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            germline_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    elif value == \"somatic\":\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"],\n",
    "        ) = dataset_builder(\n",
    "            assessment_all,\n",
    "            somatic_list,\n",
    "            analysis_chembl,\n",
    "            negativeTD,\n",
    "            diseaseTA,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        (\n",
    "            dfs_dict[f\"df_{value}_All_original\"],\n",
    "            dfs_dict[f\"df_{value}_Other_original\"],\n",
    "            dfs_dict[f\"df_{value}_OtherNull_original\"],\n",
    "            dfs_dict[f\"df_{value}_Oncology_original\"],\n",
    "            dfs_dict_propag[f\"df_{value}_All_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Other_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_OtherNull_propag\"],\n",
    "            dfs_dict_propag[f\"df_{value}_Oncology_propag\"]\n",
    "        ) = dataset_builder(\n",
    "            assessment_all, value, analysis_chembl, negativeTD, diseaseTA\n",
    "        )\n",
    "\n",
    "\n",
    "def comparisons_df() -> list:\n",
    "    \"\"\"Return list of all comparisons to be used in the analysis\"\"\"\n",
    "    comparisons = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"hasGeneticEvidence\", \"byDatatype\"),\n",
    "            (\"diagonalYes\", \"byDatatype\"),\n",
    "            (\"oneCellYes\", \"byDatatype\"),\n",
    "        ],\n",
    "        schema=StructType(\n",
    "            [\n",
    "                StructField(\"comparison\", StringType(), True),\n",
    "                StructField(\"comparisonType\", StringType(), True),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    predictions = spark.createDataFrame(\n",
    "        data=[\n",
    "            (\"Phase4\", \"clinical\"),\n",
    "            (\"Phase>=3\", \"clinical\"),\n",
    "            (\"Phase>=2\", \"clinical\"),\n",
    "            (\"Phase>=1\", \"clinical\"),\n",
    "            (\"PhaseT\", \"clinical\"),\n",
    "        ]\n",
    "    )\n",
    "    return comparisons.join(predictions, how=\"full\").collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'df_gwas_credible_sets_All_propag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdfs_dict_propag\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdf_gwas_credible_sets_All_propag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'df_gwas_credible_sets_All_propag'"
     ]
    }
   ],
   "source": [
    "dfs_dict_propag[f\"df_gwas_credible_sets_All_propag\"].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
